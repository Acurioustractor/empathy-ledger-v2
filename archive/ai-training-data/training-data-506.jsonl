{"type":"Practice","question":"What issue did the Impact Framework present regarding Indigenous community metrics?","answer":"The Impact Framework was displaying irrelevant Indigenous community metrics, such as Relationship Strengthening and Cultural Continuity, for all projects, including those unrelated to cultural contexts, like Goods projects focused on manufacturing appliances like beds, fridges, and washing machines.","context":"This issue highlights the need for tailored metrics that are appropriate for the specific context of each project.","document":"Project Outcomes Tracker - Implementation Complete","category":"Practice","section":"Project Outcomes Tracker - Implementation Complete > **Problem Solved:**","confidence":1}
{"type":"Practice","question":"How can I set up my Empathy Ledger account?","answer":"To set up your Empathy Ledger account, follow the provided guidelines to create a profile. Make sure to include relevant information about yourself and the stories you intend to share, particularly those related to sustainable tourism and cultural preservation.","context":"This is part of an overview on setting up an account on the Empathy Ledger platform.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > Overview","confidence":0.9}
{"type":"Practice","question":"What types of stories can I share on my Empathy Ledger account?","answer":"You can share stories related to sustainable tourism, cultural preservation, and specific projects such as the Napa Homestead walking trail project. It's essential to ensure that these stories respect cultural sensitivity and guidelines.","context":"This is intended to guide users on the themes appropriate for storytelling on the platform.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > Overview","confidence":0.9}
{"type":"Practice","question":"What is the importance of cultural sensitivity when using Empathy Ledger?","answer":"Cultural sensitivity is crucial when using the Empathy Ledger as it ensures that the stories shared do not offend or misrepresent Indigenous cultures. Users should be mindful of the cultural context and the audience when posting their content.","context":"This emphasizes the platform's commitment to respecting Indigenous cultures.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > Overview","confidence":0.95}
{"type":"Fact","question":"What type of platform is the Empathy Ledger?","answer":"The Empathy Ledger is a multi-tenant storytelling platform designed specifically for Indigenous communities and organizations.","context":"This fact establishes the primary function and target audience of the Empathy Ledger.","document":"Empathy Ledger Platform Architecture","category":"Practice","section":"Empathy Ledger Platform Architecture > Overview","confidence":1}
{"type":"Practice","question":"What does the Empathy Ledger connect?","answer":"The Empathy Ledger connects profiles, storytellers, organizations, projects, stories, and transcripts.","context":"Understanding these connections helps in navigating the architecture of the Empathy Ledger.","document":"Empathy Ledger Platform Architecture","category":"Practice","section":"Empathy Ledger Platform Architecture > Overview","confidence":1}
{"type":"Practice","question":"What are the components involved in the Complete Project Outcomes Integration?","answer":"The components involved in the Complete Project Outcomes Integration include the AI Analysis Engine located in `src/lib/ai/project-outcomes-tracker.ts`, the API Integration found in `src/app/api/projects/[id]/analysis/route.ts`, and the UI Component which is `src/components/projects/ProjectOutcomesView.tsx`.","context":null,"document":"Complete Project Outcomes Integration - Final Steps","category":"Principle","section":"Complete Project Outcomes Integration - Final Steps > âœ… **COMPLETED (Backend 100% Done):**","confidence":1}
{"type":"Fact","question":"What is the current status of the backend for the Complete Project Outcomes Integration?","answer":"The current status of the backend for the Complete Project Outcomes Integration is 100% completed.","context":null,"document":"Complete Project Outcomes Integration - Final Steps","category":"Principle","section":"Complete Project Outcomes Integration - Final Steps > âœ… **COMPLETED (Backend 100% Done):**","confidence":1}
{"type":"Fact","question":"What type of context is saved with the seed interview responses?","answer":"Goods Context is saved with the seed interview responses.","context":null,"document":"Complete Project Outcomes Integration - Final Steps","category":"Principle","section":"Complete Project Outcomes Integration - Final Steps > âœ… **COMPLETED (Backend 100% Done):**","confidence":1}
{"type":"Method","question":"What is the Enhanced Storyteller Card system?","answer":"The Enhanced Storyteller Card system integrates organization/project tagging, enhanced location context, and AI-driven profile development into a unified component for displaying storyteller information.","context":"This system aims to provide a comprehensive way to showcase storytellers and their respective backgrounds.","document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Overview","confidence":0.9}
{"type":"Practice","question":"What are some best practices for creating admin and storyteller pages on the Empathy Ledger platform?","answer":"Best practices for creating admin and storyteller pages include ensuring the pages are maintainable, performant, and user-friendly. This can be achieved through thoughtful design, efficient coding practices, and regular user feedback.","context":"These best practices aim to enhance the user experience and management capabilities of the platform.","document":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations","category":"Principle","section":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations > ðŸ“‹ Executive Summary","confidence":0.9}
{"type":"Method","question":"How can I ensure the admin and storyteller pages are maintainable?","answer":"To ensure maintainability of the admin and storyteller pages, focus on writing clean, modular code, utilizing consistent coding standards, and implementing thorough documentation to facilitate updates and collaboration.","context":"Maintaining clarity and structure in the codebase enhances long-term support and adaptability.","document":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations","category":"Principle","section":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations > ðŸ“‹ Executive Summary","confidence":0.85}
{"type":"Principle","question":"What is the main philosophy behind the Seed Interview System?","answer":"The Seed Interview System empowers projects and organizations to define their own success metrics and outcomes, enabling project-specific tracking based on individual definitions of success rather than relying on generic impact scores.","context":"This approach helps ensure that the evaluation process is aligned with the unique goals and needs of each project.","document":"Seed Interview System - User Guide","category":"Principle","section":"Seed Interview System - User Guide > Overview","confidence":1}
{"type":"Principle","question":"What is the purpose of the Seed Interview System?","answer":"The Seed Interview System enables organizations and projects to define their own context through guided interviews, allowing for specific project outcomes tracking and contextual analysis.","context":"The system utilizes AI to extract structured data from free-form responses.","document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > System Overview","confidence":0.9}
{"type":"Fact","question":"What LLM provider does the Empathy Ledger use?","answer":"The Empathy Ledger uses Ollama as its LLM provider.","context":"This is part of the current setup for the performance and caching guide.","document":"Ollama Analysis - Performance & Caching Guide","category":"Principle","section":"Ollama Analysis - Performance & Caching Guide > Current Setup âœ…","confidence":0.9}
{"type":"Fact","question":"What is the model used in the Empathy Ledger's current setup?","answer":"The model used is llama3.1:8b.","context":"This is specified in the current setup section of the performance and caching guide.","document":"Ollama Analysis - Performance & Caching Guide","category":"Principle","section":"Ollama Analysis - Performance & Caching Guide > Current Setup âœ…","confidence":0.9}
{"type":"Fact","question":"What is the processing method used for transcripts in the current setup?","answer":"Transcripts are processed in batches, with 2 transcripts at a time and a 2-second delay.","context":"This indicates how the system manages processing load effectively.","document":"Ollama Analysis - Performance & Caching Guide","category":"Principle","section":"Ollama Analysis - Performance & Caching Guide > Current Setup âœ…","confidence":0.9}
{"type":"Fact","question":"What is the maximum character limit for transcript truncation?","answer":"The first 8000 characters of each transcript are used before truncation.","context":"This is an important specification for managing transcript data.","document":"Ollama Analysis - Performance & Caching Guide","category":"Principle","section":"Ollama Analysis - Performance & Caching Guide > Current Setup âœ…","confidence":0.9}
{"type":"Fact","question":"What is the timeout duration for requests in the current setup?","answer":"The timeout duration for each request is set to 5 minutes.","context":"This is crucial for understanding the limits of the processing time per request.","document":"Ollama Analysis - Performance & Caching Guide","category":"Principle","section":"Ollama Analysis - Performance & Caching Guide > Current Setup âœ…","confidence":0.9}
{"type":"Fact","question":"What is the current data quality for the locations in the Location Management Strategy?","answer":"Out of 40 total locations, 29 locations (73%) are complete with properly structured name, city, state, and country. 8 locations (20%) have only the name stored in the `name` field, and 3 locations (7%) are partial, missing some structured fields.","context":"This data quality assessment is part of the Current State Analysis in the Location Management Strategy.","document":"Location Management Strategy","category":"Procedure","section":"Location Management Strategy > Current State Analysis > Data Quality (40 locations total)","confidence":0.9}
{"type":"Warning","question":"What issues are associated with the location data quality?","answer":"There are issues with 8 locations where full addresses are only stored in the `name` field, and 3 locations that are missing some structured fields, which may affect data usability and clarity.","context":"The issues identified in the data quality analysis may impact location management effectiveness.","document":"Location Management Strategy","category":"Procedure","section":"Location Management Strategy > Current State Analysis > Data Quality (40 locations total)","confidence":0.85}
{"type":"Procedure","question":"What are the steps to quickly add a storyteller and transcript in the Empathy Ledger?","answer":"To quickly add a storyteller and transcript in the Empathy Ledger, follow these steps: 1. Enter the storyteller's information by selecting an existing storyteller from the dropdown or entering a new name, along with optional email and bio. 2. Paste the full transcript into the large text area provided. 3. Enter the required video link. 4. Select the appropriate project from the dropdown list. 5. Optionally, you can add photos, locations, and tags. Finally, choose to either cancel, save and add another, or save and finish.","context":"This process is designed for quick entry of storytelling content in the platform.","document":"Quick Add Storyteller & Transcript - Optimized Workflow","category":"Procedure","section":"Quick Add Storyteller & Transcript - Optimized Workflow > Your Workflow (Optimized for Speed) > Single Form - Everything in One Place","confidence":0.9}
{"type":"Fact","question":"What information is required to add a new storyteller?","answer":"To add a new storyteller, the required information includes the storyteller's name. Additionally, you can optionally provide an email and a bio.","context":"These fields ensure the storyteller's identity is captured adequately in the platform.","document":"Quick Add Storyteller & Transcript - Optimized Workflow","category":"Procedure","section":"Quick Add Storyteller & Transcript - Optimized Workflow > Your Workflow (Optimized for Speed) > Single Form - Everything in One Place","confidence":0.9}
{"type":"Fact","question":"What components are included in the quick add storyteller and transcript workflow?","answer":"The components included in the quick add storyteller and transcript workflow are: 1. Storyteller (existing or new), 2. Transcript, 3. Video link, 4. Project selection, and optional details like photo, location, and tags.","context":"These components guide users to input the necessary storytelling information.","document":"Quick Add Storyteller & Transcript - Optimized Workflow","category":"Procedure","section":"Quick Add Storyteller & Transcript - Optimized Workflow > Your Workflow (Optimized for Speed) > Single Form - Everything in One Place","confidence":0.9}
{"type":"Procedure","question":"How do you finalize adding a storyteller and transcript after inputting the details?","answer":"To finalize adding a storyteller and transcript, you can click on 'Save & Add Another' to enter another entry or 'Save & Done' to complete and exit the workflow.","context":"This step ensures that users can efficiently manage multiple entries if needed.","document":"Quick Add Storyteller & Transcript - Optimized Workflow","category":"Procedure","section":"Quick Add Storyteller & Transcript - Optimized Workflow > Your Workflow (Optimized for Speed) > Single Form - Everything in One Place","confidence":0.8}
{"type":"Procedure","question":"How does the AI analyze project success in the Organization & Project Context Management System?","answer":"The AI conducts project-specific analysis by evaluating transcripts against the success criteria defined specifically for the project.","context":"This measurement ensures that the analysis aligns with the unique goals of the project.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > Vision","confidence":1}
{"type":"Principle","question":"What does organizational identity mean in the context of the Organization & Project Context Management System?","answer":"Organizational identity refers to the clear and consistent representation of an organization across the platform, ensuring that its unique characteristics and values are adequately reflected.","context":"This principle is essential for maintaining brand integrity and cultural sensitivity.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > Vision","confidence":1}
{"type":"Procedure","question":"How can organizations update their context in the Organization & Project Context Management System?","answer":"Organizations can update their own context autonomously through a self-service feature, which allows them to manage and modify their information without the need for developer intervention.","context":"This empowers organizations to maintain relevant and up-to-date context on the platform.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > Vision","confidence":1}
{"type":"Method","question":"What is contextual intelligence in the Organization & Project Context Management System?","answer":"Contextual intelligence refers to the system's ability to utilize appropriate context for each analysis, recommendation, and insight, ensuring that the outputs are relevant and tailored to specific circumstances.","context":"This method enhances the quality and applicability of insights generated by the platform.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > Vision","confidence":1}
{"type":"Fact","question":"What UI feature is available for managing storytellers in projects?","answer":"There is a user interface that allows for adding and removing storytellers from projects.","context":"This feature is essential for managing project collaborations within the Empathy Ledger platform.","document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > Executive Summary","confidence":0.9}
{"type":"Warning","question":"What data integrity issues have been identified within the Empathy Ledger platform?","answer":"Data integrity issues include orphaned records, missing links, and duplicate profiles.","context":"These issues can affect the reliability and usability of data within the platform.","document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > Executive Summary","confidence":0.85}
{"type":"Fact","question":"What is the status of storyteller IDs in the transcripts?","answer":"All transcripts have NULL storyteller_id values.","context":"This indicates that no storyteller has been linked to any of the transcripts.","document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > Executive Summary","confidence":0.9}
{"type":"Fact","question":"What is the status of storyteller and project IDs in the stories?","answer":"All stories have NULL storyteller_id and project_id values.","context":"This means that the stories are not associated with any specific storyteller or project.","document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > Executive Summary","confidence":0.9}
{"type":"Warning","question":"What are common database constraint errors in the Empathy Ledger platform?","answer":"Common database constraint errors include missing profile UUID, missing tenant_id for both profiles and transcripts, missing required fields such as transcript_content, and invalid status values in transcripts.","context":"These errors can prevent proper data entry and functionality within the platform.","document":"Quick Add Complete Fix - All Database Constraints Resolved","category":"Principle","section":"Quick Add Complete Fix - All Database Constraints Resolved > Problem","confidence":0.9}
{"type":"Principle","question":"What is the first step in establishing a project within the World-Class Analysis System?","answer":"The first step is to seed the project by conducting an interview about its goals.","context":"This sets a foundation for understanding the project's objectives.","document":"World-Class Analysis System - What We're Actually Building","category":"Principle","section":"World-Class Analysis System - What We're Actually Building > The Vision","confidence":0.9}
{"type":"Fact","question":"When does Sprint 6 take place in the Empathy Ledger v2 plan?","answer":"Sprint 6 takes place from March 17 to March 28.","context":"This sprint is focused on analytics and Social Return on Investment (SROI).","document":"Empathy Ledger v2 - Detailed Sprint Plan","category":"Practice","section":"Empathy Ledger v2 - Detailed Sprint Plan > Sprint Overview","confidence":1}
{"type":"Method","question":"How is the analysis framework developed in the World-Class Analysis System?","answer":"An analysis framework is created based on the insights gained from the initial interview about the project goals.","context":"This framework serves as a guideline for analyzing storyteller transcripts.","document":"World-Class Analysis System - What We're Actually Building","category":"Principle","section":"World-Class Analysis System - What We're Actually Building > The Vision","confidence":0.9}
{"type":"Process","question":"What is done after establishing the analysis framework?","answer":"Storyteller transcripts are analyzed against the established framework to assess outcomes.","context":"This evaluation helps in measuring the effectiveness of the storytelling.","document":"World-Class Analysis System - What We're Actually Building","category":"Principle","section":"World-Class Analysis System - What We're Actually Building > The Vision","confidence":0.9}
{"type":"Fact","question":"What is the outcome of employing the World-Class Analysis System?","answer":"The system shows clear evidence of outcomes being achieved from the stories analyzed.","context":"This demonstrates the impact and success of the projects using this analysis system.","document":"World-Class Analysis System - What We're Actually Building","category":"Principle","section":"World-Class Analysis System - What We're Actually Building > The Vision","confidence":0.9}
{"type":"Principle","question":"What is required for proper security in the Context System API?","answer":"Proper authentication and authorization are necessary, including role verification for admin and project manager roles.","context":"This ensures that only authorized users can access and manage the API functionalities.","document":"Context System API Implementation Complete (Week 2)","category":"Principle","section":"Context System API Implementation Complete (Week 2) > Overview","confidence":0.9}
{"type":"Principle","question":"What type of checks are performed for user access in the API?","answer":"RLS-style checks are performed to ensure that users have the correct permissions to access specific resources.","context":"RLS stands for Row-Level Security, which helps maintain user privacy and data protection.","document":"Context System API Implementation Complete (Week 2)","category":"Principle","section":"Context System API Implementation Complete (Week 2) > Overview","confidence":0.8}
{"type":"Principle","question":"What should be implemented for error handling in CRUD operations?","answer":"Proper error handling must be integrated into all CRUD operations to manage exceptions and ensure smooth operation.","context":"CRUD stands for Create, Read, Update, Delete, which are the fundamental operations for managing data.","document":"Context System API Implementation Complete (Week 2)","category":"Principle","section":"Context System API Implementation Complete (Week 2) > Overview","confidence":0.85}
{"type":"Principle","question":"How does the API leverage AI in its functions?","answer":"The API uses AI extraction through a universal LLM client, such as Ollama or OpenAI, enhancing data interaction capabilities.","context":"This integration enables more robust processing of data inputs and interactions.","document":"Context System API Implementation Complete (Week 2)","category":"Principle","section":"Context System API Implementation Complete (Week 2) > Overview","confidence":0.9}
{"type":"Procedure","question":"What are the steps to deploy the Database for the Storyteller Analytics System?","answer":"1. Open the Supabase SQL Editor by navigating to the provided URL. 2. Copy the entire content from the file 'COMBINED_STORYTELLER_ANALYTICS_MIGRATION.sql'. 3. Paste the copied content into the SQL Editor. 4. Click 'Run' and wait for a 'Success' message to confirm deployment.","context":"This procedure outlines the initial step required to deploy the database for the Storyteller Analytics System.","document":"ðŸš€ Launch Your Storyteller Analytics System!","category":"Principle","section":"ðŸš€ Launch Your Storyteller Analytics System! > ðŸŽ¯ **Quick Launch Checklist** > **Step 1: Deploy Database (5 minutes)**","confidence":0.95}
{"type":"Principle","question":"What was the problem solved by the project regarding the Impact Framework?","answer":"The project addressed the issue that a generic 'Impact Framework' was not suitable for all types of initiatives, particularly those like Goods which focus on manufacturing appliances such as beds, fridges, and washing machines, as Indigenous metrics like Cultural Continuity and Relationship Strengthening may not be applicable.","context":null,"document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.9}
{"type":"Fact","question":"What is the core framework used in the Empathy Ledger platform?","answer":"The core framework used in the Empathy Ledger platform includes Next.js 14.2+ with App Router, React 18+ supporting both Server Components and Client Components, and TypeScript 5+ in strict mode.","context":"This framework setup ensures a modern and efficient development environment.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **Framework Stack**","confidence":0.9}
{"type":"Fact","question":"What styling and UI libraries are utilized in the Empathy Ledger platform?","answer":"The styling and UI libraries utilized include Tailwind CSS 3+ for utility-first CSS, shadcn/ui as a component library, Radix UI for headless component primitives, and Lucide React for the icon system.","context":"These libraries enhance the visual design and user experience of the platform.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **Framework Stack**","confidence":0.9}
{"type":"Fact","question":"What backend technologies does the Empathy Ledger platform integrate with?","answer":"The Empathy Ledger platform integrates with Supabase, which provides a PostgreSQL database, authentication, and real-time capabilities.","context":"These backend integration technologies support robust data handling and user management.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **Framework Stack**","confidence":0.9}
{"type":"Principle","question":"What is the focus of the analytics architecture in the Empathy Ledger platform?","answer":"The analytics architecture is centered around beautiful visual storytelling impact dashboards that enhance the narrative experience and provide insights.","context":"The architecture aims to prioritize the storyteller's perspective and the impact of their narratives.","document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸ“Š Executive Summary","confidence":0.9}
{"type":"Method","question":"How does the Empathy Ledger facilitate connections between storytellers?","answer":"The platform uses AI-powered network discovery to connect storytellers, enhancing collaboration and sharing of stories.","context":"This method aims to create a more integrated storytelling community.","document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸ“Š Executive Summary","confidence":0.85}
{"type":"Practice","question":"What is the purpose of the theme intelligence feature?","answer":"Theme intelligence provides cross-narrative analysis and insights, allowing for deeper understanding and connections between different stories.","context":"This practice helps in identifying overarching themes and patterns in storytelling.","document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸ“Š Executive Summary","confidence":0.9}
{"type":"Practice","question":"What functionality does the quote mining feature provide?","answer":"The quote mining feature allows for the extraction of powerful and quotable moments from narratives, highlighting significant expressions within the stories.","context":"This facilitates the preservation of impactful storytelling elements.","document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸ“Š Executive Summary","confidence":0.85}
{"type":"Method","question":"What role does the recommendation engine play in the platform?","answer":"The recommendation engine suggests connections within a smart storyteller network, enhancing user experience by tailoring recommendations based on interactions and interests.","context":"This method fosters engagement by introducing users to relevant storytellers.","document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸ“Š Executive Summary","confidence":0.8}
{"type":"Fact","question":"What does the COMPLETE_MEDIA_INTEGRATION_GUIDE.md cover?","answer":"The COMPLETE_MEDIA_INTEGRATION_GUIDE.md is a complete guide for media system integration.","context":null,"document":"Deployment Guides","category":"Principle","section":"Deployment Guides > Files","confidence":1}
{"type":"Fact","question":"What is the purpose of the ORGANIZATION_DASHBOARD_ROUTES_GUIDE.md?","answer":"The ORGANIZATION_DASHBOARD_ROUTES_GUIDE.md serves as a guide for organization dashboard routing.","context":null,"document":"Deployment Guides","category":"Principle","section":"Deployment Guides > Files","confidence":1}
{"type":"Fact","question":"What information can be found in the ORGANIZATION_DESIGN_SYSTEM_REFERENCE.md?","answer":"The ORGANIZATION_DESIGN_SYSTEM_REFERENCE.md provides design system reference for organizations.","context":null,"document":"Deployment Guides","category":"Principle","section":"Deployment Guides > Files","confidence":1}
{"type":"Fact","question":"How many user profiles are associated with valid tenants in the Junction Tables Analysis Report?","answer":"There are 19 user profiles with valid tenant associations.","context":"This information helps understand the user base connected to the platform.","document":"Junction Tables Analysis Report","category":"Principle","section":"Junction Tables Analysis Report > Problem Summary","confidence":1}
{"type":"Fact","question":"What is the number of organizations with projects mentioned in the Junction Tables Analysis Report?","answer":"There are 19 organizations with projects.","context":"This statistic indicates the engagement level of organizations with the platform.","document":"Junction Tables Analysis Report","category":"Principle","section":"Junction Tables Analysis Report > Problem Summary","confidence":1}
{"type":"Fact","question":"How many projects are identified in the Junction Tables Analysis Report?","answer":"There are 24 projects across various organizations.","context":"Understanding the number of projects is crucial for assessing overall activity and relevance.","document":"Junction Tables Analysis Report","category":"Principle","section":"Junction Tables Analysis Report > Problem Summary","confidence":1}
{"type":"Principle","question":"What kind of relationships are highlighted in the Junction Tables Analysis Report?","answer":"The report highlights clear tenant-based relationships that should connect profiles to organizations and projects.","context":"This principle underscores the importance of connectivity within the platform for enhanced collaboration.","document":"Junction Tables Analysis Report","category":"Principle","section":"Junction Tables Analysis Report > Problem Summary","confidence":1}
{"type":"Procedure","question":"What elements are included in the Transcript List UI?","answer":"The Transcript List UI includes the interviewer's name, transcript status, duration, word count, date, and action buttons for 'View', 'Edit', 'Create Story', and 'Delete'.","context":"This information pertains to the visual layout and components present in the current UI for transcripts.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Current UI (What you see now)","confidence":0.9}
{"type":"Practice","question":"How should I use the action buttons in the Transcript List UI?","answer":"'View' allows you to see the transcript details, 'Edit' lets you modify the transcript, 'Create Story' initiates the process of using the transcript content for storytelling, and 'Delete' removes the transcript from the list.","context":"Understanding the functionalities of the action buttons helps users efficiently navigate and manage the transcript list.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Current UI (What you see now)","confidence":0.8}
{"type":"Fact","question":"What information can I find regarding each transcript in the Transcript List UI?","answer":"Each transcript in the Transcript List UI displays the interviewer's name, current status (e.g., pending), duration of the audio, total word count, and the date of the transcript creation.","context":"This fact provides detailed insights into what users can expect when viewing transcript entries.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Current UI (What you see now)","confidence":0.85}
{"type":"Fact","question":"What components are available for transcript handling in the Empathy Ledger platform?","answer":"The Empathy Ledger platform includes a stories table with a 'story_transcript' field for text, admin transcript pages UI accessible at '/admin/transcripts', and a media assets table for audio files. However, there is no dedicated transcripts table and no direct upload UI for transcripts.","context":"This information pertains to the current state of transcript management within the platform.","document":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way","category":"Procedure","section":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way > Current Situation Analysis > What We Have:","confidence":0.9}
{"type":"Practice","question":"How can transcripts be accessed in the Empathy Ledger?","answer":"Transcripts can be accessed through the admin transcript pages UI, which can be found at the URL '/admin/transcripts'. The transcripts are stored within the stories table using the 'story_transcript' field.","context":"Accessing transcripts is done through a designated admin page that allows management of transcript data.","document":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way","category":"Procedure","section":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way > Current Situation Analysis > What We Have:","confidence":0.85}
{"type":"Fact","question":"What is the current integration status of the Ollama project?","answer":"As of October 11, 2025, the Ollama integration is 95% completed.","context":"This status indicates that significant progress has been made on the integration process.","document":"Ollama Integration Status - October 11, 2025","category":"Principle","section":"Ollama Integration Status - October 11, 2025 > âœ… COMPLETED (95%) > 1. All AI Modules Refactored to Use LLM Client","confidence":1}
{"type":"Practice","question":"What does the 95% completion of the Ollama integration signify?","answer":"The 95% completion suggests that all AI modules have been successfully refactored to use the LLM client, which is a critical step in the integration process.","context":"Refactoring AI modules is essential for ensuring they function efficiently within the new system.","document":"Ollama Integration Status - October 11, 2025","category":"Principle","section":"Ollama Integration Status - October 11, 2025 > âœ… COMPLETED (95%) > 1. All AI Modules Refactored to Use LLM Client","confidence":0.9}
{"type":"Warning","question":"What is a critical issue with the AI analysis system in the GOODS project?","answer":"The AI analysis system is generating fake quotes that do not exist in the actual transcripts, leading to entirely fabricated quotes attributed to storytellers.","context":"This issue raises significant concerns regarding the integrity and reliability of the project outcomes.","document":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis","category":"Practice","section":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis > The Problem","confidence":0.95}
{"type":"Warning","question":"What are common indicators of poor quality quotes in AI extraction?","answer":"Common indicators of poor quality quotes include incomplete thoughts, excessive disfluencies (such as 'um', 'uh', 'yeah'), and reliance on superficial metrics like sentence length to determine confidence scores, rather than actual content quality.","context":"Identifying these poor quality indicators is crucial for improving the accuracy of AI quote extractions.","document":"AI Quote Extraction Quality Comparison","category":"Principle","section":"AI Quote Extraction Quality Comparison > Problem Identified > Examples of Poor Quality Quotes (Old Method):","confidence":0.9}
{"type":"Fact","question":"What are examples of poor quality quotes extracted using the old method?","answer":"Examples include fragmented quotes such as 'knowledge.', 'hard.', and 'different people.', which do not convey complete thoughts. Additionally, quotes may include non-informative disfluencies like 'um', 'uh', and 'yeah', and may present artificially high confidence scores based on irrelevant metrics.","context":"These examples illustrate the shortcomings of previous AI methods in quote extraction.","document":"AI Quote Extraction Quality Comparison","category":"Principle","section":"AI Quote Extraction Quality Comparison > Problem Identified > Examples of Poor Quality Quotes (Old Method):","confidence":0.95}
{"type":"Principle","question":"What themes do Oonchiumpa storytellers explore in their narratives?","answer":"The Oonchiumpa storytellers explore themes of cultural identity, intergenerational knowledge, and community resilience through their narratives, highlighting the connection to land, culture, and community among Indigenous Australians.","context":null,"document":"Oonchiumpa Storytellers - Insights Report","category":"Practice","section":"Oonchiumpa Storytellers - Insights Report > Executive Summary","confidence":0.9}
{"type":"Fact","question":"What are the main subjects discussed by Oonchiumpa storytellers?","answer":"The main subjects discussed include cultural heritage, challenges faced by Indigenous communities, and the ongoing struggle for justice and empowerment.","context":null,"document":"Oonchiumpa Storytellers - Insights Report","category":"Practice","section":"Oonchiumpa Storytellers - Insights Report > Executive Summary","confidence":0.85}
{"type":"Practice","question":"How do the Oonchiumpa storytellers contribute to understanding Indigenous experiences?","answer":"The Oonchiumpa storytellers enrich the collective understanding of Indigenous experiences and aspirations by bringing unique perspectives through their narratives.","context":null,"document":"Oonchiumpa Storytellers - Insights Report","category":"Practice","section":"Oonchiumpa Storytellers - Insights Report > Executive Summary","confidence":0.9}
{"type":"Practice","question":"What is the quality scoring system used in the Intelligent Quote Extractor?","answer":"The Intelligent Quote Extractor utilizes a real quality scoring system that avoids misleading scores, providing accurate evaluations of 60-95% quality based on clear criteria.","context":"This scoring system aims to ensure that users receive genuine and reliable quality metrics.","document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 1. **Intelligent Quote Extractor** âœ…","confidence":0.9}
{"type":"Practice","question":"What type of content does the Intelligent Quote Extractor focus on?","answer":"The Intelligent Quote Extractor focuses on extracting complete thoughts, ensuring that the quotes do not contain disjointed or fragmentary phrases like 'um, uh, yeah'.","context":"This approach helps maintain the quality and readability of the extracted content.","document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 1. **Intelligent Quote Extractor** âœ…","confidence":0.85}
{"type":"Fact","question":"What was the average quality score achieved by the Intelligent Quote Extractor in the Goods project?","answer":"The Intelligent Quote Extractor achieved an average quality score of 83.4 out of 100 in the Goods project.","context":"This score reflects the effectiveness and reliability of the extraction process.","document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 1. **Intelligent Quote Extractor** âœ…","confidence":0.95}
{"type":"Fact","question":"What does the DEVELOPMENT_OPTIONS_ANALYSIS.md file contain?","answer":"The DEVELOPMENT_OPTIONS_ANALYSIS.md file contains an analysis of development approach options for the Empathy Ledger platform.","context":null,"document":"Legacy Reports & Analysis","category":"Principle","section":"Legacy Reports & Analysis > Files","confidence":0.9}
{"type":"Fact","question":"What is covered in the EMPATHY_LEDGER_SCHEMA_ANALYSIS.md file?","answer":"The EMPATHY_LEDGER_SCHEMA_ANALYSIS.md file includes a database schema analysis for the Empathy Ledger.","context":null,"document":"Legacy Reports & Analysis","category":"Principle","section":"Legacy Reports & Analysis > Files","confidence":0.9}
{"type":"Fact","question":"What type of information can be found in the INDIVIDUAL_ANALYTICS_ACTIVATION_SUCCESS.md?","answer":"The INDIVIDUAL_ANALYTICS_ACTIVATION_SUCCESS.md file contains a report on the activation success of the analytics system.","context":null,"document":"Legacy Reports & Analysis","category":"Principle","section":"Legacy Reports & Analysis > Files","confidence":0.9}
{"type":"Fact","question":"What does the NEXT_STEPS_MULTI_TENANT_PLAN.md document address?","answer":"The NEXT_STEPS_MULTI_TENANT_PLAN.md document outlines the multi-tenant planning for the Empathy Ledger platform.","context":null,"document":"Legacy Reports & Analysis","category":"Principle","section":"Legacy Reports & Analysis > Files","confidence":0.9}
{"type":"Fact","question":"What is detailed in the RLS_DEPLOYMENT_REPORT.md?","answer":"The RLS_DEPLOYMENT_REPORT.md provides a report on the Row Level Security deployment for the Empathy Ledger.","context":null,"document":"Legacy Reports & Analysis","category":"Principle","section":"Legacy Reports & Analysis > Files","confidence":0.9}
{"type":"Practice","question":"What files should be included in the root directory of a project on the Empathy Ledger platform?","answer":"The root directory should include the following files: README.md for project overview, CLAUDE.md for AI assistant context, next.config.js for Next.js configuration, package.json for dependencies and scripts, tsconfig.json for TypeScript configuration, and .env.local for environment variables.","context":"These files help maintain organized project structure and provide essential configuration details.","document":"File Organization Guide","category":"Principle","section":"File Organization Guide > ðŸ“ Project Structure > Root Directory (Clean)","confidence":1}
{"type":"Warning","question":"What are some methods to avoid when analyzing transcripts in the backend integration plan?","answer":"Avoid using keyword matching to extract impact insights, as it may lead to inaccuracies. Additionally, calculating dimensions via arbitrary scores is not recommended due to potential misrepresentation of data. Using regex patterns for story element extraction is also discouraged, and extracting powerful quotes from fake insights can lead to misleading conclusions.","context":"This information is part of the backend integration plan for analyzing project transcripts.","document":"Backend Integration Plan - Intelligent AI Systems","category":"Principle","section":"Backend Integration Plan - Intelligent AI Systems > Current Flow (746 lines - OLD)","confidence":0.9}
{"type":"Practice","question":"How is the backend integration for the Project Outcomes Tracker implemented?","answer":"The backend integration for the Project Outcomes Tracker has been completed by integrating the functionality into `/src/app/api/projects/[id]/analysis/route.ts`. Specifically, it includes calling the `analyzeProjectOutcomes()` function when the context exists, and it adds `projectOutcomes` to the `aggregatedInsights` object, which returns project-specific outcomes in the API response.","context":"Details of implementation for backend integration.","document":"Project Outcomes Tracker - Implementation Status","category":"Principle","section":"Project Outcomes Tracker - Implementation Status > âœ… **COMPLETED:** > 1. **Backend Integration**","confidence":0.9}
{"type":"Principle","question":"What is the primary method for associating storytellers with organizations in the Organization Membership System?","answer":"The primary method for associating storytellers with organizations in the Organization Membership System is through the use of a unique `tenant_id` for each organization. Profiles that are connected to that organization share the same `tenant_id`, and the profiles include a `tenant_roles` array that specifies their role, which can include the role of 'storyteller'.","context":"This method ensures that storytellers are appropriately linked to their respective organizations through a tenant-based system.","document":"Organization Membership System - Architecture & Usage Guide","category":"Principle","section":"Organization Membership System - Architecture & Usage Guide > System Architecture Overview > 1. Primary System: Tenant-Based (tenant_id + tenant_roles)","confidence":0.9}
{"type":"Fact","question":"How is the organization identified in the profiles of the tenants?","answer":"Each organization is identified in the profiles of the tenants by a unique identifier called `tenant_id`. This `tenant_id` is consistent across all profiles connected to that organization.","context":"The identification system helps maintain a clear relationship between storytellers and their respective organizations.","document":"Organization Membership System - Architecture & Usage Guide","category":"Principle","section":"Organization Membership System - Architecture & Usage Guide > System Architecture Overview > 1. Primary System: Tenant-Based (tenant_id + tenant_roles)","confidence":0.85}
{"type":"Method","question":"How does the tenant roles array function in the Organization Membership System?","answer":"The `tenant_roles` array functions as a designation of the roles associated with a profile within a specific organization. For instance, a profile that aims to fulfill the role of 'storyteller' will have this role listed in their `tenant_roles` array, which helps to classify the member's purpose within the organization.","context":"This structure facilitates role management and ensures that members are recognized appropriately within their respective organizations.","document":"Organization Membership System - Architecture & Usage Guide","category":"Principle","section":"Organization Membership System - Architecture & Usage Guide > System Architecture Overview > 1. Primary System: Tenant-Based (tenant_id + tenant_roles)","confidence":0.8}
{"type":"Principle","question":"What is the purpose of the Empathy Ledger platform?","answer":"The Empathy Ledger serves as a revolutionary digital storytelling ecosystem that transforms how communities preserve, share, and celebrate human experiences. It aims to foster authentic community building, cultural preservation, and achieve meaningful social impact through personal narratives.","context":"This summary highlights the overarching goals and values of the Empathy Ledger platform.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary","confidence":0.9}
{"type":"Practice","question":"What improvements were made to the Tailwind configuration for the Empathy Ledger platform?","answer":"A comprehensive `tailwind.config.ts` was created with a custom theme to enhance the styling of the platform.","context":"This improvement aims to provide a more cohesive design tailored to the platform's branding.","document":"ðŸ” Site Audit Report - Empathy Ledger Platform","category":"Principle","section":"ðŸ” Site Audit Report - Empathy Ledger Platform > Executive Summary > âœ… Completed Improvements","confidence":0.9}
{"type":"Practice","question":"How was the CSS system improved for the Empathy Ledger platform?","answer":"The `globals.css` file was rebuilt to support proper dark mode and include utility classes, improving the overall user interface and accessibility.","context":"These changes are important for enhancing the usability of the platform in various lighting conditions.","document":"ðŸ” Site Audit Report - Empathy Ledger Platform","category":"Principle","section":"ðŸ” Site Audit Report - Empathy Ledger Platform > Executive Summary > âœ… Completed Improvements","confidence":0.9}
{"type":"Practice","question":"What new components were added to the Empathy Ledger platform?","answer":"New components such as DatePicker and Calendar were added to enhance the platform's functionality.","context":"These components are essential for managing dates and events within the storytelling context.","document":"ðŸ” Site Audit Report - Empathy Ledger Platform","category":"Principle","section":"ðŸ” Site Audit Report - Empathy Ledger Platform > Executive Summary > âœ… Completed Improvements","confidence":0.9}
{"type":"Practice","question":"What was done to improve route configuration in the Empathy Ledger platform?","answer":"A centralized route configuration was created at `/src/lib/config/routes.ts`, streamlining the routing process across the platform.","context":"Centralized routing helps maintain organization and improve navigation within the application.","document":"ðŸ” Site Audit Report - Empathy Ledger Platform","category":"Principle","section":"ðŸ” Site Audit Report - Empathy Ledger Platform > Executive Summary > âœ… Completed Improvements","confidence":0.9}
{"type":"Practice","question":"What are the main features of the Storyteller Analytics System?","answer":"The Storyteller Analytics System includes 12 specialized tables for analytics, vector search capabilities for semantic similarity, row level security to protect all data, advanced indexing for real-time performance, and AI integration points throughout the system.","context":"These features are part of the database architecture deployed for the analytics system.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸ“Š **Database Architecture Deployed**","confidence":0.9}
{"type":"Fact","question":"How many specialized tables are there in the Storyteller Analytics System?","answer":"There are 12 specialized tables designed for storyteller analytics in the Storyteller Analytics System.","context":"This is a key feature of the database architecture.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸ“Š **Database Architecture Deployed**","confidence":0.95}
{"type":"Practice","question":"What does the vector search capability in the Storyteller Analytics System enable?","answer":"The vector search capability enables semantic similarity searching, allowing users to find related content more effectively.","context":"This feature enhances the functionality of the analytics system by improving search accuracy.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸ“Š **Database Architecture Deployed**","confidence":0.85}
{"type":"Practice","question":"What is row level security in the context of the Storyteller Analytics System?","answer":"Row level security is a feature that protects all data by ensuring that users can only access the data they are authorized to view.","context":"This is crucial for maintaining the privacy and security of data in the analytics system.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸ“Š **Database Architecture Deployed**","confidence":0.9}
{"type":"Fact","question":"What data structure exists for locations in the system?","answer":"There is a locations table that contains structured data including city, state, country, and latitude/longitude.","context":null,"document":"Location & Relationships Audit","category":"Procedure","section":"Location & Relationships Audit > Executive Summary > Key Findings:","confidence":0.9}
{"type":"Fact","question":"What is the utilization rate of the locations table?","answer":"The utilization rate of the locations table is 0%, indicating that there are no foreign key relationships pointing to it.","context":null,"document":"Location & Relationships Audit","category":"Procedure","section":"Location & Relationships Audit > Executive Summary > Key Findings:","confidence":0.85}
{"type":"Warning","question":"What major gap exists in the stories regarding location data?","answer":"Stories in the system do not have a location field at all, which is a significant gap in data representation.","context":null,"document":"Location & Relationships Audit","category":"Procedure","section":"Location & Relationships Audit > Executive Summary > Key Findings:","confidence":0.9}
{"type":"Fact","question":"What is missing from transcripts in relation to location data?","answer":"Transcripts are missing foreign key relationships for story_id and location_id, which are essential for linking transcripts to their corresponding stories and locations.","context":null,"document":"Location & Relationships Audit","category":"Procedure","section":"Location & Relationships Audit > Executive Summary > Key Findings:","confidence":0.85}
{"type":"Practice","question":"How does the Project Outcomes Tracker extract outcomes from a project context?","answer":"The Project Outcomes Tracker extracts outcomes from a project context by utilizing specific seed interview questions, specifically Q2 and Q5, to identify relevant outcomes.","context":"This process ensures that the outcomes are directly linked to the context of the project being evaluated.","document":"Project Outcomes Tracker - Implementation Complete","category":"Practice","section":"Project Outcomes Tracker - Implementation Complete > **Solution: Project-Specific Outcomes From Seed Interview**","confidence":0.9}
{"type":"Practice","question":"What method does the Project Outcomes Tracker use to find evidence of outcomes?","answer":"The Project Outcomes Tracker searches through transcripts for evidence that supports the specific outcomes identified from the project context.","context":"This evidence collection is crucial for validating the outcomes and ensuring they are based on actual data.","document":"Project Outcomes Tracker - Implementation Complete","category":"Practice","section":"Project Outcomes Tracker - Implementation Complete > **Solution: Project-Specific Outcomes From Seed Interview**","confidence":0.9}
{"type":"Practice","question":"How does the Project Outcomes Tracker display relevant progress?","answer":"The tracker shows relevant progress by including quotes and contributions from storytellers, highlighting their experiences related to the specific outcomes.","context":"Utilizing quotes enriches the data and provides qualitative insights into the project's impact.","document":"Project Outcomes Tracker - Implementation Complete","category":"Practice","section":"Project Outcomes Tracker - Implementation Complete > **Solution: Project-Specific Outcomes From Seed Interview**","confidence":0.9}
{"type":"Practice","question":"What criteria does the Project Outcomes Tracker use to score outcomes?","answer":"The Project Outcomes Tracker scores outcomes based on the depth of evidence provided, rather than merely counting keywords.","context":"This approach focuses on the quality and relevance of evidence, enhancing the reliability of the scoring process.","document":"Project Outcomes Tracker - Implementation Complete","category":"Practice","section":"Project Outcomes Tracker - Implementation Complete > **Solution: Project-Specific Outcomes From Seed Interview**","confidence":0.9}
{"type":"Procedure","question":"What are the steps to analyze an interview transcript in the Empathy Ledger platform?","answer":"To analyze an interview transcript, locate the transcript in the Transcript List UI, select the 'Analyze' option, and review the AI-generated summary and key quotes associated with the transcript. This will provide insights into the themes and quotes that highlight important aspects of the conversation.","context":"This process helps to identify cultural themes and preserve Indigenous knowledge through storytelling.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Proposed UI (With AI Analysis)","confidence":0.9}
{"type":"Fact","question":"What type of information can be found in the AI-generated summary of an interview transcript?","answer":"The AI-generated summary provides an overview of the subject matter discussed in the interview, highlighting key themes such as cultural preservation, sustainable tourism, and Indigenous technology, as well as collaborative efforts in community knowledge sharing.","context":"This information is crucial for understanding the broader context of the stories shared by community members.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Proposed UI (With AI Analysis)","confidence":0.95}
{"type":"Fact","question":"What themes are highlighted in the transcript UI examples?","answer":"The themes highlighted in the transcript UI examples include Cultural Preservation, Sustainable Tourism, Indigenous Technology, and Community Leadership.","context":"These themes reflect the focus areas of the discussions held in the interview transcripts.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Proposed UI (With AI Analysis)","confidence":0.9}
{"type":"Fact","question":"What is the purpose of key quotes included in the interview transcripts?","answer":"Key quotes are included to encapsulate essential insights and perspectives expressed by the interviewees, emphasizing the impact and themes of their narratives.","context":"These quotes help to frame the discussions within a cultural and community context.","document":"Transcript List UI - With Themes & Quotes","category":"Procedure","section":"Transcript List UI - With Themes & Quotes > Proposed UI (With AI Analysis)","confidence":0.85}
{"type":"Fact","question":"What are the deliverables for Sprint 1 of the Empathy Ledger v2?","answer":"The deliverables for Sprint 1 are profile display, privacy settings, and the ALMA panel.","context":"This refers to the foundational features to be developed in the first sprint.","document":"Empathy Ledger v2 - Detailed Sprint Plan","category":"Practice","section":"Empathy Ledger v2 - Detailed Sprint Plan > Sprint Overview","confidence":1}
{"type":"Fact","question":"What is the theme for Sprint 4 in the Empathy Ledger v2 detailed sprint plan?","answer":"The theme for Sprint 4 is Search & Discovery.","context":"This sprint focuses on implementing features that enhance user search capabilities.","document":"Empathy Ledger v2 - Detailed Sprint Plan","category":"Practice","section":"Empathy Ledger v2 - Detailed Sprint Plan > Sprint Overview","confidence":1}
{"type":"Procedure","question":"What is the flow of data when a user selects an organization from the dropdown?","answer":"When a user selects 'Oonchiumpa' from the dropdown, the OrganizationSelector component triggers an onChange event with the selected orgId. This updates the OrganizationContext with the new selectedOrgId. The AdminDashboard component detects this change using useEffect, which triggers a refetch of the data. An API call is made to retrieve organization-specific stats based on the selectedOrgId. If 'all' is selected, a different endpoint is called. After processing the request, the database is queried with an organization_id filter to gather the relevant statistics, which updates the UI to show the selected organization's data.","context":"Describes the step-by-step process of selecting an organization and updating the dashboard.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > Data Flow: Organization Selection","confidence":0.9}
{"type":"Fact","question":"What API endpoints are used to fetch organization-specific statistics?","answer":"The API call depends on the selectedOrgId: if it is 'all', the endpoint is GET /api/admin/stats/platform; otherwise, it is GET /api/admin/organizations/{orgId}/stats.","context":"Information on API endpoints for data fetching based on the organization selection.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > Data Flow: Organization Selection","confidence":0.9}
{"type":"Process","question":"What happens in the AdminDashboard component when the organization is changed?","answer":"In the AdminDashboard component, when the selectedOrgId changes, the useEffect hook is triggered, initiating a new data fetch for the organization-specific stats based on the updated orgId.","context":"Explains the reactive behavior of the AdminDashboard component regarding changes in organization selection.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > Data Flow: Organization Selection","confidence":0.85}
{"type":"Fact","question":"What was successfully implemented in the Empathy Ledger platform?","answer":"Complete multi-tenant data isolation was successfully implemented in the Empathy Ledger platform.","context":"This implementation ensures that data is properly segregated by organization.","document":"Multi-Tenant Implementation Complete âœ…","category":"Principle","section":"Multi-Tenant Implementation Complete âœ… > Summary","confidence":1}
{"type":"Warning","question":"What critical bug was addressed by the multi-tenant implementation in Empathy Ledger?","answer":"The critical bug where organizations could see each other's data was addressed by the multi-tenant implementation.","context":"This bug posed a significant risk to data privacy among different organizations using the platform.","document":"Multi-Tenant Implementation Complete âœ…","category":"Principle","section":"Multi-Tenant Implementation Complete âœ… > Summary","confidence":1}
{"type":"Fact","question":"What is the current deployment status of the Empathy Ledger platform?","answer":"The Empathy Ledger cultural storytelling platform is currently PARTIALLY DEPLOYED.","context":"This status indicates that while essential features have been implemented, the platform is not fully operational.","document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Platform Status: **PARTIALLY DEPLOYED** âš ï¸","confidence":0.9}
{"type":"Warning","question":"What are the critical issues identified in the Empathy Ledger platform?","answer":"The platform has critical security gaps and missing components that hinder its full functionality.","context":"These issues must be addressed to ensure a secure and functional storytelling experience for users.","document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Platform Status: **PARTIALLY DEPLOYED** âš ï¸","confidence":0.9}
{"type":"Fact","question":"What does the platform's solid foundation refer to?","answer":"The solid foundation of the Empathy Ledger platform refers to its significant data and core functionality that have already been deployed.","context":"This indicates that while the platform is not fully operational, essential elements are in place.","document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Platform Status: **PARTIALLY DEPLOYED** âš ï¸","confidence":0.85}
{"type":"Practice","question":"What technology stack is the Empathy Ledger platform built on?","answer":"The platform uses Next.js version 15.5.2 with a cutting-edge architecture.","context":null,"document":"Empathy Ledger Platform - Comprehensive Implementation Plan","category":"Practice","section":"Empathy Ledger Platform - Comprehensive Implementation Plan > ðŸŽ¯ Executive Summary > Platform Vision","confidence":0.95}
{"type":"Practice","question":"What kind of architecture does the Empathy Ledger platform use?","answer":"The platform is built on a multi-tenant architecture that supports unlimited growth.","context":null,"document":"Empathy Ledger Platform - Comprehensive Implementation Plan","category":"Practice","section":"Empathy Ledger Platform - Comprehensive Implementation Plan > ðŸŽ¯ Executive Summary > Platform Vision","confidence":0.95}
{"type":"Practice","question":"What information is stored in the profiles table of the Empathy Ledger platform?","answer":"The profiles table includes the following information: basic info such as name, email, bio, and cultural background; flags indicating if the user is a storyteller, elder, or featured; visibility status which can be public, private, draft, etc.; tenant ID for multi-tenancy; and relationships to organizations, projects, and locations.","context":"This data structure is foundational for user profiles on the Empathy Ledger platform.","document":"Empathy Ledger Platform Architecture","category":"Practice","section":"Empathy Ledger Platform Architecture > Core Data Model > 1. **Profiles** (The Foundation)","confidence":0.95}
{"type":"Practice","question":"How is multi-tenancy represented in the profiles table of the Empathy Ledger?","answer":"Multi-tenancy is represented in the profiles table through the tenant_id field, which associates each profile with a specific tenant.","context":"This allows the platform to support multiple independent user bases while sharing the same technological infrastructure.","document":"Empathy Ledger Platform Architecture","category":"Practice","section":"Empathy Ledger Platform Architecture > Core Data Model > 1. **Profiles** (The Foundation)","confidence":0.9}
{"type":"Practice","question":"What are the flags used in the profiles table, and what do they indicate?","answer":"The flags in the profiles table include is_storyteller, is_elder, and is_featured. These flags indicate the role of the user within the platform (whether they are a storyteller or elder) and highlight featured users.","context":"These flags help in identifying user roles and enhancing visibility within the platform.","document":"Empathy Ledger Platform Architecture","category":"Practice","section":"Empathy Ledger Platform Architecture > Core Data Model > 1. **Profiles** (The Foundation)","confidence":0.92}
{"type":"Principle","question":"What is the role of building connections in the Empathy Ledger?","answer":"Building connections involves discovering thematic links across stories and storytellers, fostering a deeper understanding of shared experiences and cultural narratives.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.8}
{"type":"Principle","question":"How does the Empathy Ledger demonstrate its impact?","answer":"The Empathy Ledger demonstrates its impact by tracking real-world outcomes and the value that the community derives from the storytelling initiatives.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.8}
{"type":"Principle","question":"Why is preserving knowledge important for the Empathy Ledger?","answer":"Preserving knowledge is vital for ensuring multi-generational storytelling and archival, allowing future generations to inherit and learn from past narratives.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.8}
{"type":"Fact","question":"What priority level is assigned to Sprint 2 in the Empathy Ledger v2?","answer":"Sprint 2 is assigned a priority level of P0.","context":"P0 indicates the highest priority for the delivery of essential components for the storyteller dashboard.","document":"Empathy Ledger v2 - Detailed Sprint Plan","category":"Practice","section":"Empathy Ledger v2 - Detailed Sprint Plan > Sprint Overview","confidence":1}
{"type":"Fact","question":"What are the key deliverables planned for the final Sprint 8 of the Empathy Ledger v2?","answer":"The key deliverables for Sprint 8 include security audit, performance improvements, training, and the launch of the platform.","context":"This sprint is the culmination of the development process, focusing on readiness for release.","document":"Empathy Ledger v2 - Detailed Sprint Plan","category":"Practice","section":"Empathy Ledger v2 - Detailed Sprint Plan > Sprint Overview","confidence":1}
{"type":"Practice","question":"What are the key features of the Enhanced Storyteller Cards related to organization and project tagging?","answer":"The Enhanced Storyteller Cards include several key features for organization and project tagging: color-coded affiliations to indicate the type of organization (tribal, nonprofit, community, government), status indicators to reflect the project's current state (active, completed, planning, paused), role details that are displayed when viewing an expanded card, and a smart overflow function that allows users to click 'show more' to reveal additional information.","context":"These features enhance the usability and organization of storytelling content on the Empathy Ledger platform.","document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ¢ Organization & Project Tagging","confidence":0.9}
{"type":"Practice","question":"What was the issue with the Quick Add API regarding database constraints?","answer":"The Quick Add API was not including all required fields when creating database records, resulting in a mismatch between TypeScript types, which showed many fields as optional, and the actual database constraints, which enforced NOT NULL and CHECK constraints.","context":"This issue highlights the importance of ensuring that API field definitions align with database constraints to prevent data integrity errors.","document":"Quick Add Complete Fix - All Database Constraints Resolved","category":"Principle","section":"Quick Add Complete Fix - All Database Constraints Resolved > Root Cause","confidence":0.9}
{"type":"Warning","question":"What should developers be cautious of when working with the Quick Add API?","answer":"Developers should be cautious of the discrepancies between TypeScript optional fields and the actual database constraints, as this can lead to errors when attempting to create database records without necessary fields.","context":"Maintaining consistency between API implementations and database requirements is crucial to avoid runtime errors.","document":"Quick Add Complete Fix - All Database Constraints Resolved","category":"Principle","section":"Quick Add Complete Fix - All Database Constraints Resolved > Root Cause","confidence":0.8}
{"type":"Practice","question":"What files were created for the project outcomes tracker?","answer":"The project outcomes tracker involved the creation of two files: `src/lib/ai/project-outcomes-tracker.ts`, which extracts outcomes from the seed interview, and `src/components/projects/ProjectOutcomesView.tsx`, which is a UI component for displaying the outcomes.","context":"These components are part of the backend and frontend implementations of the project outcomes tracker.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.9}
{"type":"Practice","question":"How is the project outcomes tracker integrated into the API?","answer":"The project outcomes tracker is integrated into the API through the route `/api/projects/[id]/analysis`. This integration allows the outcomes to be part of the project's analysis response.","context":"This integration is specified by modifications made in the code between lines 388-408 and 480.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.85}
{"type":"Practice","question":"What happens if there is no seed interview context for a project?","answer":"If there is no seed interview context for a project, the system falls back to using the Impact Framework to provide project outcomes.","context":"This ensures that even projects lacking seed interview information have some form of outcome representation.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.8}
{"type":"Practice","question":"What UI updates were made in the ProjectAnalysisView?","answer":"The ProjectAnalysisView was updated to show a 'Project Outcomes' tab whenever outcomes are available for the project.","context":"This UI enhancement improves the visual representation of project outcomes within the analysis view.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.85}
{"type":"Fact","question":"What are the key fields in the profiles table for JusticeHub integration?","answer":"The key fields in the profiles table for JusticeHub integration are: `justicehub_enabled` (boolean - controls if the profile appears on JusticeHub), `justicehub_role` (text - indicates the role which can be one of founder, leader, advocate, practitioner, researcher, lived-experience, community-member), `justicehub_featured` (boolean - indicates if the profile should be shown prominently on JusticeHub), and `justicehub_synced_at` (timestamptz - records the last sync timestamp).","context":"The section outlines the structure of the profiles table relevant to integrating with JusticeHub.","document":"JusticeHub Integration - Setup Complete","category":"Principle","section":"JusticeHub Integration - Setup Complete > âœ… What's Been Done > 1. Database Migration Created","confidence":0.9}
{"type":"Principle","question":"What is the purpose of the `justicehub_enabled` field in the profiles table?","answer":"The `justicehub_enabled` field in the profiles table determines whether a user's profile is displayed on JusticeHub, thereby controlling their visibility within the platform.","context":"This principle is related to user control and visibility in the JusticeHub integration.","document":"JusticeHub Integration - Setup Complete","category":"Principle","section":"JusticeHub Integration - Setup Complete > âœ… What's Been Done > 1. Database Migration Created","confidence":0.8}
{"type":"Fact","question":"What are the possible values for the `justicehub_role` field?","answer":"The possible values for the `justicehub_role` field are founder, leader, advocate, practitioner, researcher, lived-experience, and community-member.","context":"This field categorizes the type of user engaging with JusticeHub.","document":"JusticeHub Integration - Setup Complete","category":"Principle","section":"JusticeHub Integration - Setup Complete > âœ… What's Been Done > 1. Database Migration Created","confidence":0.9}
{"type":"Fact","question":"What does the `justicehub_featured` field indicate?","answer":"The `justicehub_featured` field indicates whether the profile should be shown prominently on JusticeHub, enhancing its visibility to other users.","context":"This fact is important for understanding how profiles are showcased within the JusticeHub platform.","document":"JusticeHub Integration - Setup Complete","category":"Principle","section":"JusticeHub Integration - Setup Complete > âœ… What's Been Done > 1. Database Migration Created","confidence":0.9}
{"type":"Fact","question":"What type of information is stored in the `justicehub_synced_at` field?","answer":"The `justicehub_synced_at` field stores the last sync timestamp, indicating when the profile was last synchronized with the JusticeHub.","context":"This information is crucial for maintaining up-to-date profiles within the JusticeHub integration.","document":"JusticeHub Integration - Setup Complete","category":"Principle","section":"JusticeHub Integration - Setup Complete > âœ… What's Been Done > 1. Database Migration Created","confidence":0.9}
{"type":"Warning","question":"What are common errors encountered when working with the Empathy Ledger database?","answer":"While trying to migrate the database, common errors include: 'Local not running, unclear how to start' when attempting local migrations, 'Connection issues, unclear credentials' for remote connections, and 'Auth unclear, connection fails' when using SQL directly.","context":"These errors indicate potential misconfigurations or issues with setting up the local and remote database connections.","document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > Current Broken State âŒ","confidence":0.9}
{"type":"Fact","question":"How many migration files are present in the Empathy Ledger system?","answer":"There are 38 migration files located in the supabase/migrations directory, but it's unclear which of these files have been applied.","context":"These migration files are crucial for database updates and schema changes.","document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > Current Broken State âŒ","confidence":0.9}
{"type":"Principle","question":"What spelling conventions must be followed in the Empathy Ledger platform?","answer":"Always use Australian spelling in routes and URLs to ensure consistency both in the database and user-facing elements.","context":"In the Empathy Ledger platform, adhering to Australian spelling is critical for routes such as `/organisations` and `/api/organisations`.","document":"Spelling Guidelines - Empathy Ledger v2","category":"Principle","section":"Spelling Guidelines - Empathy Ledger v2 > ðŸš¨ Critical Rules - NEVER BREAK THESE > 1. **Routes & URLs**","confidence":0.9}
{"type":"Fact","question":"Can you provide examples of correct and incorrect URL spelling in the Empathy Ledger?","answer":"Correct examples include `/organisations/[id]/dashboard` and `/api/organisations/[id]/members`. An incorrect example would be `/organizations/[id]/dashboard`.","context":"Using the correct Australian spelling in URLs is essential for functionality and consistency.","document":"Spelling Guidelines - Empathy Ledger v2","category":"Principle","section":"Spelling Guidelines - Empathy Ledger v2 > ðŸš¨ Critical Rules - NEVER BREAK THESE > 1. **Routes & URLs**","confidence":0.95}
{"type":"Principle","question":"What are the key spelling conventions regarding -ise endings in the Empathy Ledger?","answer":"In the Empathy Ledger, -ise endings should be used instead of -ize. For example, the correct forms are `organise`, `recognise`, `realise`, `analyse`, `specialise`, and `categorise`, with their respective past and present participle forms being `organised`, `recognised`, `realised`, `analysed`, `specialised`, `categorised`, and their gerund forms being `organising`, `recognising`, `realising`, `analysing`, `specialising`, `categorising`. Note that `analysis` retains the -is spelling.","context":"This relates to the Australian spelling conventions followed by the Empathy Ledger.","document":"Australian Spelling Guide - Empathy Ledger v2","category":"Principle","section":"Australian Spelling Guide - Empathy Ledger v2 > Key Spelling Conventions > -ise endings (not -ize)","confidence":1}
{"type":"Principle","question":"What is the design principle behind the public frontend of the Empathy Ledger platform?","answer":"The design principle of the public frontend focuses on providing a beautiful story reading experience with clean, narrative-focused design elements. It emphasizes simplicity and accessibility for storytellers and audiences.","context":"This principle ensures that users engaging with stories have an enjoyable and intuitive experience.","document":"Admin Backend vs Public Frontend Setup","category":"Principle","section":"Admin Backend vs Public Frontend Setup > ðŸŽ¯ Overview: Two Separate Experiences > **Public Frontend** (Storytellers & Audience)","confidence":0.9}
{"type":"Fact","question":"What are the URL patterns used in the public frontend of the Empathy Ledger platform?","answer":"The URL patterns used in the public frontend are `/storytellers/*`, `/stories/*`, and `/galleries/*`.","context":"These URL patterns help organize the content and make navigation intuitive for users.","document":"Admin Backend vs Public Frontend Setup","category":"Principle","section":"Admin Backend vs Public Frontend Setup > ðŸŽ¯ Overview: Two Separate Experiences > **Public Frontend** (Storytellers & Audience)","confidence":1}
{"type":"Method","question":"How does the public frontend cater to a non-technical audience?","answer":"The public frontend avoids using AI jargon and technical details, making it accessible for all users regardless of their technical expertise.","context":"This approach facilitates broader community engagement and understanding of the storytelling content.","document":"Admin Backend vs Public Frontend Setup","category":"Principle","section":"Admin Backend vs Public Frontend Setup > ðŸŽ¯ Overview: Two Separate Experiences > **Public Frontend** (Storytellers & Audience)","confidence":0.85}
{"type":"Practice","question":"What features contribute to the storyteller experience on the public frontend?","answer":"The public frontend includes simple profile pages for storytellers, enhancing their visibility and connection to the audience while maintaining a user-friendly interface.","context":"These features promote storytelling and foster community engagement on the platform.","document":"Admin Backend vs Public Frontend Setup","category":"Principle","section":"Admin Backend vs Public Frontend Setup > ðŸŽ¯ Overview: Two Separate Experiences > **Public Frontend** (Storytellers & Audience)","confidence":0.8}
{"type":"Fact","question":"How many tables are there in the Empathy Ledger database?","answer":"The Empathy Ledger database contains a total of 181 tables.","context":"This count includes both actively used and unused or orphaned tables within the database.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Current State","confidence":1}
{"type":"Fact","question":"What percentage of the tables in the Empathy Ledger database are actively used?","answer":"72% of the tables in the Empathy Ledger database are actively used, totaling 130 tables.","context":"This indicates a significant portion of the database is operational while some are not.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Current State","confidence":1}
{"type":"Fact","question":"What issue exists with unused tables in the Empathy Ledger database?","answer":"The Empathy Ledger database has 51 unused or orphaned tables, which constitutes 28% bloat.","context":"This bloat may affect performance and optimization of the database.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Current State","confidence":1}
{"type":"Fact","question":"What types of naming conflicts are present in the Empathy Ledger database?","answer":"There are multiple naming conflicts within the Empathy Ledger database, specifically between the terms 'organisations' and 'organizations'.","context":"Such conflicts can lead to inconsistencies in data retrieval and processing.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Current State","confidence":1}
{"type":"Fact","question":"What is a critical issue affecting high-traffic queries in the Empathy Ledger database?","answer":"The Empathy Ledger database is missing critical indexes on high-traffic queries.","context":"The absence of these indexes can significantly degrade performance and slower response times for queries.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Current State","confidence":1}
{"type":"Principle","question":"What are the OCAP principles?","answer":"The OCAP principles stand for Ownership, Control, Access, and Possession. They are essential guidelines that support Indigenous Data Sovereignty, ensuring that Indigenous communities own and control their data.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > Executive Summary","confidence":1}
{"type":"Principle","question":"How do the UN Sustainable Development Goals relate to Indigenous communities?","answer":"The UN Sustainable Development Goals (SDGs) provide a global framework for addressing various social, economic, and environmental issues. For Indigenous communities, these goals emphasize the importance of inclusivity and the participation of Indigenous voices in achieving sustainable development.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > Executive Summary","confidence":0.9}
{"type":"Principle","question":"What is Social Return on Investment (SROI) and its importance?","answer":"Social Return on Investment (SROI) is a framework for measuring the social value created by an investment. It emphasizes the importance of quantifying social, environmental, and economic impacts, particularly relevant for assessing projects aimed at benefiting Indigenous communities.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > Executive Summary","confidence":0.9}
{"type":"Method","question":"What is a Theory of Change framework?","answer":"A Theory of Change framework is a comprehensive description and illustration of how and why a desired change is expected to happen in a particular context. It's a valuable tool for planning, participation, and evaluation, especially in community-driven initiatives.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > Executive Summary","confidence":0.9}
{"type":"Principle","question":"What are community-defined success metrics?","answer":"Community-defined success metrics are specific indicators developed by the community to measure the success and impact of programs or interventions. This approach ensures that the metrics are relevant to the community's unique values and goals.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > Executive Summary","confidence":0.9}
{"type":"Fact","question":"What critical tables are identified in the Empathy Ledger database?","answer":"The critical tables identified in the Empathy Ledger database are profiles, stories, transcripts, organizations, media_assets, galleries, and photos.","context":null,"document":"ðŸ”’ RLS DEPLOYMENT REPORT - Empathy Ledger Cultural Data Protection","category":"Principle","section":"ðŸ”’ RLS DEPLOYMENT REPORT - Empathy Ledger Cultural Data Protection > ðŸŽ¯ EXECUTIVE SUMMARY > Key Findings:","confidence":1}
{"type":"Warning","question":"What limitation is encountered during the automatic deployment of the Empathy Ledger?","answer":"The automatic deployment is blocked by Supabase API limitations, which requires manual deployment via the Supabase Dashboard.","context":null,"document":"ðŸ”’ RLS DEPLOYMENT REPORT - Empathy Ledger Cultural Data Protection","category":"Principle","section":"ðŸ”’ RLS DEPLOYMENT REPORT - Empathy Ledger Cultural Data Protection > ðŸŽ¯ EXECUTIVE SUMMARY > Key Findings:","confidence":1}
{"type":"Procedure","question":"How is a transcript created in the Empathy Ledger platform?","answer":"A transcript can be created via the user interface either through the Storyteller Wizard or the Transcript Edit page.","context":"This is the first step in the transcript analysis workflow.","document":"Transcript Analysis Workflow","category":"Procedure","section":"Transcript Analysis Workflow > Automatic Processing Flow > 1. Transcript Creation","confidence":0.9}
{"type":"Procedure","question":"What happens to a transcript after it is created?","answer":"Once created, the transcript is saved to the database with a status of 'pending'.","context":"This indicates that the transcript is not yet finalized and awaits further processing.","document":"Transcript Analysis Workflow","category":"Procedure","section":"Transcript Analysis Workflow > Automatic Processing Flow > 1. Transcript Creation","confidence":0.9}
{"type":"Fact","question":"What basic metadata is calculated when a transcript is created?","answer":"When a transcript is created, basic metadata such as word count and character count is calculated.","context":"This metadata is useful for understanding the length and scope of the transcript.","document":"Transcript Analysis Workflow","category":"Procedure","section":"Transcript Analysis Workflow > Automatic Processing Flow > 1. Transcript Creation","confidence":0.9}
{"type":"Procedure","question":"How do I deploy the Individual Analytics Schema?","answer":"To deploy the Individual Analytics Schema, copy the entire contents of 'database/14-individual-analytics-schema.sql', paste it into an SQL Editor, and execute the command. This will create 6 new tables: 'personal_insights', 'professional_competencies', 'impact_stories', 'opportunity_recommendations', 'development_plans', and 'analysis_jobs'.","context":null,"document":"Individual Analytics System - Production Deployment Guide","category":"Practice","section":"Individual Analytics System - Production Deployment Guide > ðŸ—„ï¸ Database Schema Deployment > Step 1: Deploy Individual Analytics Schema","confidence":0.95}
{"type":"Fact","question":"What tables are created when deploying the Individual Analytics Schema?","answer":"When deploying the Individual Analytics Schema, the following 6 tables are created: 'personal_insights' for core narrative themes and values, 'professional_competencies' for skills analysis with market value, 'impact_stories' for professional impact narratives, 'opportunity_recommendations' for career and grant matching, 'development_plans' for personal growth planning, and 'analysis_jobs' for AI processing queue.","context":null,"document":"Individual Analytics System - Production Deployment Guide","category":"Practice","section":"Individual Analytics System - Production Deployment Guide > ðŸ—„ï¸ Database Schema Deployment > Step 1: Deploy Individual Analytics Schema","confidence":0.9}
{"type":"Fact","question":"What functionalities are currently working in the Seed Interview System?","answer":"The Seed Interview System is currently fully functional with the following features: Project Seed Interview API (GET & POST), Organization Seed Interview API (GET & POST), AI Extraction with Ollama (FREE, unlimited), Development mode bypass (no auth required for testing), Database storage with proper RLS bypass, Quality scoring (0-100), and Structured outcome extraction.","context":null,"document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > Current Status: âœ… FULLY FUNCTIONAL > What's Working:","confidence":1}
{"type":"Method","question":"What is the role of the AI Extraction feature in the Seed Interview System?","answer":"The AI Extraction feature, powered by Ollama, provides free and unlimited extraction capabilities, enhancing the efficiency and effectiveness of gathering data from interviews.","context":null,"document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > Current Status: âœ… FULLY FUNCTIONAL > What's Working:","confidence":0.9}
{"type":"Principle","question":"What is the importance of using the PMPP framework in organizing documentation?","answer":"The PMPP framework is essential in organizing documentation as it categorizes knowledge into Principles, Methods, Practices, and Procedures, ensuring a structured approach to knowledge management. This leads to improved accessibility and clarity for users.","context":"PMPP Framework Overview","document":"Knowledge Base System Architecture","category":"Principle","section":"Knowledge Base System Architecture > System Overview","confidence":0.9}
{"type":"Process","question":"What are the phases involved in the document scanning process of the Empathy Ledger knowledge base?","answer":"The document scanning process involves several phases: Phase 1 scans for all markdown files while avoiding certain directories, Phase 2 extracts metadata from these files including cultural sensitivity, Phase 3 creates semantic chunks for accurate structuring and retrieval, Phase 4 generates embeddings for the knowledge chunks, and Phase 5 stores the documents and chunks in a PostgreSQL database.","context":"Knowledge Base System Architecture Overview","document":"Knowledge Base System Architecture","category":"Principle","section":"Knowledge Base System Architecture > System Overview","confidence":0.85}
{"type":"Fact","question":"What are the specifications for the embeddings generated in the knowledge base?","answer":"The embeddings generated for the knowledge base use the OpenAI text-embedding-3-small model, which has 1536 dimensions. The estimated cost for generating embeddings is approximately $0.10-$0.20 for 200 documents, with a typical processing time of around 5-10 minutes including network latency.","context":"Embedding Generation Phase","document":"Knowledge Base System Architecture","category":"Principle","section":"Knowledge Base System Architecture > System Overview","confidence":0.95}
{"type":"Method","question":"How does the Empathy Ledger ensure cultural sensitivity in its photo gallery system?","answer":"The Empathy Ledger uses a three-tier cultural sensitivity system (Low, Medium, High) that incorporates appropriate access controls to ensure that users can only access content suitable to their level of clearance.","context":null,"document":"Photo Gallery System - Empathy Ledger","category":"Principle","section":"Photo Gallery System - Empathy Ledger > Key Features > ðŸŒ± Cultural Respect & Protocols","confidence":0.9}
{"type":"Procedure","question":"What are the approval workflows for content in the Empathy Ledger's photo gallery?","answer":"The photo gallery includes built-in Elder approval workflows that are necessary for any culturally significant content, ensuring it meets the standards of cultural respect before being published.","context":null,"document":"Photo Gallery System - Empathy Ledger","category":"Principle","section":"Photo Gallery System - Empathy Ledger > Key Features > ðŸŒ± Cultural Respect & Protocols","confidence":0.85}
{"type":"Practice","question":"How is ceremonial content handled in the Empathy Ledger photo gallery?","answer":"The platform has special handling protocols for sacred and ceremonial imagery, ensuring that such content is treated with the highest level of respect and protection.","context":null,"document":"Photo Gallery System - Empathy Ledger","category":"Principle","section":"Photo Gallery System - Empathy Ledger > Key Features > ðŸŒ± Cultural Respect & Protocols","confidence":0.9}
{"type":"Method","question":"What systems are in place to protect traditional knowledge in the photo gallery?","answer":"The Empathy Ledger implements safeguarding measures specifically designed to protect culturally sensitive information, ensuring that traditional knowledge is respected and preserved.","context":null,"document":"Photo Gallery System - Empathy Ledger","category":"Principle","section":"Photo Gallery System - Empathy Ledger > Key Features > ðŸŒ± Cultural Respect & Protocols","confidence":0.85}
{"type":"Fact","question":"What is Kristy Bloomfield's role in sustainable tourism?","answer":"Kristy Bloomfield is a visionary leader in sustainable tourism and cultural preservation.","context":"This highlights her contributions and importance in the field.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > ðŸŽ¯ Who is Kristy?","confidence":0.9}
{"type":"Method","question":"What project is Kristy Bloomfield working on related to cultural heritage?","answer":"Kristy Bloomfield is working on a transformative walking trail at Napa Homestead.","context":"This project aims to enhance the experience of cultural heritage in the region.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > ðŸŽ¯ Who is Kristy?","confidence":0.8}
{"type":"Method","question":"What are the key components of the AI Enhancement System for Empathy Ledger?","answer":"The AI Enhancement System for Empathy Ledger includes the following key components: 1. Cultural Safety AI Middleware (OCAP Compliance), 2. Story Recommendations Engine (Cultural Filtering), 3. Content Enhancement System (Metadata & Analysis), 4. Cultural Safety Moderation (Elder Review Workflows), 5. Intelligent Search System (Semantic + Cultural Context), and 6. Story Connection Analysis (Narrative Threads & Patterns).","context":"Overview of the system architecture","document":"AI Enhancement System Implementation Plan for Empathy Ledger","category":"Method","section":"AI Enhancement System Implementation Plan for Empathy Ledger > System Architecture Overview","confidence":0.9}
{"type":"Practice","question":"What documentation is available for setting up the GOODS project?","answer":"The available documentation for setting up the GOODS project is 'GOODS_PROJECT_SETUP.md', which covers project setup and configuration.","context":null,"document":"GOODS Project Documentation","category":"Practice","section":"GOODS Project Documentation > Key Documents","confidence":1}
{"type":"Practice","question":"Where can I find the strategic direction for the GOODS project?","answer":"The strategic direction for the GOODS project can be found in the document 'GOODS_STRATEGIC_PATH_FORWARD.md'.","context":null,"document":"GOODS Project Documentation","category":"Practice","section":"GOODS Project Documentation > Key Documents","confidence":1}
{"type":"Warning","question":"Are there any known issues with AI quote fabrication in the GOODS project?","answer":"Yes, there is a known issue regarding AI quote fabrication, which is documented in 'GOODS_AI_QUOTE_FABRICATION_ISSUE.md'.","context":null,"document":"GOODS Project Documentation","category":"Practice","section":"GOODS Project Documentation > Key Documents","confidence":1}
{"type":"Warning","question":"What issues are documented regarding the outcomes tracker in the GOODS project?","answer":"Issues related to the outcomes tracker are documented in 'GOODS_OUTCOMES_TRACKER_PROBLEM.md'.","context":null,"document":"GOODS Project Documentation","category":"Practice","section":"GOODS Project Documentation > Key Documents","confidence":1}
{"type":"Principle","question":"What is the significance of using partnership-focused messaging in the Empathy Ledger?","answer":"The importance of using partnership-focused messaging lies in fostering collaboration and mutual respect among Indigenous communities, as opposed to using terminology like 'empower', which can imply a power dynamic that is not aligned with the principles of equality and shared agency.","context":"Messaging within the Empathy Ledger should reflect the core values of partnership and respect for Indigenous knowledge and authority.","document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things > Key Documents","confidence":0.9}
{"type":"Principle","question":"What are the multi-tenant principles in the Empathy Ledger?","answer":"The multi-tenant principles in the Empathy Ledger focus on maintaining cultural sensitivity, respecting the autonomy of each community, and ensuring that the platform serves the diverse needs of multiple Indigenous groups effectively.","context":"These principles guide the development and operation of the platform to support various communities while upholding the values of cultural safety.","document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things > Key Documents","confidence":0.85}
{"type":"Principle","question":"What is the operational philosophy behind the Empathy Ledger?","answer":"The operational philosophy of the Empathy Ledger emphasizes collaboration, accountability, and cultural sensitivity to ensure that the platform not only serves its users effectively but also honors the traditions and practices of Indigenous communities.","context":"This philosophy informs all aspects of the platformâ€™s operation, from technical implementations to user interactions.","document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things > Key Documents","confidence":0.88}
{"type":"Method","question":"What does the AI enhancement methodology cover?","answer":"The AI enhancement methodology outlines the systematic approach to integrating artificial intelligence into the platform, focusing on improving user interaction and personalization.","context":"This methodology is documented in the AI enhancement system implementation plan.","document":"Methods: Frameworks and Approaches","category":"Method","section":"Methods: Frameworks and Approaches > Key Documents","confidence":0.9}
{"type":"Method","question":"What is the purpose of the transcript analysis framework?","answer":"The transcript analysis framework provides guidelines for analyzing user interactions and narratives, ensuring that insights derived from transcripts align with the platform's objectives and cultural sensitivity.","context":"Details of this framework can be found in the individual transcript analysis system implementation plan.","document":"Methods: Frameworks and Approaches","category":"Method","section":"Methods: Frameworks and Approaches > Key Documents","confidence":0.85}
{"type":"Method","question":"What is the STORY_CREATION_FRAMEWORK used for?","answer":"The STORY_CREATION_FRAMEWORK serves as a methodology for developing narratives within the platform, ensuring that storytelling aligns with community values and cultural integrity.","context":"This framework is crucial for guiding users in creating respectful and relevant stories.","document":"Methods: Frameworks and Approaches","category":"Method","section":"Methods: Frameworks and Approaches > Key Documents","confidence":0.9}
{"type":"Fact","question":"How many mission pillars does the Empathy Ledger have?","answer":"The Empathy Ledger has 8 mission pillars.","context":"This information is relevant for understanding the foundational structure of the platform.","document":"Empathy Ledger v2 - Complete Strategic Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Complete Strategic Rebuild Plan > Executive Summary","confidence":1}
{"type":"Fact","question":"How many database tables are included in the Empathy Ledger?","answer":"The Empathy Ledger includes 171 database tables.","context":"This statistic provides insight into the complexity and scope of the platform's database architecture.","document":"Empathy Ledger v2 - Complete Strategic Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Complete Strategic Rebuild Plan > Executive Summary","confidence":1}
{"type":"Fact","question":"What are the distinct user audiences of the Empathy Ledger?","answer":"The Empathy Ledger serves 3 distinct user audiences: Storytellers, Organizations, and the Public.","context":"Understanding the target audiences is essential for developing user-centric features.","document":"Empathy Ledger v2 - Complete Strategic Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Complete Strategic Rebuild Plan > Executive Summary","confidence":1}
{"type":"Practice","question":"What methodology is used for the ACT Ecosystem integration in the Empathy Ledger?","answer":"The ACT Ecosystem integration employs the LCAA methodology.","context":"This information helps in understanding the strategic approach taken for system integration.","document":"Empathy Ledger v2 - Complete Strategic Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Complete Strategic Rebuild Plan > Executive Summary","confidence":1}
{"type":"Fact","question":"What brand identity does the Empathy Ledger emphasize?","answer":"The Empathy Ledger emphasizes an Editorial Warmth brand identity.","context":"Understanding the brand identity can help in aligning content and user interactions with the platformâ€™s values.","document":"Empathy Ledger v2 - Complete Strategic Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Complete Strategic Rebuild Plan > Executive Summary","confidence":1}
{"type":"Practice","question":"How does Kristy Bloomfield innovate Indigenous storytelling?","answer":"She is innovating with technology such as underwater drones for Indigenous storytelling.","context":"This represents a unique approach to preserving and sharing cultural narratives.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > ðŸŽ¯ Who is Kristy?","confidence":0.9}
{"type":"Fact","question":"Who does Kristy Bloomfield collaborate with for cultural heritage projects?","answer":"Kristy collaborates with Minga Minga Rangers on cultural heritage projects.","context":"This collaboration is essential for preserving and promoting cultural heritage.","document":"Kristy Bloomfield - Account Walkthrough ðŸŒ","category":"Practice","section":"Kristy Bloomfield - Account Walkthrough ðŸŒ > ðŸŽ¯ Who is Kristy?","confidence":0.9}
{"type":"Principle","question":"What does the principle of quality improvement entail in the context of the Empathy Ledger platform?","answer":"The principle of quality improvement focuses on enhancing the clarity and confidence of content generated, moving from fragmented expressions to well-formed, coherent thoughts. This ensures a higher quality of communication, reflected in quality scores that range from 60 to 100.","context":"This principle is crucial for maintaining high standards of interaction and storytelling within the platform.","document":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited)","category":"Principle","section":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited) > Current Status: WORKING BUT BLOCKED BY OPENAI RATE LIMIT > What's Working âœ…","confidence":0.9}
{"type":"Fact","question":"What documents are key to understanding the Empathy Ledger platform?","answer":"The key documents for understanding the Empathy Ledger platform include: EMPATHY_LEDGER_WIKI.md, which provides an overview; EMPATHY_LEDGER_STRATEGIC_FOUNDATION.md, which outlines the strategic foundation and mission; EMPATHY_LEDGER_TECHNICAL_ARCHITECTURE.md, detailing the technical architecture; and EMPATHY_LEDGER_MESSAGING_REVIEW.md, which contains partnership-focused messaging guidelines.","context":"These documents serve as foundational resources for understanding various aspects of the platform.","document":"Platform Overview and Strategy","category":"Practice","section":"Platform Overview and Strategy > Key Documents","confidence":0.9}
{"type":"Principle","question":"What principle guides the architecture of the Empathy Ledger platform?","answer":"The architecture of the Empathy Ledger platform is guided by full OCAP compliance, ensuring exceptional cultural safety implementation.","context":"OCAP stands for Ownership, Control, Access, and Possession, which are principles that prioritize Indigenous sovereignty over their data.","document":"Comprehensive Supabase Database Analysis Report","category":"Principle","section":"Comprehensive Supabase Database Analysis Report > ðŸ” Executive Summary > Key Findings:","confidence":0.9}
{"type":"Practice","question":"How is cultural media supported in the Empathy Ledger's storage architecture?","answer":"The storage architecture employs a multi-bucket strategy tailored for cultural media, facilitating the organization and management of diverse media types relevant to storytelling.","context":"This approach helps maintain a clear and respectful separation of different forms of media.","document":"Comprehensive Supabase Database Analysis Report","category":"Principle","section":"Comprehensive Supabase Database Analysis Report > ðŸ” Executive Summary > Key Findings:","confidence":0.88}
{"type":"Practice","question":"What features are included in the authentication system of the Empathy Ledger platform?","answer":"The authentication system is advanced and multi-tenant, incorporating specific cultural permissions to ensure that users' rights and access are managed with sensitivity to cultural protocols.","context":"This helps to maintain the integrity and security of the cultural narratives being stored and shared on the platform.","document":"Comprehensive Supabase Database Analysis Report","category":"Principle","section":"Comprehensive Supabase Database Analysis Report > ðŸ” Executive Summary > Key Findings:","confidence":0.9}
{"type":"Fact","question":"What is the accuracy improvement achieved in the Claude Sonnet 4.5 AI upgrade?","answer":"The accuracy improved to 90-95%, up from 60-70%.","context":null,"document":"Claude Sonnet 4.5 AI Upgrade - Complete Summary","category":"Principle","section":"Claude Sonnet 4.5 AI Upgrade - Complete Summary > ðŸŽ¯ Mission Accomplished > What We Built","confidence":0.95}
{"type":"Fact","question":"What is the quote verification rate of the Claude Sonnet 4.5 AI?","answer":"The quote verification rate is 100%, with 0% fabrication.","context":null,"document":"Claude Sonnet 4.5 AI Upgrade - Complete Summary","category":"Principle","section":"Claude Sonnet 4.5 AI Upgrade - Complete Summary > ðŸŽ¯ Mission Accomplished > What We Built","confidence":0.95}
{"type":"Fact","question":"How many standardized themes are mapped to the UN Sustainable Development Goals (SDGs) in the upgrade?","answer":"There are over 40 standardized themes mapped to the UN SDGs.","context":null,"document":"Claude Sonnet 4.5 AI Upgrade - Complete Summary","category":"Principle","section":"Claude Sonnet 4.5 AI Upgrade - Complete Summary > ðŸŽ¯ Mission Accomplished > What We Built","confidence":0.9}
{"type":"Fact","question":"What capability does the production-ready pipeline of the Claude Sonnet 4.5 AI provide?","answer":"The production-ready pipeline can process 188 transcripts.","context":null,"document":"Claude Sonnet 4.5 AI Upgrade - Complete Summary","category":"Principle","section":"Claude Sonnet 4.5 AI Upgrade - Complete Summary > ðŸŽ¯ Mission Accomplished > What We Built","confidence":0.9}
{"type":"Practice","question":"What is the purpose of OrganizationContext in the Super Admin frontend?","answer":"OrganizationContext is a React context designed to manage the selected organization state within the Super Admin frontend. It provides the `selectedOrgId` and `setSelectedOrgId` to all admin components, facilitating the user's ability to switch between viewing 'all organizations' and a specific organization.","context":null,"document":"Super Admin Frontend Implementation Summary","category":"Principle","section":"Super Admin Frontend Implementation Summary > What We Implemented > Phase 1: Core Components > 1. OrganizationContext (src/lib/contexts/OrganizationContext.tsx)","confidence":0.9}
{"type":"Fact","question":"What does the COMPREHENSIVE_DATABASE_STATUS_2025.md report include?","answer":"The COMPREHENSIVE_DATABASE_STATUS_2025.md report includes information on the database health and structure.","context":"This report is part of the key reports under the 'Analysis Reports' section.","document":"Analysis Reports","category":"Principle","section":"Analysis Reports > Key Reports","confidence":1}
{"type":"Fact","question":"What specific analysis does the COMPREHENSIVE_SUPABASE_DATABASE_ANALYSIS_REPORT.md provide?","answer":"The COMPREHENSIVE_SUPABASE_DATABASE_ANALYSIS_REPORT.md provides a Supabase-specific analysis.","context":"This report is included in the key reports related to analysis under the 'Analysis Reports' section.","document":"Analysis Reports","category":"Principle","section":"Analysis Reports > Key Reports","confidence":1}
{"type":"Fact","question":"What is the focus of the CLAUDE_TOOLS_AUDIT_REPORT.md?","answer":"The CLAUDE_TOOLS_AUDIT_REPORT.md focuses on an audit of AI tools.","context":"This report is listed among the key reports in the 'Analysis Reports' section.","document":"Analysis Reports","category":"Principle","section":"Analysis Reports > Key Reports","confidence":1}
{"type":"Fact","question":"What intelligent AI systems have been imported into the Empathy Ledger platform?","answer":"The Empathy Ledger platform has imported intelligent AI systems that enhance its functionality and capabilities.","context":"This refers to the backend integration of AI systems that improve the platform's performance.","document":"âœ… Integration Complete - Intelligent AI is Live!","category":"Principle","section":"âœ… Integration Complete - Intelligent AI is Live! > ðŸŽ‰ What's Been Deployed > Backend Integration âœ…","confidence":0.9}
{"type":"Practice","question":"What feature was added to improve content moderation?","answer":"A flag detection feature was added to the Empathy Ledger platform to help identify and manage inappropriate content.","context":"Flag detection assists in maintaining cultural sensitivity and ensuring community guidelines are followed.","document":"âœ… Integration Complete - Intelligent AI is Live!","category":"Principle","section":"âœ… Integration Complete - Intelligent AI is Live! > ðŸŽ‰ What's Been Deployed > Backend Integration âœ…","confidence":0.85}
{"type":"Method","question":"How was parallel analysis implemented in the AI integration?","answer":"The integration includes parallel GPT-4 analysis, allowing the platform to effectively evaluate and generate content concurrently, enhancing its responsiveness and intelligence.","context":"This method leverages advanced AI capabilities to provide better services to users.","document":"âœ… Integration Complete - Intelligent AI is Live!","category":"Principle","section":"âœ… Integration Complete - Intelligent AI is Live! > ðŸŽ‰ What's Been Deployed > Backend Integration âœ…","confidence":0.9}
{"type":"Practice","question":"What was done to preserve the legacy system in the Empathy Ledger platform?","answer":"The legacy system was preserved for comparison with the new AI integrations, allowing for evaluation against previous functionalities.","context":"This practice ensures that users can transition smoothly while maintaining access to previous system features.","document":"âœ… Integration Complete - Intelligent AI is Live!","category":"Principle","section":"âœ… Integration Complete - Intelligent AI is Live! > ðŸŽ‰ What's Been Deployed > Backend Integration âœ…","confidence":0.8}
{"type":"Principle","question":"What is the importance of focusing on lived experiences in the GOODS Analysis?","answer":"Focusing on lived experiences rather than evaluation methods ensures that the narratives truly reflect the realities and insights of individuals, particularly within Indigenous communities. This approach fosters authenticity and respects the personal dimensions of storytelling.","context":"This principle was applied by updating the seed interview extraction prompt to request lived experiences.","document":"âœ… READY TO TEST: Fixed GOODS Analysis","category":"Principle","section":"âœ… READY TO TEST: Fixed GOODS Analysis > The Fix Applied","confidence":0.9}
{"type":"Practice","question":"What changes were made to the GOODS success criteria in the database?","answer":"Eight new success criteria focused on essential aspects such as beds, sleep, and hygiene were manually corrected and added to the GOODS database.","context":"The corrections made ensure that the criteria used in analysis more accurately reflect relevant factors.","document":"âœ… READY TO TEST: Fixed GOODS Analysis","category":"Principle","section":"âœ… READY TO TEST: Fixed GOODS Analysis > The Fix Applied","confidence":0.8}
{"type":"Process","question":"What steps were taken to ensure the analysis uses corrected criteria?","answer":"The analysis cache was cleared to ensure that the next run utilizes the newly corrected GOODS success criteria.","context":"This process step is crucial for maintaining accuracy in future analyses.","document":"âœ… READY TO TEST: Fixed GOODS Analysis","category":"Principle","section":"âœ… READY TO TEST: Fixed GOODS Analysis > The Fix Applied","confidence":0.85}
{"type":"Practice","question":"What types of reports are used to track weekly progress in the Empathy Ledger platform?","answer":"The Empathy Ledger platform utilizes WEEK_*.md files for tracking weekly progress.","context":"Weekly progress tracking is essential for understanding the implementation status.","document":"Implementation Completion Reports","category":"Principle","section":"Implementation Completion Reports > Quick Navigation","confidence":0.9}
{"type":"Practice","question":"How can I confirm feature completions in the Empathy Ledger platform?","answer":"Feature completions are confirmed using *_COMPLETE.md files.","context":"These files provide documentation on completed features, aiding in project management.","document":"Implementation Completion Reports","category":"Principle","section":"Implementation Completion Reports > Quick Navigation","confidence":0.9}
{"type":"Practice","question":"What file type is used for documenting external integrations in the Empathy Ledger?","answer":"External integrations are documented using *_INTEGRATION_COMPLETE.md files.","context":"This documentation is critical for tracking the status of integrations with external systems.","document":"Implementation Completion Reports","category":"Principle","section":"Implementation Completion Reports > Quick Navigation","confidence":0.9}
{"type":"Practice","question":"What is the layout style of the Project Outcomes View component?","answer":"The Project Outcomes View component features a beautiful card-based layout.","context":"This layout is designed to enhance visual appeal and organization of information.","document":"Project Outcomes Tracker - Implementation Status","category":"Principle","section":"Project Outcomes Tracker - Implementation Status > âœ… **COMPLETED:** > 2. **UI Component Created**","confidence":0.9}
{"type":"Practice","question":"How does the Project Outcomes View indicate the strength of evidence?","answer":"The Project Outcomes View utilizes color-coding to represent the strength of evidence.","context":"Color-coding helps users quickly assess the reliability of the information presented.","document":"Project Outcomes Tracker - Implementation Status","category":"Principle","section":"Project Outcomes Tracker - Implementation Status > âœ… **COMPLETED:** > 2. **UI Component Created**","confidence":0.8}
{"type":"Practice","question":"What types of information are displayed in the Project Outcomes View?","answer":"The Project Outcomes View displays quotes, storytellers, scores, as well as sections for key wins and opportunities.","context":"This information is critical for understanding the project's impact and areas for further development.","document":"Project Outcomes Tracker - Implementation Status","category":"Principle","section":"Project Outcomes Tracker - Implementation Status > âœ… **COMPLETED:** > 2. **UI Component Created**","confidence":0.85}
{"type":"Fact","question":"What percentage of profiles have email fields?","answer":"9% of the profiles, which translates to 22 out of 235 profiles, have email fields.","context":"Summary of the profiles table cleanup actions regarding email fields.","document":"Profiles Table Cleanup - Summary Report","category":"Principle","section":"Profiles Table Cleanup - Summary Report > âœ… Completed Actions > 1. Email Field Policy âœ…","confidence":1}
{"type":"Procedure","question":"What actions were taken related to the email field policy?","answer":"The actions taken included documenting null-handling requirements for all code related to the email field policy.","context":"This action was part of a broader effort in cleaning up the profiles table.","document":"Profiles Table Cleanup - Summary Report","category":"Principle","section":"Profiles Table Cleanup - Summary Report > âœ… Completed Actions > 1. Email Field Policy âœ…","confidence":1}
{"type":"Fact","question":"What was the impact of the email field policy documentation?","answer":"The impact was that no migration was needed and the policy regarding email fields was clarified.","context":"This was a result of the actions taken to handle email fields during profiles table cleanup.","document":"Profiles Table Cleanup - Summary Report","category":"Principle","section":"Profiles Table Cleanup - Summary Report > âœ… Completed Actions > 1. Email Field Policy âœ…","confidence":1}
{"type":"Fact","question":"What are the indicators of a successful local Supabase setup?","answer":"A successful local Supabase setup is indicated by the successful start of the local Supabase instance, clean application of the initial schema migration, successful application of the first five migrations, the discovery of additional bugs that can be fixed safely, and a clean and predictable migration pattern.","context":"These indicators demonstrate that the setup process went smoothly and identified areas for improvement.","document":"âœ… Local Supabase Setup - SUCCESS!","category":"Principle","section":"âœ… Local Supabase Setup - SUCCESS! > ðŸŽ¯ Mission Accomplished","confidence":1}
{"type":"Principle","question":"What are the benefits of using Supabase TypeScript Type Generation?","answer":"The benefits of Supabase TypeScript Type Generation include full type safety, allowing TypeScript to know your table columns and types; auto-complete features in the IDE which suggest available columns; compile-time error checking to catch typos before runtime; schema synchronization so that types update automatically when the database changes; and the ability to generate thousands of types automatically without manual typing.","context":"This principle ensures developers can work more efficiently and with fewer errors in their applications.","document":"Supabase TypeScript Type Generation Guide","category":"Principle","section":"Supabase TypeScript Type Generation Guide > What is Supabase Type Generation?","confidence":0.95}
{"type":"Practice","question":"What is the best way to organize migration files in Supabase?","answer":"Migration files in Supabase should be organized as follows: Active migrations should be placed in the 'migrations/' directory, with each file named using a timestamp to indicate the order of execution, such as '20250101000000_initial_schema.sql' for new base tables. Additionally, old manual scripts should be stored in the 'migrations/archive/' directory for historical reference, but should not be run. A 'seed.sql' file can be included for sample data needed for local development.","context":"This organization pattern helps manage the migration lifecycle effectively.","document":"Migration Strategy - Making It Perfect","category":"Principle","section":"Migration Strategy - Making It Perfect > The Perfect Migration Pattern > 1. **File Organization** (CLEAN)","confidence":0.9}
{"type":"Warning","question":"What should I avoid doing with old migration scripts?","answer":"You should avoid running old manual migration scripts stored in the 'migrations/archive/' directory as they are intended for historical reference only. Instead, ensure all active migrations are properly executed from the main 'migrations/' directory.","context":"Running outdated scripts could lead to issues in your database setup.","document":"Migration Strategy - Making It Perfect","category":"Principle","section":"Migration Strategy - Making It Perfect > The Perfect Migration Pattern > 1. **File Organization** (CLEAN)","confidence":0.8}
{"type":"Practice","question":"How can I create sample analytics for testing on the Empathy Ledger platform?","answer":"You can create sample analytics by running the following command in your terminal: `node test-with-sample-data.js`. This will generate the necessary dashboard data for testing purposes.","context":"This command helps in populating the analytics system with sample data for Aunty Vicky.","document":"ðŸš€ Launch Your Storyteller Analytics System!","category":"Principle","section":"ðŸš€ Launch Your Storyteller Analytics System! > ðŸŽ¯ **Quick Launch Checklist** > **Step 2: Populate Sample Data (2 minutes)**","confidence":0.9}
{"type":"Fact","question":"What types of data are created when I run the sample analytics command?","answer":"Running the command will create the following types of data: Storyteller analytics dashboard data, AI-extracted themes with prominence scores, powerful quotes with impact ratings, and a network connection foundation.","context":"These data points are relevant for understanding the outputs generated by the analytics system.","document":"ðŸš€ Launch Your Storyteller Analytics System!","category":"Principle","section":"ðŸš€ Launch Your Storyteller Analytics System! > ðŸŽ¯ **Quick Launch Checklist** > **Step 2: Populate Sample Data (2 minutes)**","confidence":0.95}
{"type":"Fact","question":"What was the total number of stories before and after the cleanup?","answer":"Before the cleanup, there were 556 total stories, and after the cleanup, there were 252 stories. This indicates a reduction of 304 stories.","context":"Comparison of story metrics before and after the cleanup process.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Before vs. After Statistics","confidence":0.9}
{"type":"Fact","question":"How many duplicate stories were present before the cleanup?","answer":"There were 288 duplicate stories identified before the cleanup, all of which were removed, achieving a 100% removal rate.","context":"Focus on the impact of the cleanup on story duplicates.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Before vs. After Statistics","confidence":0.9}
{"type":"Fact","question":"What was the result of the cleanup regarding stories with titles?","answer":"After the cleanup, 252 stories had titles completed, achieving 100% completion for this metric compared to approximately 500 stories before the cleanup.","context":"Emphasis on the significance of titles for stories in the database.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Before vs. After Statistics","confidence":0.8}
{"type":"Fact","question":"What was the effect of the cleanup on database efficiency?","answer":"The cleanup resulted in a 53% reduction in database inefficiency, indicating a significant improvement in overall database performance.","context":"Impact of the cleanup on operational metrics.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Before vs. After Statistics","confidence":0.8}
{"type":"Fact","question":"What is the file structure for the Organization Dashboard?","answer":"The file structure for the Organization Dashboard is as follows: `src/app/organizations/[id]/` contains organization routes such as layout, page redirects, dashboard, member directory, story collection, projects portfolio, analytics, and settings. The `src/components/organization/` folder includes various UI components like OrganizationHeader, OrganizationNavigation, OrganizationMetrics, and others. The `src/lib/services/` contains the organization data layer.","context":"The file structure is essential for understanding how the Organization Dashboard is organized and how to navigate its components.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **File Structure**","confidence":0.95}
{"type":"Practice","question":"What components are included in the Organization UI for the Dashboard?","answer":"The Organization UI for the Dashboard includes the following components: OrganizationHeader, OrganizationNavigation, OrganizationMetrics, MemberDirectory, StoryCollection, ProjectsCollection, OrganizationAnalytics, RecentActivity, RecentProjects, and MemberHighlights.","context":"These components play a crucial role in displaying organization-specific data and enhancing navigation within the Dashboard.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **File Structure**","confidence":0.9}
{"type":"Fact","question":"What new features are introduced in the Organization Dashboard?","answer":"The new features introduced in the Organization Dashboard include the Projects page and the RecentProjects widget.","context":"These features expand functionality, allowing organizations to manage projects alongside stories and member directories.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **File Structure**","confidence":0.85}
{"type":"Procedure","question":"How is the dashboard overview structured in the Organization Dashboard?","answer":"The dashboard overview is structured in the `src/app/organizations/[id]/dashboard/page.tsx` file, which serves as the main entry point for the dashboard's layout and content.","context":"This file organizes how the dashboard will display various metrics and information to the users.","document":"ðŸŽ¨ Organization Dashboard Design System Reference","category":"Principle","section":"ðŸŽ¨ Organization Dashboard Design System Reference > ðŸ—ï¸ **ARCHITECTURE & TECH STACK** > **File Structure**","confidence":0.88}
{"type":"Practice","question":"What routes are protected for admin access only in the Empathy Ledger platform?","answer":"The routes protected for admin access only are: `/storytellers/[id]/enhanced`, which shows transcripts and AI recommendations; `/storytellers/[id]/analytics`, which displays AI analysis, charts, and metrics; and `/storytellers/[id]/insights`, which reveals AI-generated personal insights.","context":"These routes are intended to ensure that sensitive information and functionality is only accessible to authorized admin users.","document":"Public vs Admin Views - Implementation Complete âœ…","category":"Principle","section":"Public vs Admin Views - Implementation Complete âœ… > Changes Made > 1. **Admin-Only Routes Protected** ðŸ”’","confidence":0.9}
{"type":"Fact","question":"What is the purpose of the profile_organizations table in the Organization Membership System?","answer":"The purpose of the profile_organizations table is to provide explicit membership tracking along with additional metadata related to user profiles and their associated organizations.","context":"This information helps manage memberships within the Organization Membership System.","document":"Organization Membership System - Architecture & Usage Guide","category":"Principle","section":"Organization Membership System - Architecture & Usage Guide > System Architecture Overview > 2. Secondary System: Profile Organizations Junction Table","confidence":0.9}
{"type":"Fact","question":"What is the current status of the backend integration for Intelligent AI in the Empathy Ledger platform?","answer":"The backend integration is complete, with the `/api/projects/[id]/analysis?intelligent=true` endpoint working as intended.","context":"This status indicates that the integration has been successfully implemented.","document":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited)","category":"Principle","section":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited) > Current Status: WORKING BUT BLOCKED BY OPENAI RATE LIMIT > What's Working âœ…","confidence":1}
{"type":"Fact","question":"What are the key columns in the profile_organizations table?","answer":"The key columns in the profile_organizations table include: `profile_id` (UUID of the profile), `organization_id` (UUID of the organization), `role` (String to indicate the member's role such as 'storyteller', 'Team Member', or 'admin'), `is_active` (Boolean to indicate if the membership is currently active), and `joined_at` (Timestamp of when the member joined).","context":"These columns store important information for tracking organizational memberships and roles.","document":"Organization Membership System - Architecture & Usage Guide","category":"Principle","section":"Organization Membership System - Architecture & Usage Guide > System Architecture Overview > 2. Secondary System: Profile Organizations Junction Table","confidence":0.95}
{"type":"Practice","question":"What is the purpose of the `createLLMClient()` function in the Ollama integration?","answer":"`createLLMClient()` is a function added to the Ollama integration that facilitates the creation of a language model (LLM) client. It includes an OpenAI-compatible interface to simplify migration and ensure compatibility between different LLM providers.","context":"This function is part of the technical implementations in the Ollama integration.","document":"Ollama Integration Status - October 11, 2025","category":"Principle","section":"Ollama Integration Status - October 11, 2025 > âœ… COMPLETED (95%) > 2. LLM Client Factory Created","confidence":0.9}
{"type":"Practice","question":"How does the Ollama integration automatically select the LLM provider?","answer":"The Ollama integration automatically selects the LLM provider based on the `LLM_PROVIDER` environment variable. This allows for flexible configuration of which LLM service to use without needing to modify the code directly.","context":"This feature is designed to enhance the usability and adaptability of the integration.","document":"Ollama Integration Status - October 11, 2025","category":"Principle","section":"Ollama Integration Status - October 11, 2025 > âœ… COMPLETED (95%) > 2. LLM Client Factory Created","confidence":0.9}
{"type":"Fact","question":"What logging feature is included in the Ollama integration?","answer":"The integration includes logging that shows which provider (either Ollama or OpenAI) is currently being used. This helps in monitoring and debugging the integration.","context":"Logging is an important aspect for understanding runtime behavior.","document":"Ollama Integration Status - October 11, 2025","category":"Principle","section":"Ollama Integration Status - October 11, 2025 > âœ… COMPLETED (95%) > 2. LLM Client Factory Created","confidence":0.9}
{"type":"Fact","question":"How many active organizations are currently supported by the Empathy Ledger platform?","answer":"There are 5 active organizations currently supported by the Empathy Ledger platform.","context":"The platform provides complete tenant isolation for these organizations.","document":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan","category":"Principle","section":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan > âœ… **CURRENT SYSTEM STATUS: PRODUCTION-READY** > **ðŸ¢ Organizations: FULLY CONFIGURED**","confidence":0.9}
{"type":"Method","question":"What type of organizations are fully configured in the Empathy Ledger system?","answer":"The Empathy Ledger system is fully configured for professional nonprofit and community organization types.","context":"These configurations ensure proper cultural sensitivity and support.","document":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan","category":"Principle","section":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan > âœ… **CURRENT SYSTEM STATUS: PRODUCTION-READY** > **ðŸ¢ Organizations: FULLY CONFIGURED**","confidence":0.85}
{"type":"Practice","question":"What privacy controls does the Empathy Ledger platform implement?","answer":"The platform includes advanced privacy controls, as well as elder approval workflows to secure sensitive information.","context":"These controls are crucial for protecting the privacy of the organizations and their cultural data.","document":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan","category":"Principle","section":"ðŸš€ Next Steps: Multi-Tenant Organizational System Plan > âœ… **CURRENT SYSTEM STATUS: PRODUCTION-READY** > **ðŸ¢ Organizations: FULLY CONFIGURED**","confidence":0.9}
{"type":"Procedure","question":"How do I pull the recommended Llama model using Ollama?","answer":"To pull the recommended Llama model using Ollama, first, identify your Ollama container with the command 'docker ps | grep ollama'. Then, execute the command 'docker exec -it <container-name> ollama pull llama3.1:8b' to pull the Llama 3.1 8B model, which is considered the best balance of speed and quality.","context":"Follow these steps to efficiently set up the Llama model in your Docker environment.","document":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI","category":"Principle","section":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI > ðŸš€ Quick Setup (2 minutes) > 1. Pull the recommended model","confidence":0.95}
{"type":"Procedure","question":"What is the command to pull a smaller, faster Llama model using Ollama?","answer":"To pull a smaller, faster Llama model (4B) using Ollama, use the command 'docker exec -it <container-name> ollama pull llama3.1:4b'.","context":"This command provides an alternative option for users seeking quicker response times with a slightly reduced quality.","document":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI","category":"Principle","section":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI > ðŸš€ Quick Setup (2 minutes) > 1. Pull the recommended model","confidence":0.9}
{"type":"Procedure","question":"What command do I use to pull the larger, higher quality Llama model with Ollama?","answer":"To pull the larger, higher quality Llama model (70B), which is slower but offers exceptional quality, use the command 'docker exec -it <container-name> ollama pull llama3.1:70b'.","context":"This option is recommended for users who prioritize quality over speed in their applications.","document":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI","category":"Principle","section":"ðŸ¦™ Ollama Setup Guide - FREE Unlimited AI > ðŸš€ Quick Setup (2 minutes) > 1. Pull the recommended model","confidence":0.93}
{"type":"Practice","question":"What are the key components of the projects database schema in the Empathy Ledger?","answer":"The `projects` table includes additional columns such as `context_model` for the context model, `context_description` for describing the project context, and `context_updated_at` to track when the context was last updated.","context":null,"document":"Project Context Implementation Guide","category":"Procedure","section":"Project Context Implementation Guide > âœ… What's Been Built > 1. Database Schema","confidence":1}
{"type":"Fact","question":"What type of data does the `project_seed_interviews` table store?","answer":"The `project_seed_interviews` table is designed to store seed interview transcripts.","context":null,"document":"Project Context Implementation Guide","category":"Procedure","section":"Project Context Implementation Guide > âœ… What's Been Built > 1. Database Schema","confidence":1}
{"type":"Fact","question":"What information is contained within the `project_profiles` table?","answer":"The `project_profiles` table holds extracted project profiles that contain all relevant context associated with the project.","context":null,"document":"Project Context Implementation Guide","category":"Procedure","section":"Project Context Implementation Guide > âœ… What's Been Built > 1. Database Schema","confidence":1}
{"type":"Fact","question":"What is the cost of processing images in the Vision AI proof of concept?","answer":"$0.01 per image, with 90% of images processed under a $0.20 budget.","context":null,"document":"Vision AI PoC Test Results","category":"Principle","section":"Vision AI PoC Test Results > Executive Summary > Key Findings","confidence":0.9}
{"type":"Fact","question":"What is the accuracy of face detection in the Vision AI proof of concept?","answer":"The face detection achieved 90% accuracy, detecting faces in 9 out of 10 images.","context":null,"document":"Vision AI PoC Test Results","category":"Principle","section":"Vision AI PoC Test Results > Executive Summary > Key Findings","confidence":0.9}
{"type":"Fact","question":"How sensitive is the Vision AI proof of concept to cultural elements?","answer":"The cultural sensitivity of the Vision AI proof of concept is promising, as it successfully detected cultural text markers.","context":null,"document":"Vision AI PoC Test Results","category":"Principle","section":"Vision AI PoC Test Results > Executive Summary > Key Findings","confidence":0.8}
{"type":"Fact","question":"What is the average processing speed of images in the Vision AI proof of concept?","answer":"The processing speed is approximately 6.4 seconds per image.","context":null,"document":"Vision AI PoC Test Results","category":"Principle","section":"Vision AI PoC Test Results > Executive Summary > Key Findings","confidence":0.9}
{"type":"Principle","question":"What does multi-tenant content isolation in the Empathy Ledger imply?","answer":"Multi-tenant content isolation refers to advanced isolation mechanisms that enable distinct organizational content while allowing for cross-organizational collaboration capabilities.","context":"This feature ensures that content is securely managed within separate organizational contexts.","document":"Phase 2: Organizational Access & Tagging System - Design Document","category":"Principle","section":"Phase 2: Organizational Access & Tagging System - Design Document > Executive Summary > Key Design Decisions","confidence":0.8}
{"type":"Fact","question":"What UI/UX transformation was implemented in Empathy Ledger V2?","answer":"A complete UI/UX transformation with a cultural storytelling theme was implemented in Empathy Ledger V2.","context":null,"document":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT","category":"Principle","section":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT > ðŸ“Š EXECUTIVE SUMMARY > ðŸ† Key Achievements","confidence":0.9}
{"type":"Fact","question":"How has the database schema been aligned in Empathy Ledger V2?","answer":"All API routes and database columns have been synchronized for proper database schema alignment.","context":null,"document":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT","category":"Principle","section":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT > ðŸ“Š EXECUTIVE SUMMARY > ðŸ† Key Achievements","confidence":0.9}
{"type":"Fact","question":"What is the architecture of Empathy Ledger V2?","answer":"Empathy Ledger V2 utilizes a multi-tenant architecture that provides organization-based data isolation.","context":null,"document":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT","category":"Principle","section":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT > ðŸ“Š EXECUTIVE SUMMARY > ðŸ† Key Achievements","confidence":0.9}
{"type":"Fact","question":"What performance optimizations were made in Empathy Ledger V2?","answer":"Performance optimizations included adding over 35 database indexes to ensure optimal performance.","context":null,"document":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT","category":"Principle","section":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT > ðŸ“Š EXECUTIVE SUMMARY > ðŸ† Key Achievements","confidence":0.9}
{"type":"Fact","question":"What is the success rate of API endpoints in Empathy Ledger V2?","answer":"All API endpoints in Empathy Ledger V2 are functional, with a 100% success rate on critical endpoints.","context":null,"document":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT","category":"Principle","section":"ðŸŽ‰ EMPATHY LEDGER V2 - PRODUCTION READINESS REPORT > ðŸ“Š EXECUTIVE SUMMARY > ðŸ† Key Achievements","confidence":0.9}
{"type":"Procedure","question":"How can I define my organization's mission, values, and approach in the context management system?","answer":"To define your organization's mission, values, and approach, navigate to the Organization & Project Context Management System section. You will find options to enter and edit your organization's key contextual information that reflects its identity and guiding principles.","context":"This is essential for ensuring that all projects align with the core purpose and ethics of your organization.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As an Organization Admin:","confidence":0.9}
{"type":"Procedure","question":"How can I specify what impact means for our organization?","answer":"You can specify what impact means for your organization within the Organization & Project Context Management System. Look for the section dedicated to defining organizational impact and input your unique perspective and desired outcomes.","context":"This helps in aligning project objectives with the expected impact that resonates with organizational values.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As an Organization Admin:","confidence":0.85}
{"type":"Procedure","question":"How can I update our organization's mission, values, and approach as our work evolves?","answer":"To update your organization's mission, values, and approach, revisit the Organization & Project Context Management System and locate the relevant editing options. Regularly review and revise this information to reflect any changes in your organization's direction or focus.","context":"Keeping this information current is crucial for effective alignment in ongoing and future projects.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As an Organization Admin:","confidence":0.9}
{"type":"Procedure","question":"How can I ensure that AI understands our context when analyzing our projects?","answer":"To ensure that AI understands your context during project analysis, make sure that you have accurately filled in all relevant details about your organization's mission, values, and impact within the Organization & Project Context Management System. This context helps the AI to provide better insights and analytics tailored to your organizational needs.","context":"Providing a clear context will improve the relevance and effectiveness of the AI's project analyses.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As an Organization Admin:","confidence":0.85}
{"type":"Fact","question":"What fields are included in the 'transcripts' table of the database schema?","answer":"The 'transcripts' table includes the following fields: title (string), content (string), word_count (number), ai_summary (string | null), ai_processing_status (string | null), themes (string[] | null), key_quotes (string[] | null), tags (string[] | null), cultural_context (Json | null), cultural_sensitivity_level (string | null), metadata (Json | null), processing_notes (string | null), and status (string | null).","context":"This information pertains to the structure of the 'transcripts' table within the Empathy Ledger database schema.","document":"Themes and Quotes: AI Analysis Structure","category":"Procedure","section":"Themes and Quotes: AI Analysis Structure > Database Schema > **transcripts** table","confidence":1}
{"type":"Fact","question":"What are the possible statuses for the ai_processing_status field in the 'transcripts' table?","answer":"The possible statuses for the ai_processing_status field are 'pending', 'processing', 'completed', and 'failed'.","context":"This refers to the AI processing state of transcript data within the Empathy Ledger platform.","document":"Themes and Quotes: AI Analysis Structure","category":"Procedure","section":"Themes and Quotes: AI Analysis Structure > Database Schema > **transcripts** table","confidence":1}
{"type":"Fact","question":"What information can be found in the themes and key_quotes fields of the 'transcripts' table?","answer":"The themes field contains extracted themes from the transcript, while the key_quotes field contains an array of extracted key quotes from the transcript.","context":"These fields are designed to capture important thematic and quotable elements from the transcript content.","document":"Themes and Quotes: AI Analysis Structure","category":"Procedure","section":"Themes and Quotes: AI Analysis Structure > Database Schema > **transcripts** table","confidence":1}
{"type":"Fact","question":"What is the purpose of the cultural_context field in the 'transcripts' table?","answer":"The cultural_context field is intended to store JSON data related to the cultural context of the transcript.","context":"This field is part of the cultural sensitivity considerations within the Empathy Ledger platform.","document":"Themes and Quotes: AI Analysis Structure","category":"Procedure","section":"Themes and Quotes: AI Analysis Structure > Database Schema > **transcripts** table","confidence":1}
{"type":"Practice","question":"How can I implement a simple regex pattern for extracting specific quotes?","answer":"You can use a regex pattern that matches sentences containing specific keywords. For example, the following TypeScript code snippet demonstrates a regex pattern that grabs any sentence with the keywords 'changed', 'transformed', 'different', 'overcome', or 'breakthrough':\n\n```typescript\nconst transformationPatterns = /\\b(changed|transformed|different|overcome|breakthrough)\\b.*?[.!?]/gi;\n```","context":"This regex pattern does not provide semantic understanding but allows for basic quote extraction based on keyword matching.","document":"AI Quote Extraction Quality Comparison","category":"Principle","section":"AI Quote Extraction Quality Comparison > Root Cause Analysis","confidence":0.9}
{"type":"Practice","question":"What features were consolidated from Empathy Ledger v.02 into v2?","answer":"The features consolidated from v.02 into v2 include various valuable components focused on enhancing user experience and functionality.","context":"The plan for the recovery and rebuild involved extracting these features over several integration phases.","document":"Empathy Ledger v2 - Recovery & Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Recovery & Rebuild Plan > WHAT HAPPENED: The Full Story > Timeline of Events","confidence":0.8}
{"type":"Process","question":"What were the phases of integration completed in the Empathy Ledger v2 recovery plan?","answer":"The integration process consisted of 7 phases completed over one day: Phase 1 focused on campaign documentation, Phase 2 on advanced analytics, Phase 3 on workflow and consent enhancements, Phase 4 on the campaign management system, Phase 5 on notification triggers, Phase 6 on story distribution improvements, and Phase 7 on partner portal synchronization.","context":"Each phase aimed at improving specific aspects of the Empathy Ledger platform.","document":"Empathy Ledger v2 - Recovery & Rebuild Plan","category":"Practice","section":"Empathy Ledger v2 - Recovery & Rebuild Plan > WHAT HAPPENED: The Full Story > Timeline of Events","confidence":0.9}
{"type":"Fact","question":"What is the data volume in the Empathy Ledger platform's database?","answer":"The database contains over 1,500 rows across 7 core tables with real content.","context":null,"document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Key Findings:","confidence":0.9}
{"type":"Fact","question":"How many authenticated users are in the Empathy Ledger system?","answer":"There are currently 9 authenticated users in the system.","context":null,"document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Key Findings:","confidence":0.9}
{"type":"Fact","question":"How many storage buckets are configured in the Empathy Ledger platform?","answer":"There are 10 configured buckets for media management.","context":null,"document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Key Findings:","confidence":0.9}
{"type":"Warning","question":"What critical issues are present in the Empathy Ledger platform database?","answer":"There are 2 immediate security concerns requiring action.","context":null,"document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Key Findings:","confidence":0.9}
{"type":"Warning","question":"Are there any missing components in the Empathy Ledger platform's database?","answer":"Yes, there are 9 important tables that have not yet been deployed.","context":null,"document":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform","category":"Principle","section":"ðŸ“Š Comprehensive Live Database Analysis - Empathy Ledger Platform > ðŸŽ¯ Executive Summary > Key Findings:","confidence":0.9}
{"type":"Practice","question":"What are the key updates made in the admin layout for the Super Admin multi-tenant implementation?","answer":"The key updates made in the admin layout include the addition of a super admin warning banner in yellow, an organization selector in the header for easy access, the implementation of an OrganizationContext provider that wraps all pages, and a dynamic subtitle that changes based on the view mode.","context":"These updates are part of the core components completed during Phase 1 of the Super Admin multi-tenant implementation.","document":"Session Summary: Super Admin Multi-Tenant Implementation","category":"Principle","section":"Session Summary: Super Admin Multi-Tenant Implementation > What We Accomplished > âœ… Phase 1: Core Components (COMPLETE)","confidence":0.9}
{"type":"Principle","question":"What is the core philosophy behind storyteller profiles in the Empathy Ledger?","answer":"The core philosophy emphasizes a storyteller-centric design, which aims to enhance storyteller profiles through rich analytics support. This approach fosters a deeper understanding of storytellers' preferences, visibility, and impact within the community.","context":null,"document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸŽ¯ Core Philosophy: Storyteller-Centric Design > 1. **Storyteller Profile Enhancement**","confidence":0.9}
{"type":"Practice","question":"How are storyteller profiles enhanced in the Empathy Ledger?","answer":"Storyteller profiles are enhanced through the addition of various analytics features, such as analytics preferences, network visibility options, recommendation opt-in settings, impact scores, narrative themes, and connection strength scores. This allows for a more customized and engaging storytelling experience.","context":null,"document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸŽ¯ Core Philosophy: Storyteller-Centric Design > 1. **Storyteller Profile Enhancement**","confidence":0.9}
{"type":"Procedure","question":"What SQL commands are used to enhance storyteller profiles in the Empathy Ledger?","answer":"The SQL commands used to enhance storyteller profiles include: 1. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS analytics_preferences JSONB DEFAULT '{}'`; 2. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS network_visibility VARCHAR(20) DEFAULT 'public'`; 3. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS recommendation_opt_in BOOLEAN DEFAULT true`; 4. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS impact_score DECIMAL(5,2) DEFAULT 0.0`; 5. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS narrative_themes TEXT[] DEFAULT '{}'`; 6. `ALTER TABLE profiles ADD COLUMN IF NOT EXISTS connection_strength_scores JSONB DEFAULT '{}'`. These commands define various attributes that can support storytellers in their engagement with the platform.","context":null,"document":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture","category":"Principle","section":"ðŸŒŸ Storyteller-Centered Analytics Database Architecture > ðŸŽ¯ Core Philosophy: Storyteller-Centric Design > 1. **Storyteller Profile Enhancement**","confidence":0.9}
{"type":"Principle","question":"What is the significance of including traditional territories in storyteller cards?","answer":"Including traditional territories in storyteller cards acknowledges and respects the historical and cultural connections Indigenous communities have to their land. It enhances the authenticity of the storytelling experience by situating narratives within the rightful context of Indigenous heritage.","context":"This practice emphasizes the importance of recognizing both traditional and modern locations when presenting community stories.","document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ—ºï¸ Enhanced Location Context","confidence":0.9}
{"type":"Principle","question":"Why is it important to include geographic scope indicators in storytelling?","answer":"Incorporating geographic scope indicators (local, regional, national, international) helps define the audience for the story and situates it within a broader context, allowing for better understanding and appreciation of the narrative's significance across different areas.","context":"Geographic scope is pivotal for contextualizing stories and enhancing their relevance to diverse audiences.","document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ—ºï¸ Enhanced Location Context","confidence":0.85}
{"type":"Principle","question":"What is the importance of respectful territorial acknowledgment in storytelling?","answer":"Respectful territorial acknowledgment is vital as it shows recognition of the Indigenous peoples who have inhabited the land historically and presently. It fosters respect and understanding among audiences and reinforces the idea of shared space.","context":"Acknowledging territories is a fundamental practice that underpins cultural safety and respect in storytelling.","document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ—ºï¸ Enhanced Location Context","confidence":0.9}
{"type":"Procedure","question":"What steps should I follow to get my Supabase OAuth redirect URL?","answer":"1. Go to your Supabase project dashboard at https://app.supabase.com/. 2. Navigate to **Authentication** â†’ **Providers**. 3. Locate the **Google** provider section. 4. You will find a redirect URL that looks like `https://yvnuayzslukamizrlhwb.supabase.co/auth/v1/callback`. 5. **Copy this URL** for use in Google Cloud Console.","context":null,"document":"Google OAuth Setup Guide for Empathy Ledger","category":"Principle","section":"Google OAuth Setup Guide for Empathy Ledger > ðŸš€ Step-by-Step Setup > Step 1: Get Your Supabase OAuth Redirect URL","confidence":0.9}
{"type":"Procedure","question":"How do I access the Project Context UI?","answer":"To access the Project Context UI, start by looking for two tabs: 'Context & Outcomes' and 'Storytellers'. Click on the 'Context & Outcomes' tab, where you will see a message stating 'No Project Context Defined'. Below this message, there will be three buttons available: 'Create Manually', 'Seed Interview' (recommended), and 'Import Document'.","context":"This procedure outlines the steps to navigate the Project Context UI efficiently.","document":"How to Access Project Context UI - Quick Start","category":"Principle","section":"How to Access Project Context UI - Quick Start > What You Should See","confidence":0.9}
{"type":"Fact","question":"How many SQL sections were executed without errors during the activation of the Individual Analytics System?","answer":"A total of 42 SQL sections were executed without errors.","context":"This includes tasks related to tables, indexes, policies, and permissions.","document":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS!","category":"Principle","section":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS! > ðŸ“‹ **DEPLOYMENT SUMMARY** > âœ… **COMPLETED TASKS** > **1. Schema Deployment** - SUCCESS âœ…","confidence":0.9}
{"type":"Fact","question":"What are the key spelling conventions regarding -our endings in the Empathy Ledger?","answer":"The key spelling conventions for -our endings in the Empathy Ledger include using `colour`, `colours`, `coloured`, `colouring`, `favour`, `favours`, `favoured`, `favouring`, `favourite`, `honour`, `honours`, `honoured`, `honouring`, `behaviour`, `behaviours`, `labour`, `labours`, `neighbour`, and `neighbours`.","context":"This is part of the Australian Spelling Guide for the Empathy Ledger.","document":"Australian Spelling Guide - Empathy Ledger v2","category":"Principle","section":"Australian Spelling Guide - Empathy Ledger v2 > Key Spelling Conventions > -our endings (not -or)","confidence":1}
{"type":"Fact","question":"What type of architecture does the Empathy Ledger use?","answer":"The Empathy Ledger employs a comprehensive multi-tenant architecture with tenant_id isolation.","context":"This architecture ensures that the data for each tenant is securely isolated from others.","document":"Empathy Ledger v2 - Complete Database Architecture Documentation","category":"Principle","section":"Empathy Ledger v2 - Complete Database Architecture Documentation > Executive Summary > Critical Findings","confidence":1}
{"type":"Fact","question":"What system does Empathy Ledger have for managing user consent?","answer":"The platform includes a complete GDPR/consent management system.","context":"This system is essential for ensuring compliance with data protection laws and respect for user privacy.","document":"Empathy Ledger v2 - Complete Database Architecture Documentation","category":"Principle","section":"Empathy Ledger v2 - Complete Database Architecture Documentation > Executive Summary > Critical Findings","confidence":1}
{"type":"Warning","question":"What are some critical issues that need to be addressed before deploying the latest version of Empathy Ledger?","answer":"There are three critical bugs in the latest migrations that must be fixed before deploying, and the AI processing pipeline is broken, indicating unreliable execution.","context":"Addressing these issues is crucial to ensure the stability and reliability of the deployment.","document":"Empathy Ledger v2 - Complete Database Architecture Documentation","category":"Principle","section":"Empathy Ledger v2 - Complete Database Architecture Documentation > Executive Summary > Critical Findings","confidence":1}
{"type":"Practice","question":"How can I check the status of the database?","answer":"You can check the status of the database by running the command: `npm run db:status`.","context":"This command allows you to see the current state of your database.","document":"Database Workflow - Quick Reference","category":"Principle","section":"Database Workflow - Quick Reference > ðŸš€ Quick Commands (Use These Daily)","confidence":0.9}
{"type":"Procedure","question":"What command do I use to start the local development database?","answer":"To start the local development database, use the command: `npm run db:start`.","context":"This command initializes the local development environment for the database.","document":"Database Workflow - Quick Reference","category":"Principle","section":"Database Workflow - Quick Reference > ðŸš€ Quick Commands (Use These Daily)","confidence":0.9}
{"type":"Procedure","question":"How can I apply migrations to the local database?","answer":"To apply migrations to the local database, you should run: `npm run db:migrate`.","context":"This command ensures that your local database schema is up to date with migrations.","document":"Database Workflow - Quick Reference","category":"Principle","section":"Database Workflow - Quick Reference > ðŸš€ Quick Commands (Use These Daily)","confidence":0.85}
{"type":"Procedure","question":"What is the command to apply migrations to the production database?","answer":"To apply migrations to the production database, use: `npm run db:migrate:remote`. Make sure to confirm the safety prompt before proceeding.","context":"This command applies the necessary migrations to the production environment but requires safety confirmation.","document":"Database Workflow - Quick Reference","category":"Principle","section":"Database Workflow - Quick Reference > ðŸš€ Quick Commands (Use These Daily)","confidence":0.85}
{"type":"Practice","question":"How do I stop the local database?","answer":"You can stop the local database by running the command: `npm run db:stop`.","context":"This command stops the local database service.","document":"Database Workflow - Quick Reference","category":"Principle","section":"Database Workflow - Quick Reference > ðŸš€ Quick Commands (Use These Daily)","confidence":0.9}
{"type":"Procedure","question":"What are the steps to analyze a project using the backend integration framework?","answer":"To analyze a project using the backend integration framework, follow these steps: 1. Use the API endpoint GET /api/projects/[id]/analysis to fetch the project and its transcripts. 2. For each transcript that contains text, apply the function extractIntelligentQuotes() to gather professional quotes, and use assessIndigenousImpact() to generate evidence-based impact scores. 3. Aggregate the Indigenous impact scores utilizing the aggregateIndigenousImpact() function to derive project-level insights. 4. Finally, return the results that include evidence and reasoning behind the insights provided.","context":"This procedure outlines the steps for analyzing projects with a focus on Indigenous impacts.","document":"Backend Integration Plan - Intelligent AI Systems","category":"Principle","section":"Backend Integration Plan - Intelligent AI Systems > New Flow (Intelligent AI)","confidence":0.9}
{"type":"Principle","question":"What is a key principle of the Empathy Ledger's database optimization?","answer":"The database should align with Empathy Ledger's mission to effectively support Indigenous communities.","context":"This principle emphasizes the importance of maintaining a mission-driven approach in optimizing the database.","document":"Empathy Ledger v2 - Database Optimization Plan","category":"Principle","section":"Empathy Ledger v2 - Database Optimization Plan > Executive Summary","confidence":0.9}
{"type":"Principle","question":"Why is it important for the database to scale efficiently?","answer":"It's important for the database to scale efficiently for multiple sites and processes to accommodate the needs of various Indigenous communities effectively.","context":"Scalability is essential to handle varying loads and ensure that all users can access the platform without performance issues.","document":"Empathy Ledger v2 - Database Optimization Plan","category":"Principle","section":"Empathy Ledger v2 - Database Optimization Plan > Executive Summary","confidence":0.95}
{"type":"Principle","question":"What does the principle of 'zero bloat or unused components' imply for database design?","answer":"It implies that the database should be streamlined and efficient, containing only the necessary components to avoid unnecessary complexity and resource consumption.","context":"This principle ensures that the database remains maintainable and focused on essential functionality.","document":"Empathy Ledger v2 - Database Optimization Plan","category":"Principle","section":"Empathy Ledger v2 - Database Optimization Plan > Executive Summary","confidence":0.85}
{"type":"Principle","question":"How does team understanding contribute to the database optimization process?","answer":"Ensuring that the database is understood by all team members contributes to better collaboration, maintenance, and overall effectiveness in managing the database.","context":"A shared understanding fosters a collaborative environment where team members can efficiently contribute to the platform's success.","document":"Empathy Ledger v2 - Database Optimization Plan","category":"Principle","section":"Empathy Ledger v2 - Database Optimization Plan > Executive Summary","confidence":0.9}
{"type":"Procedure","question":"How should the transcripts be renamed in relation to their content?","answer":"The transcripts need to be renamed based on the thematic content that has been pulled. It is important to ensure that the themes are accurately reflected in the transcript names to facilitate better context understanding.","context":null,"document":"Transcript Themes & Quotes - Implementation Summary","category":"Procedure","section":"Transcript Themes & Quotes - Implementation Summary > ðŸŽ¯ What You Asked For","confidence":0.9}
{"type":"Procedure","question":"How can I view the thematics and quotes related to the transcripts?","answer":"You can view the thematics and related quotes in a dropdown format. This allows for easy access to summaries of the content, enhancing contextual understanding.","context":null,"document":"Transcript Themes & Quotes - Implementation Summary","category":"Procedure","section":"Transcript Themes & Quotes - Implementation Summary > ðŸŽ¯ What You Asked For","confidence":0.85}
{"type":"Practice","question":"Why is it essential to understand how thematics and quotes are saved?","answer":"Understanding how thematics and quotes are saved is important for AI analysis across the entire platform. Proper structuring of this data supports more effective analysis and retrieval.","context":null,"document":"Transcript Themes & Quotes - Implementation Summary","category":"Procedure","section":"Transcript Themes & Quotes - Implementation Summary > ðŸŽ¯ What You Asked For","confidence":0.8}
{"type":"Practice","question":"What are some examples of regex patterns used for extracting quotes and themes?","answer":"In the current approach, two regex patterns are defined for extracting meaningful quotes and themes. The first pattern matches words related to transformation: `/\\b(changed|transformed|different|overcome|breakthrough|realised|learned|growth)\\b.*?[.!?]/gi`. The second pattern is for wisdom-related terms: `/\\b(wisdom|teaching|learned|understand|realise|important|advice|knowledge)\\b.*?[.!?]/gi`. These patterns could be used to identify and extract relevant quotes from text data.","context":"This information relates to improving the quality of AI quote and theme extraction.","document":"AI Quote & Theme Extraction - Quality Improvement","category":"Principle","section":"AI Quote & Theme Extraction - Quality Improvement > Problems with Current Approach > 1. **Simple Regex Pattern Matching**","confidence":0.9}
{"type":"Principle","question":"What are the OCAP principles and why are they important?","answer":"The OCAP principles stand for Ownership, Control, Access, and Possession. They are important because they ensure that Indigenous communities maintain sovereignty over their data and stories, and that they are respected in their cultural rights and identity.","context":null,"document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things","confidence":0.9}
{"type":"Principle","question":"Why is it important to avoid savior-complex language?","answer":"Avoiding savior-complex language is crucial as it can perpetuate stereotypes and undermine Indigenous self-determination. It is important to communicate in a way that empowers storytellers rather than positioning them as victims needing saving.","context":null,"document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things","confidence":0.85}
{"type":"Principle","question":"What should be prioritized, platform control or storyteller sovereignty?","answer":"Storyteller sovereignty should always be prioritized over platform control. This ensures that the voices and rights of storytellers are respected and upheld within the platform.","context":null,"document":"Principles: Why We Do Things","category":"Principle","section":"Principles: Why We Do Things","confidence":0.9}
{"type":"Principle","question":"What is the importance of comfort and wellbeing in community initiatives?","answer":"Comfort and wellbeing are essential values symbolized by the cherished bed shared with friends, representing a deeper appreciation for the emotional and physical security of individuals and families within the community.","context":"This emphasizes the role of comfort in enhancing the quality of life for families and ensuring a supportive environment.","document":"GOODS Analysis Fix: Success Criteria Problem SOLVED","category":"Principle","section":"GOODS Analysis Fix: Success Criteria Problem SOLVED > The Critical Problem You Identified","confidence":0.9}
{"type":"Principle","question":"Why is collaboration on community initiatives important?","answer":"Collaboration on initiatives, such as providing free, comfortable beds for families, fosters shared responsibility, strengthens community bonds, and addresses fundamental needs to improve overall wellbeing.","context":"The act of coming together to support families highlights the importance of community unity in addressing challenges.","document":"GOODS Analysis Fix: Success Criteria Problem SOLVED","category":"Principle","section":"GOODS Analysis Fix: Success Criteria Problem SOLVED > The Critical Problem You Identified","confidence":0.9}
{"type":"Fact","question":"What was the outcome of the story database cleanup on the Empathy Ledger platform?","answer":"The comprehensive story database cleanup removed 288 duplicate and low-quality stories, preserving all legitimate content. The database now contains 252 high-quality, unique stories ready for development.","context":"This information reflects the results of a cleanup process aimed at improving the quality of storytelling content on the platform.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Executive Summary","confidence":1}
{"type":"Principle","question":"Why is it important to ensure high-quality stories in the Empathy Ledger platform?","answer":"Ensuring high-quality stories is vital for maintaining cultural integrity and delivering enriching content that resonates with Indigenous communities, fostering meaningful engagement.","context":"The focus on quality aligns with the platform's commitment to cultural sensitivity and respectful representation.","document":"Story Database Cleanup Report","category":"Principle","section":"Story Database Cleanup Report > Executive Summary","confidence":0.9}
{"type":"Fact","question":"What specific features have been implemented in the backend integration for Intelligent AI?","answer":"The features implemented include GPT-4o quote extraction and evidence-based Indigenous impact scoring.","context":"These features enhance the platform's capabilities in providing relevant analysis based on Indigenous perspectives.","document":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited)","category":"Principle","section":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited) > Current Status: WORKING BUT BLOCKED BY OPENAI RATE LIMIT > What's Working âœ…","confidence":1}
{"type":"Fact","question":"Are both old and new systems available within the Empathy Ledger platform?","answer":"Yes, both the old and new systems are available side-by-side for users.","context":"This allows for a smoother transition and continuity for users familiar with the previous system.","document":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited)","category":"Principle","section":"âœ… Intelligent AI Integration - COMPLETE (Rate Limited) > Current Status: WORKING BUT BLOCKED BY OPENAI RATE LIMIT > What's Working âœ…","confidence":1}
{"type":"Practice","question":"What is the purpose of the OrganizationContext in the Super Admin multi-tenant implementation?","answer":"The OrganizationContext is a React context used for managing the selected organization state. It provides a globally accessible `selectedOrgId` and a method `setSelectedOrgId`, which enables organization switching throughout the admin interface.","context":"This is a core component that allows administrators to manage and switch between different organizations within the platform.","document":"Session Summary: Super Admin Multi-Tenant Implementation","category":"Principle","section":"Session Summary: Super Admin Multi-Tenant Implementation > What We Accomplished > âœ… Phase 1: Core Components (COMPLETE)","confidence":0.9}
{"type":"Fact","question":"What are the key features of the OrganizationContext in the multi-tenant implementation?","answer":"The key features of the OrganizationContext include managing the selected organization state, providing `selectedOrgId`, and allowing the use of `setSelectedOrgId` for organization switching in the admin interface.","context":"The OrganizationContext is essential for facilitating a seamless user experience when managing multiple organizations.","document":"Session Summary: Super Admin Multi-Tenant Implementation","category":"Principle","section":"Session Summary: Super Admin Multi-Tenant Implementation > What We Accomplished > âœ… Phase 1: Core Components (COMPLETE)","confidence":0.85}
{"type":"Principle","question":"What are the key elements to ensure in organization end-to-end testing?","answer":"The key elements to ensure in organization end-to-end testing include the creation of the organization (tenant + organization), database integrity to maintain proper relationships, data isolation to prevent cross-tenant contamination, functionality of the Stats API, and overall multi-tenant system integrity.","context":"This summarizes the critical components that should be verified during organization end-to-end testing.","document":"Organization End-to-End Testing Guide","category":"Principle","section":"Organization End-to-End Testing Guide > Test Results Summary","confidence":0.9}
{"type":"Practice","question":"What is the purpose of the OrganizationSelector component in the Super Admin Multi-Tenant Implementation?","answer":"The OrganizationSelector component serves as a dropdown for selecting an organization within the platform. It fetches all available organizations from the API and includes a special option for viewing 'All Organizations (Platform View)'.","context":"This component is crucial for enabling Super Admins to manage multiple organizations effectively.","document":"Session Summary: Super Admin Multi-Tenant Implementation","category":"Principle","section":"Session Summary: Super Admin Multi-Tenant Implementation > What We Accomplished > âœ… Phase 1: Core Components (COMPLETE)","confidence":0.9}
{"type":"Practice","question":"How does the OrganizationSelector component enhance user experience?","answer":"The OrganizationSelector component enhances user experience by providing a loading state with a skeleton UI, which indicates to the user that data is being fetched and improves perceived performance.","context":"A good user experience is essential for navigating a multi-tenant platform.","document":"Session Summary: Super Admin Multi-Tenant Implementation","category":"Principle","section":"Session Summary: Super Admin Multi-Tenant Implementation > What We Accomplished > âœ… Phase 1: Core Components (COMPLETE)","confidence":0.8}
{"type":"Fact","question":"How many active organizations are currently confirmed on the Empathy Ledger platform?","answer":"There are 5 active organizations confirmed on the Empathy Ledger platform, each with unique tenant isolation.","context":"This information highlights the multi-tenant capabilities of the platform.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ¢ Organizations: READY & CONFIGURED**","confidence":1}
{"type":"Fact","question":"What is the structure of tenant_id used in the Empathy Ledger platform?","answer":"The tenant_id structure across all data is properly configured to ensure unique identification for each organization.","context":"This is important for maintaining data integrity and organization isolation.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ¢ Organizations: READY & CONFIGURED**","confidence":1}
{"type":"Fact","question":"What types of organizations are supported on the Empathy Ledger platform?","answer":"The Empathy Ledger platform supports nonprofit and community organizations.","context":"This indicates the range of entities that can utilize the platform for storytelling.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ¢ Organizations: READY & CONFIGURED**","confidence":1}
{"type":"Fact","question":"What are the core features of the Storyteller Analytics System?","answer":"The core features of the Storyteller Analytics System include a Personal Analytics Dashboard for tracking storyteller impact metrics, AI Theme Intelligence for automatically extracting narrative themes, a Powerful Quotes Gallery for showcasing impactful moments with citation tracking, a Network Discovery Engine for connecting storytellers through AI, Beautiful Visualizations that present data in compelling ways, and Smart Recommendations for personalized growth insights.","context":"This information highlights the main functionalities offered by the Storyteller Analytics System.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸŽ¯ **Core Features Ready**","confidence":1}
{"type":"Principle","question":"How does AI Theme Intelligence benefit storytellers in the Storyteller Analytics System?","answer":"AI Theme Intelligence benefits storytellers by automatically identifying and extracting narrative themes from their content, allowing storytellers to better understand the essence and patterns of their narratives without manually analyzing them.","context":"This principle emphasizes the use of technology to enhance storytelling practices within the platform.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸŽ¯ **Core Features Ready**","confidence":0.9}
{"type":"Principle","question":"Why is the Personal Analytics Dashboard important for storytellers?","answer":"The Personal Analytics Dashboard is important for storytellers as it provides metrics on their impact, helping them assess their storytelling effectiveness and make informed decisions about their future narratives.","context":"Understanding the significance of self-assessment tools enhances the storytelling experience.","document":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE!","category":"Principle","section":"ðŸŒŸ Storyteller Analytics System - DEPLOYMENT COMPLETE! > âœ… What We've Built > ðŸŽ¯ **Core Features Ready**","confidence":0.95}
{"type":"Principle","question":"What is the focus of Pillar 6 in the Privacy Components Cultural Review?","answer":"Pillar 6 focuses on Privacy & Data Sovereignty, ensuring that these elements are fully implemented to protect the rights and data of Indigenous storytellers.","context":null,"document":"Privacy Components Cultural Review","category":"Principle","section":"Privacy Components Cultural Review > ðŸŽ¯ Executive Summary","confidence":1}
{"type":"Principle","question":"What do the Partnership Principles guarantee for storytellers?","answer":"The Partnership Principles ensure that storytellers retain full control over their narratives and data.","context":null,"document":"Privacy Components Cultural Review","category":"Principle","section":"Privacy Components Cultural Review > ðŸŽ¯ Executive Summary","confidence":1}
{"type":"Principle","question":"How is compliance with GDPR reflected in the Privacy Components Cultural Review?","answer":"GDPR Compliance is addressed with Articles 15 & 17 being properly implemented, which relates to the rights of individuals regarding their personal data.","context":null,"document":"Privacy Components Cultural Review","category":"Principle","section":"Privacy Components Cultural Review > ðŸŽ¯ Executive Summary","confidence":1}
{"type":"Principle","question":"What do the OCAP Principles signify in the context of the Privacy Components Cultural Review?","answer":"The OCAP Principles signify that Indigenous data sovereignty is embedded within the platform, reinforcing the rights of Indigenous peoples over their data.","context":null,"document":"Privacy Components Cultural Review","category":"Principle","section":"Privacy Components Cultural Review > ðŸŽ¯ Executive Summary","confidence":1}
{"type":"Fact","question":"What standards of accessibility does the platform adhere to?","answer":"The platform is compliant with WCAG 2.1 AA standards, ensuring it is accessible to all users.","context":null,"document":"Privacy Components Cultural Review","category":"Principle","section":"Privacy Components Cultural Review > ðŸŽ¯ Executive Summary","confidence":1}
{"type":"Practice","question":"How does the Intelligent Indigenous Impact Analyzer assess cultural sensitivity?","answer":"The Intelligent Indigenous Impact Analyzer uses a context-based assessment rather than relying solely on keyword matching, which ensures a more accurate evaluation of cultural sensitivity.","context":null,"document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 2. **Intelligent Indigenous Impact Analyzer** âœ…","confidence":0.9}
{"type":"Practice","question":"What scoring system does the Intelligent Indigenous Impact Analyzer use?","answer":"The analyzer provides evidence-based scores ranging from 0 to 100, avoiding arbitrary decimals like 0.6 or 0.9. This scoring is designed to reflect real differences in cultural sensitivity impact.","context":null,"document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 2. **Intelligent Indigenous Impact Analyzer** âœ…","confidence":0.9}
{"type":"Practice","question":"What are the depth levels used in the Indigenous Impact Analyzer?","answer":"The depth levels in the Indigenous Impact Analyzer include mention, description, demonstration, and transformation, allowing for a comprehensive assessment of cultural sensitivity.","context":null,"document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 2. **Intelligent Indigenous Impact Analyzer** âœ…","confidence":0.9}
{"type":"Practice","question":"How is transparency maintained in the scoring of the Indigenous Impact Analyzer?","answer":"The Intelligent Indigenous Impact Analyzer provides transparent reasoning for each score, enabling users to understand the basis for the assigned scores.","context":null,"document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 2. **Intelligent Indigenous Impact Analyzer** âœ…","confidence":0.9}
{"type":"Practice","question":"Can you provide an example of how the Intelligent Indigenous Impact Analyzer shows differences in impact scores?","answer":"Yes, the analyzer has been tested and it shows real differences in scores. For instance, an assessment may reveal a score of 85/100 for Jimmy and 40/100 for Melissa for the same dimension, indicating a significant variance in cultural impact.","context":null,"document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 2. **Intelligent Indigenous Impact Analyzer** âœ…","confidence":0.9}
{"type":"Fact","question":"How many locations were cleaned in the optimization process?","answer":"A total of 35 locations were cleaned during the optimization process, resulting in 89% complete structured data.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.9}
{"type":"Fact","question":"What was accomplished regarding duplicate locations?","answer":"Five duplicate locations were merged as part of the optimization process.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.9}
{"type":"Practice","question":"What is the purpose of the admin location manager UI?","answer":"The admin location manager UI, accessible at `/admin/locations`, was built to manage location data effectively.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.8}
{"type":"Practice","question":"What features does the location picker component include?","answer":"The location picker component includes an autocomplete feature to enhance user experience when selecting locations.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.8}
{"type":"Process","question":"What automation tasks were performed during the optimization of profiles?","answer":"The process included automated extraction of 58 profiles with location information in bio text and the auto-migration of these profiles, which doubled coverage.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.8}
{"type":"Fact","question":"What API endpoints were created related to locations and profiles?","answer":"The following API endpoints were created: `/api/locations` and `/api/profiles/[id]/locations`.","context":null,"document":"Session Summary - Profiles & Locations Optimization","category":"Principle","section":"Session Summary - Profiles & Locations Optimization > ðŸŽ‰ What We Accomplished > 1. âœ… Location System - COMPLETE","confidence":0.9}
{"type":"Practice","question":"What spelling conventions should be followed for table and column names in the Empathy Ledger platform?","answer":"For the Empathy Ledger platform, you should use Australian spelling for both table names and column names. For example, table names like `organisations` and column names such as `organisation_id` are correct, whereas `organizations` is incorrect.","context":"Spelling guidelines specifically address naming conventions for database elements.","document":"Spelling Guidelines - Empathy Ledger v2","category":"Principle","section":"Spelling Guidelines - Empathy Ledger v2 > ðŸš¨ Critical Rules - NEVER BREAK THESE > 2. **Database References**","confidence":1}
{"type":"Fact","question":"What recent fixes were implemented in the Seed Interview System as of October 11, 2025?","answer":"The recent fixes implemented include: 1. Fixed `user` undefined error in dev mode (Auth Bypass Bug); 2. Removed duplicate template endpoint (Duplicate GET Function); 3. Used service role client in dev mode to bypass RLS (RLS Policy Violation); 4. Updated to use proper `createSupabaseServiceClient()` (createServerClient API).","context":"These fixes enhance the functionality and reliability of the Seed Interview System.","document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > Current Status: âœ… FULLY FUNCTIONAL > Recent Fixes (October 11, 2025):","confidence":0.9}
{"type":"Practice","question":"What should developers do to address an Auth Bypass Bug in a development environment?","answer":"Developers should fix the 'user' undefined error that occurs in development mode to resolve the Auth Bypass Bug. This involves ensuring that user data is properly initialized and accessible during the authentication process.","context":null,"document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > Current Status: âœ… FULLY FUNCTIONAL > Recent Fixes (October 11, 2025):","confidence":0.8}
{"type":"Practice","question":"How can developers avoid RLS policy violations in the Seed Interview System?","answer":"To avoid RLS (Row Level Security) policy violations in the Seed Interview System, developers should utilize a service role client when working in development mode. This ensures that proper access control is maintained during testing.","context":null,"document":"Seed Interview System - Testing & Status Report","category":"Principle","section":"Seed Interview System - Testing & Status Report > Current Status: âœ… FULLY FUNCTIONAL > Recent Fixes (October 11, 2025):","confidence":0.85}
{"type":"Procedure","question":"What are the steps to complete a project-specific outcomes tracker?","answer":"1. Admin completes 'Full Setup' seed interview for a project. 2. AI extracts expected outcomes from Q2 (success definition) and Q5 (how you'll know). 3. When analyzing transcripts, AI finds evidence of those specific outcomes. 4. Scores each outcome by depth: not_mentioned â†’ mentioned â†’ described â†’ demonstrated. 5. Shows results in a beautiful UI with quotes, storytellers, and progress tracking.","context":"This process highlights how to utilize the AI for effective outcomes tracking within a project.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.9}
{"type":"Fact","question":"What is the completion status of the Project-Specific Outcomes Tracker?","answer":"The backend and frontend of the Project-Specific Outcomes Tracker are both 100% complete.","context":"The completion status indicates full readiness for using the tracker in projects.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.95}
{"type":"Practice","question":"How does the AI score the expected outcomes of a project?","answer":"The AI scores each expected outcome by depth using the following scale: not_mentioned, mentioned, described, and demonstrated.","context":"This scoring system allows for measuring the clarity and visibility of outcomes within interviews.","document":"âœ… Session Complete - Project Outcomes & Ollama Integration","category":"Principle","section":"âœ… Session Complete - Project Outcomes & Ollama Integration > ðŸŽ¯ What Was Accomplished > 1. **Project-Specific Outcomes Tracker** (Backend 100% Complete, Frontend 100% Complete)","confidence":0.85}
{"type":"Principle","question":"What is the significance of cultural sensitivity in the context of Claude 3.5?","answer":"Cultural sensitivity in Claude 3.5 highlights its training on ethical AI principles, enabling it to handle discussions and interactions in a manner that respects and acknowledges diverse cultural contexts.","context":"This reflects the platform's commitment to serving Indigenous communities with appropriate care and understanding.","document":"âœ… Claude 3.5 Sonnet Integration - COMPLETE","category":"Principle","section":"âœ… Claude 3.5 Sonnet Integration - COMPLETE > Why Claude > GPT-4o > Quality Benefits:","confidence":0.9}
{"type":"Principle","question":"How does Claude 3.5 understand emotional tone?","answer":"Claude 3.5 demonstrates a nuanced understanding by being superior at detecting emotional tone and significance, which aids in making interactions more relevant and empathetic.","context":"This is particularly important when engaging with storytelling within Indigenous communities.","document":"âœ… Claude 3.5 Sonnet Integration - COMPLETE","category":"Principle","section":"âœ… Claude 3.5 Sonnet Integration - COMPLETE > Why Claude > GPT-4o > Quality Benefits:","confidence":0.85}
{"type":"Principle","question":"What does transparent reasoning mean in the context of Claude 3.5?","answer":"Transparent reasoning in Claude 3.5 refers to its ability to provide explainable decisions, allowing users to understand the rationale behind its outputs.","context":"This aligns with the platform's goal of fostering trust and clarity in AI-generated content.","document":"âœ… Claude 3.5 Sonnet Integration - COMPLETE","category":"Principle","section":"âœ… Claude 3.5 Sonnet Integration - COMPLETE > Why Claude > GPT-4o > Quality Benefits:","confidence":0.88}
{"type":"Fact","question":"What is the context length capacity of Claude 3.5?","answer":"Claude 3.5 has a context window capacity of 200K tokens, enabling it to manage and recall extensive information for more coherent conversations.","context":"This feature is especially beneficial for storytelling purposes where detailed narratives are involved.","document":"âœ… Claude 3.5 Sonnet Integration - COMPLETE","category":"Principle","section":"âœ… Claude 3.5 Sonnet Integration - COMPLETE > Why Claude > GPT-4o > Quality Benefits:","confidence":0.9}
{"type":"Fact","question":"What mechanisms are used to protect admin-only routes in the Empathy Ledger platform?","answer":"The admin-only routes are protected by checking user roles through authentication hooks such as 'isSuperAdmin' and 'isAdmin'. If a user does not have these roles, they are redirected to the storyteller's page.","context":"This mechanism ensures that only authorized users can access certain routes.","document":"Public vs Admin Views - Implementation Complete âœ…","category":"Principle","section":"Public vs Admin Views - Implementation Complete âœ… > Changes Made > 1. **Admin-Only Routes Protected** ðŸ”’","confidence":0.9}
{"type":"Procedure","question":"How does the user redirection work for unauthorized access in the Empathy Ledger platform?","answer":"When a user attempts to access admin-only routes, a useEffect hook checks if the user is a super admin or admin. If the user is neither, they are redirected to the relevant storyteller page using the redirect function.","context":"This procedure is essential for maintaining security and access control within the platform.","document":"Public vs Admin Views - Implementation Complete âœ…","category":"Principle","section":"Public vs Admin Views - Implementation Complete âœ… > Changes Made > 1. **Admin-Only Routes Protected** ðŸ”’","confidence":0.8}
{"type":"Principle","question":"What does the Empathy Ledger platform prioritize in terms of cultural identity?","answer":"The Empathy Ledger platform prioritizes cultural identity through various attributes such as cultural affiliations, cultural background, and cultural protocols. This commitment ensures that user profiles reflect their unique cultural identities appropriately.","context":null,"document":"Empathy Ledger v2 - Database Schema Analysis & Comparison","category":"Principle","section":"Empathy Ledger v2 - Database Schema Analysis & Comparison > ðŸ—ï¸ WHAT'S ALREADY BUILT (Foundation Analysis) > Core Database Tables - **FULLY IMPLEMENTED** > 1. **`profiles` Table** - â­ **SOPHISTICATED & COMPLETE**","confidence":0.9}
{"type":"Principle","question":"What accessibility features does the Empathy Ledger include?","answer":"The Empathy Ledger includes accessibility features such as accessibility needs and dietary requirements, aiming to accommodate users with various needs to ensure inclusivity.","context":null,"document":"Empathy Ledger v2 - Database Schema Analysis & Comparison","category":"Principle","section":"Empathy Ledger v2 - Database Schema Analysis & Comparison > ðŸ—ï¸ WHAT'S ALREADY BUILT (Foundation Analysis) > Core Database Tables - **FULLY IMPLEMENTED** > 1. **`profiles` Table** - â­ **SOPHISTICATED & COMPLETE**","confidence":0.9}
{"type":"Principle","question":"Why is a multi-language support feature important for the Empathy Ledger?","answer":"Multi-language support is important for the Empathy Ledger as it allows users to communicate in their preferred languages, promoting greater engagement and understanding among diverse Indigenous communities.","context":null,"document":"Empathy Ledger v2 - Database Schema Analysis & Comparison","category":"Principle","section":"Empathy Ledger v2 - Database Schema Analysis & Comparison > ðŸ—ï¸ WHAT'S ALREADY BUILT (Foundation Analysis) > Core Database Tables - **FULLY IMPLEMENTED** > 1. **`profiles` Table** - â­ **SOPHISTICATED & COMPLETE**","confidence":0.9}
{"type":"Practice","question":"What tasks were completed during the activation of the Individual Analytics System?","answer":"The completed tasks include the creation and deployment of a custom exec function for programmatic SQL execution, successful creation of all 6 analytics tables with the proper structure, execution of 42 SQL sections without errors (including tables, indexes, policies, and permissions), implementation of RLS policies for data security, and granting of database permissions to service roles and authenticated users.","context":"This is a summary of the activation process for the Individual Analytics System, highlighting the successful deployment tasks.","document":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS!","category":"Principle","section":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS! > ðŸ“‹ **DEPLOYMENT SUMMARY** > âœ… **COMPLETED TASKS** > **1. Schema Deployment** - SUCCESS âœ…","confidence":0.9}
{"type":"Practice","question":"What is the purpose of RLS policies in the Individual Analytics System?","answer":"RLS (Row-Level Security) policies are implemented in the Individual Analytics System to ensure data security and user privacy by restricting access to data at the row level based on the user's identity or role.","context":"RLS policies are important for maintaining the integrity and confidentiality of user data within the analytics system.","document":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS!","category":"Principle","section":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS! > ðŸ“‹ **DEPLOYMENT SUMMARY** > âœ… **COMPLETED TASKS** > **1. Schema Deployment** - SUCCESS âœ…","confidence":0.8}
{"type":"Fact","question":"How many analytics tables were created during the deployment of the Individual Analytics System?","answer":"A total of 6 analytics tables were successfully created during the deployment.","context":"This is part of the schema deployment for the Individual Analytics System.","document":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS!","category":"Principle","section":"ðŸŽ‰ Individual Analytics System - ACTIVATION SUCCESS! > ðŸ“‹ **DEPLOYMENT SUMMARY** > âœ… **COMPLETED TASKS** > **1. Schema Deployment** - SUCCESS âœ…","confidence":0.9}
{"type":"Procedure","question":"How can I add transcripts to Kristy's profile using the API?","answer":"To add transcripts to Kristy's profile via the API, you can use the following cURL command: \n\n```bash\ncurl -X POST http://localhost:3030/api/transcripts \n  -H \"Content-Type: application/json\" \n  -d '{\n    \"storyteller_id\": \"b59a1f4c-94fd-4805-a2c5-cac0922133e0\",\n    \"title\": \"Kristy Bloomfield - Community Leadership\",\n    \"transcript_content\": \"[Your transcript text here...]\",\n    \"status\": \"completed\",\n    \"word_count\": 5000\n  }'\n``` \n\nMake sure to replace `[Your transcript text here...]` with the actual content of the transcript.","context":"This API method allows for bulk uploads of transcripts linked to storyteller profiles.","document":"Transcript â†’ Story Workflow Guide","category":"Procedure","section":"Transcript â†’ Story Workflow Guide > ðŸ“ Step 1: Add New Transcripts > How to Add Transcripts to Kristy's Profile","confidence":0.9}
{"type":"Principle","question":"What are the critical quality rules for quote extraction in the Claude 3.5 Sonnet V2 integration?","answer":"The critical quality rules dictate that quotes must be complete, coherent sentences that exist word-for-word in the transcript, carry clear meaning and proper grammar, and demonstrate depth and insight. If no high-quality quotes exist, the system should return an empty array and maintain these standards by not lowering the quality to include low-quality quotes.","context":"These rules help ensure the integrity and quality of the content extracted for the platform.","document":"Claude 3.5 Sonnet V2 Integration - COMPLETE","category":"Principle","section":"Claude 3.5 Sonnet V2 Integration - COMPLETE > What Was Implemented > 1. New Claude Quote Extractor V2 > Anti-Fabrication System","confidence":1}
{"type":"Principle","question":"What is the significance of traditional knowledge in community work?","answer":"Traditional knowledge plays a foundational role in community work by connecting individuals to their cultural identity and supporting personal growth. It is crucial for maintaining cultural heritage and ensuring that community programs reflect the values and experiences of the community members.","context":"Emphasizes the importance of cultural roots in personal and communal development.","document":"ðŸŽ¯ AI Quality Upgrade - COMPLETE & PRODUCTION READY","category":"Principle","section":"ðŸŽ¯ AI Quality Upgrade - COMPLETE & PRODUCTION READY > What You Get Now > âœ… NEW (What You Have Now):","confidence":0.9}
{"type":"Principle","question":"How can community members empower themselves in the context of community programs?","answer":"Community members can empower themselves by actively participating in local programs and asserting their role in decision-making processes. This involvement leads to greater self-determination and fosters local leadership, ensuring that community initiatives align with the needs and aspirations of the community.","context":"Encourages community engagement and ownership of local programs.","document":"ðŸŽ¯ AI Quality Upgrade - COMPLETE & PRODUCTION READY","category":"Principle","section":"ðŸŽ¯ AI Quality Upgrade - COMPLETE & PRODUCTION READY > What You Get Now > âœ… NEW (What You Have Now):","confidence":0.9}
{"type":"Fact","question":"What is the token per minute (TPM) limit for Anthropic Claude?","answer":"The token per minute (TPM) limit for Anthropic Claude is 500K, which is 2.5 times more than the GPT-4o-mini.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Fact","question":"What is the context window size for Anthropic Claude compared to GPT-4o?","answer":"Anthropic Claude has a context window of 200K, while GPT-4o has a context window of 128K.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Fact","question":"How does Anthropic Claude perform in terms of nuanced analysis?","answer":"Anthropic Claude is better at nuanced analysis, particularly regarding cultural sensitivity and Indigenous contexts.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Fact","question":"What is the cost per million input tokens for Anthropic Claude?","answer":"The cost for Anthropic Claude is $3 per million input tokens, compared to $5 per million for GPT-4o.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Fact","question":"How does the response speed of Anthropic Claude compare to GPT-4o?","answer":"In practice, Anthropic Claude provides faster responses compared to GPT-4o.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Practice","question":"What changes are needed to implement Anthropic Claude instead of GPT-4o?","answer":"To implement Anthropic Claude, you need similar code changes; you just swap the API client.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":1}
{"type":"Procedure","question":"What are the steps for creating a storyteller and uploading a video transcript in the Empathy Ledger platform?","answer":"To create a storyteller and upload a video transcript, follow these steps: 1. Go to `/admin/storytellers` and select 'Create storyteller'. 2. Fill in the storyteller's name, bio, and details. 3. Navigate to `/admin/transcripts` and select 'Create transcript'. 4. Copy and paste the transcript text. 5. Enter the video URL. 6. Upload a thumbnail image manually. 7. Link the transcript to the relevant project. 8. Repeat this process as necessary for additional storytellers or transcripts.","context":"This process is part of the bulk upload guide aimed at managing video and transcript submissions efficiently.","document":"Bulk Upload Guide: Efficient Video & Transcript Management","category":"Principle","section":"Bulk Upload Guide: Efficient Video & Transcript Management > Current Manual Process (Slow)","confidence":0.9}
{"type":"Fact","question":"What are the benefits of goods delivery according to the Fixed GOODS Analysis?","answer":"The benefits of goods delivery according to the Fixed GOODS Analysis include better sleep and reduced floor sleeping after bed delivery, improved hygiene and dignity from reliable washing machines, reduced household stress and immediate morale lift, reduced respiratory and skin infections, increased household wellbeing and safety especially for women and girls, growing community capability in manufacturing, repair, and design, sustained local employment and income from community-owned production, and community requests for more products which signal trust and fit-for-purpose design.","context":"These benefits reflect the positive impact of reliable goods on community wellbeing.","document":"âœ… READY TO TEST: Fixed GOODS Analysis","category":"Principle","section":"âœ… READY TO TEST: Fixed GOODS Analysis > New Success Criteria (What Claude NOW Looks For)","confidence":0.9}
{"type":"Principle","question":"What core values does the Fixed GOODS Analysis emphasize?","answer":"The Fixed GOODS Analysis emphasizes core values such as improved community wellbeing, dignity, safety (especially for women and girls), and the importance of community-owned production for local employment and capability.","context":"These values guide the analysis and implementation of goods delivery in the community.","document":"âœ… READY TO TEST: Fixed GOODS Analysis","category":"Principle","section":"âœ… READY TO TEST: Fixed GOODS Analysis > New Success Criteria (What Claude NOW Looks For)","confidence":0.85}
{"type":"Fact","question":"What are the main components of the Empathy Ledger database?","answer":"The main components of the Empathy Ledger database include stories (published narratives), profiles (users and storytellers), transcripts (raw interview content), organizations (supporting a multi-tenant structure), and projects (storytelling initiatives).","context":"These components indicate the breadth of content managed within the platform.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Fact","question":"How many references are there for stories in the Empathy Ledger?","answer":"There are 235 references for stories in the Empathy Ledger, indicating a rich collection of published narratives.","context":"Stories form a core part of the platform's offerings.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Fact","question":"What is the reference count for user and storyteller profiles in the Empathy Ledger?","answer":"There are 214 references for user and storyteller profiles in the Empathy Ledger.","context":"Profiles are crucial for connecting and engaging with the user base.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Fact","question":"How many references does the Empathy Ledger have for transcripts?","answer":"The Empathy Ledger has 110 references for transcripts, which consists of raw interview content.","context":"Transcripts serve as an important source of authentic voices and experiences.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Principle","question":"What is the core mission of the Empathy Ledger?","answer":"The core mission of the Empathy Ledger is to partner with Indigenous communities in their storytelling journeys, ensuring that the control and leadership of these narratives remains firmly with the storytellers.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.9}
{"type":"Principle","question":"How does the Empathy Ledger approach cultural sensitivity?","answer":"Cultural safety is foundational to the Empathy Ledger, meaning that it is intrinsic to the platform's design and operation, rather than an add-on or afterthought.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.8}
{"type":"Method","question":"Who leads storytelling on the Empathy Ledger platform?","answer":"Storytellers are the leaders on the Empathy Ledger platform, while the organization provides support to ensure their narratives are told with respect and integrity.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.85}
{"type":"Method","question":"How does the Empathy Ledger integrate Indigenous expertise?","answer":"The Empathy Ledger is designed as a universal platform with guidance from Indigenous expertise, which informs its development and features to reflect cultural sensitivity.","context":null,"document":"Empathy Ledger - Mission & Strategic Wiki","category":"Practice","section":"Empathy Ledger - Mission & Strategic Wiki > ðŸŽ¯ Core Mission","confidence":0.85}
{"type":"Fact","question":"What profiles were migrated in the JusticeHub integration?","answer":"The profiles migrated in the JusticeHub integration included the fields: `justicehub_enabled`, `justicehub_role`, `justicehub_featured`, and `justicehub_synced_at`.","context":"Details regarding the database migration applied during the JusticeHub integration.","document":"âœ… JusticeHub Integration - COMPLETE!","category":"Principle","section":"âœ… JusticeHub Integration - COMPLETE! > What Was Done > 1. âœ… Database Migration Applied","confidence":0.9}
{"type":"Fact","question":"What organization fields were included in the JusticeHub integration?","answer":"The organization fields included in the JusticeHub integration were `justicehub_enabled` and `justicehub_synced_at`.","context":"These fields were part of the database migration related to organizations during the JusticeHub integration.","document":"âœ… JusticeHub Integration - COMPLETE!","category":"Principle","section":"âœ… JusticeHub Integration - COMPLETE! > What Was Done > 1. âœ… Database Migration Applied","confidence":0.9}
{"type":"Fact","question":"What project fields were migrated for the JusticeHub integration?","answer":"The project fields migrated for the JusticeHub integration included `justicehub_enabled`, `justicehub_program_type`, and `justicehub_synced_at`.","context":"This information pertains to the data integration process concerning projects in the JusticeHub framework.","document":"âœ… JusticeHub Integration - COMPLETE!","category":"Principle","section":"âœ… JusticeHub Integration - COMPLETE! > What Was Done > 1. âœ… Database Migration Applied","confidence":0.9}
{"type":"Procedure","question":"What are the steps to take before writing any database migration in Empathy Ledger?","answer":"Before writing any database migration, follow these steps: 1. Check the current production schema by running the command `npm run db:status`. 2. Verify that the table or column exists by executing `npm run db:sql` followed by `\t table_name`. 3. Document the changes you are planning to make in a file named `EXECUTE_PHASE_X.md`.","context":"These steps are crucial to ensure the integrity and accuracy of the database migration process.","document":"Database Best Practices - Empathy Ledger v2","category":"Principle","section":"Database Best Practices - Empathy Ledger v2 > 1. **Migration Workflow (THE RIGHT WAY)** > Before Writing ANY Migration","confidence":0.9}
{"type":"Fact","question":"What files are included in the '/docs/platform' directory?","answer":"The '/docs/platform' directory includes the following files: 'EMPATHY_LEDGER_PLATFORM_PROSPECTUS.md' for platform overview, 'EMPATHY_LEDGER_COMPLETE_PLATFORM_PROSPECTUS.md' for a detailed prospectus, 'PRODUCTION_READINESS_REPORT.md' for production deployment status, 'SITE_AUDIT_REPORT.md' for site audit findings, and 'DEPLOYMENT_COMPLETE.md' for deployment documentation.","context":"These files are part of the file organization guide for the Empathy Ledger platform.","document":"File Organization Guide","category":"Principle","section":"File Organization Guide > ðŸ“ Project Structure > ðŸ“š Documentation (`/docs`) > Platform Documentation (`/docs/platform`)","confidence":0.9}
{"type":"Principle","question":"What is the purpose of having detailed documentation in the Empathy Ledger platform's directory?","answer":"The purpose of having detailed documentation in the Empathy Ledger platform's directory is to ensure comprehensive understanding and transparency regarding the platform's operations, deployment status, and overall readiness for production use, which aligns with the platform's commitment to cultural sensitivity and community engagement.","context":"This principle supports the idea that well-structured documentation is crucial for effective collaboration and accountability.","document":"File Organization Guide","category":"Principle","section":"File Organization Guide > ðŸ“ Project Structure > ðŸ“š Documentation (`/docs`) > Platform Documentation (`/docs/platform`)","confidence":0.8}
{"type":"Fact","question":"What critical issue was found regarding the relationship between stories and authors in the database?","answer":"The critical issue identified is that the stories table contains both `author_id` and `storyteller_id` fields, but all 550 stories use `author_id`, leaving all `storyteller_id` values as NULL.","context":"This issue arises because the API expects `storyteller_id` to be populated, resulting in zero results from certain API calls.","document":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT","category":"Principle","section":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT > âŒ CRITICAL ISSUES FOUND > 1. **Story-Author Relationship Confusion** ðŸš¨","confidence":0.9}
{"type":"Warning","question":"What impact does the confusion between `author_id` and `storyteller_id` have on API functionality?","answer":"The impact is that APIs which expect to retrieve data using `storyteller_id` return zero results, as all `storyteller_id` fields are currently set to NULL.","context":"This issue affects the functionality of routes such as `/stories`, `/storytellers`, and `/storytellers/[id]`.","document":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT","category":"Principle","section":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT > âŒ CRITICAL ISSUES FOUND > 1. **Story-Author Relationship Confusion** ðŸš¨","confidence":0.85}
{"type":"Fact","question":"How many stories are currently affected by the `author_id` and `storyteller_id` issue?","answer":"All 550 stories in the database are affected by the issue, as they all utilize `author_id` while having `storyteller_id` set to NULL.","context":"This highlights a significant inconsistency in how authors and storytellers are represented in the database.","document":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT","category":"Principle","section":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT > âŒ CRITICAL ISSUES FOUND > 1. **Story-Author Relationship Confusion** ðŸš¨","confidence":0.9}
{"type":"Fact","question":"Which API routes are affected by the confusion between the `author_id` and `storyteller_id` fields?","answer":"The affected API routes include `/stories`, `/storytellers`, and `/storytellers/[id]`.","context":"These routes may not function properly due to the lack of data in the `storyteller_id` field.","document":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT","category":"Principle","section":"ðŸ” DATABASE & FRONTEND COMPREHENSIVE AUDIT REPORT > âŒ CRITICAL ISSUES FOUND > 1. **Story-Author Relationship Confusion** ðŸš¨","confidence":0.9}
{"type":"Fact","question":"What is the purpose of organizations in the Empathy Ledger?","answer":"Organizations in the Empathy Ledger support a multi-tenant structure, with 77 references indicating their role in community collaboration.","context":"This structure is essential for including diverse Indigenous communities.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Fact","question":"How many projects are referenced in the Empathy Ledger?","answer":"The Empathy Ledger references 63 projects, which are storytelling initiatives designed to foster engagement and education.","context":"Projects help in promoting storytelling and sharing cultural narratives.","document":"Empathy Ledger v2 - World-Class Database Strategy","category":"Principle","section":"Empathy Ledger v2 - World-Class Database Strategy > Core Findings (From Comprehensive Analysis) > Database Health: GOOD Core, BLOATED Periphery âœ…/âš ï¸","confidence":0.9}
{"type":"Principle","question":"How does the 'profiles' table maintain cultural sensitivity?","answer":"The 'profiles' table maintains cultural sensitivity through fields that allow users to specify their cultural affiliations, languages spoken, cultural background, and important cultural permissions and protocols, ensuring that cultural identity and privacy are respected and supported.","context":"These features help to align the platform with cultural safety protocols.","document":"Empathy Ledger v2 - Database Schema Analysis & Comparison","category":"Principle","section":"Empathy Ledger v2 - Database Schema Analysis & Comparison > ðŸ—ï¸ WHAT'S ALREADY BUILT (Foundation Analysis) > Core Database Tables - **FULLY IMPLEMENTED** > 1. **`profiles` Table** - â­ **SOPHISTICATED & COMPLETE**","confidence":0.85}
{"type":"Warning","question":"What is a critical issue regarding AI in project analysis?","answer":"A critical issue is the fabrication of quotes, which can misrepresent the actual voices and viewpoints of individuals involved in the project. For example, quotes about 'beds', 'showers', and 'hygiene' do not exist in the transcripts from relevant individuals.","context":"This issue emphasizes the importance of accuracy and integrity in representing Indigenous voices.","document":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis","category":"Practice","section":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis > The Problem > Example of Fabricated Quotes","confidence":0.9}
{"type":"Fact","question":"What are some themes discussed in the transcripts of the individuals involved in the GOODS project analysis?","answer":"The themes discussed in the transcripts include cultural connection to country, traditional ownership, working with elders on artifacts, and community leadership.","context":"These themes highlight the cultural sensitivity and depth of knowledge present within Indigenous communities.","document":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis","category":"Practice","section":"CRITICAL ISSUE: AI Quote Fabrication in GOODS Project Analysis > The Problem > Example of Fabricated Quotes","confidence":0.95}
{"type":"Practice","question":"What is the purpose of the 'analyze-with-intelligent-ai.ts' demo script?","answer":"The 'analyze-with-intelligent-ai.ts' demo script serves as a full demonstration of integrating intelligent AI systems into the Empathy Ledger platform, showcasing how AI can analyze storytelling data effectively.","context":"This script is part of the completed features in the integration process.","document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 3. **Demonstration Scripts** âœ…","confidence":0.9}
{"type":"Practice","question":"How does the 'test-quote-extraction-comparison.ts' script function?","answer":"The 'test-quote-extraction-comparison.ts' script performs a side-by-side comparison of quote extraction methods, allowing developers to assess the effectiveness and accuracy of different approaches to quote extraction in storytelling.","context":"This script is intended to improve the precision of AI functionalities within the platform.","document":"âœ… Ready to Integrate - Intelligent AI Systems","category":"Practice","section":"âœ… Ready to Integrate - Intelligent AI Systems > ðŸŽ‰ What's Been Completed > 3. **Demonstration Scripts** âœ…","confidence":0.85}
{"type":"Procedure","question":"What is the process for retrieving platform-wide statistics as a super admin?","answer":"To retrieve platform-wide statistics, follow these steps: 1. The user selects 'All Organizations (Platform View)'. 2. Call the API endpoint GET /api/admin/stats/platform. 3. Authenticate the request by verifying the user as a super admin. 4. Create a service role client to bypass row-level security and gain full database access. 5. Query all organizations without an organization_id filter. 6. Aggregate statistics by querying stories, transcripts, and profile organizations. 7. Calculate totals such as total organizations, total stories, and other relevant statistics. 8. The response will provide aggregated stats along with details of all organizations.","context":"This describes the flow for obtaining stats across all organizations in the platform.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > API Architecture > Platform Stats Flow (All Organizations)","confidence":0.9}
{"type":"Fact","question":"What are the total counts for organizations, stories, transcripts, and members in the platform?","answer":"The platform currently contains the following totals: Total organizations: 18, Total stories: 301, Total transcripts: 222, Total members: 247.","context":"This data is part of the aggregated statistics returned in the API response.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > API Architecture > Platform Stats Flow (All Organizations)","confidence":0.95}
{"type":"Process","question":"What SQL queries are involved in aggregating statistics across all organizations?","answer":"The SQL queries involved in aggregating statistics are: 1. SELECT * FROM organizations ORDER BY name; 2. SELECT * FROM stories; 3. SELECT * FROM transcripts; 4. SELECT * FROM profile_organizations. Note that these queries do not filter by organization_id.","context":"These queries are used to gather data needed for calculating platform-wide statistics.","document":"Super Admin Architecture Diagram","category":"Procedure","section":"Super Admin Architecture Diagram > API Architecture > Platform Stats Flow (All Organizations)","confidence":0.85}
{"type":"Procedure","question":"How do I define what success looks like for a specific project on the Empathy Ledger platform?","answer":"As a Project Manager, you should clearly articulate the goals and success criteria tailored to the specific project, ensuring alignment with community expectations and values.","context":"User stories highlight the importance of contextualizing success to the community's needs.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As a Project Manager:","confidence":0.9}
{"type":"Procedure","question":"What steps should I take to specify expected outcomes that matter to our community?","answer":"Begin by engaging with community stakeholders to understand their priorities and desired impacts, then document these expected outcomes clearly within the project framework.","context":"This is part of user storytelling aimed at aligning project goals with community needs.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As a Project Manager:","confidence":0.85}
{"type":"Procedure","question":"Can I incorporate existing documents into my project context management?","answer":"Yes, you can paste in existing documents such as theory of change or logic models to provide background context and align your project with established frameworks.","context":"This allows for a seamless integration of existing knowledge into your project planning.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As a Project Manager:","confidence":0.9}
{"type":"Procedure","question":"How can AI assist in structuring my project information?","answer":"You can utilize AI features on the platform to analyze your free-form text, extracting key themes and structure which helps in organizing your project context effectively.","context":"Leveraging AI can streamline the project management process by enhancing clarity in project documentation.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As a Project Manager:","confidence":0.8}
{"type":"Principle","question":"What is the core value proposition of the Empathy Ledger?","answer":"The core value proposition of the Empathy Ledger includes being a universal storytelling platform that supports individuals, communities, organizations, and enterprises. It emphasizes cultural sovereignty by respecting Indigenous protocols and community values, aims for multi-generational impact by preserving knowledge and stories for future generations, tracks measurable social outcomes related to community health, engagement, and cultural vitality, and features a scalable architecture that accommodates both individual storytellers and large organizations.","context":"This summary outlines the fundamental values that guide the Empathy Ledger's operations and purpose.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary > Core Value Proposition","confidence":0.9}
{"type":"Principle","question":"How does the Empathy Ledger support cultural sovereignty?","answer":"The Empathy Ledger supports cultural sovereignty by incorporating built-in respect for Indigenous protocols and community values within its platform. This ensures that storytelling practices align with the cultural and ethical expectations of the communities it serves.","context":"Cultural sovereignty is an essential aspect of the Empathy Ledger's commitment to Indigenous communities.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary > Core Value Proposition","confidence":0.85}
{"type":"Principle","question":"What type of impact does the Empathy Ledger aim for?","answer":"The Empathy Ledger aims for a multi-generational impact by preserving knowledge and stories for future generations. This goal highlights the platform's role in ensuring that cultural narratives endure over time.","context":"The commitment to multi-generational impact is a key principle of the Empathy Ledger's mission.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary > Core Value Proposition","confidence":0.8}
{"type":"Principle","question":"What outcomes does the Empathy Ledger strive to measure?","answer":"The Empathy Ledger strives to measure social outcomes such as community health, engagement, and cultural vitality. This focus allows for tracking the effectiveness of storytelling initiatives and their positive impact on communities.","context":"Measuring social outcomes is integral to demonstrating the value of the Empathy Ledger's platform.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary > Core Value Proposition","confidence":0.75}
{"type":"Principle","question":"What is the architectural design of the Empathy Ledger?","answer":"The Empathy Ledger features a scalable architecture that accommodates a wide range of users from individual storytellers to organizations with multi-thousand members. This flexibility allows the platform to serve diverse storytelling needs effectively.","context":"The scalable architecture of the Empathy Ledger is designed to support both individual and collective storytelling efforts.","document":"Empathy Ledger: Complete Platform Prospectus","category":"Principle","section":"Empathy Ledger: Complete Platform Prospectus > Executive Summary > Core Value Proposition","confidence":0.8}
{"type":"Procedure","question":"What is the first step in the transcript upload process?","answer":"The first step in the transcript upload process is to prepare your transcript data, which includes the file name, title of the story, the storyteller's name, and the date recorded.","context":"This step ensures that all necessary metadata about the transcript is organized before uploading.","document":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way","category":"Procedure","section":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way > ðŸ“‹ Option 1: Quick Manual Upload (Fastest - Start Here!) > For Adding a Few Transcripts","confidence":0.9}
{"type":"Procedure","question":"What information should be included in the transcript file?","answer":"The transcript file should include the title of the story, the storyteller's name, the date recorded, and the actual transcript content.","context":"Including this information helps in properly categorizing and contextualizing the transcript on the platform.","document":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way","category":"Procedure","section":"ðŸŽ™ï¸ Transcript Upload Guide - The Easiest Way > ðŸ“‹ Option 1: Quick Manual Upload (Fastest - Start Here!) > For Adding a Few Transcripts","confidence":0.85}
{"type":"Practice","question":"How can I use the Anthropic Claude API in my application?","answer":"To use the Anthropic Claude API, you need to first install the SDK and set up your API key. Here's a sample implementation in TypeScript:\n\n```typescript\nimport Anthropic from '@anthropic-ai/sdk'\n\nconst anthropic = new Anthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY\n})\n\nconst message = await anthropic.messages.create({\n  model: 'claude-3-5-sonnet-20241022',\n  max_tokens: 4000,\n  messages: [\n    { role: 'user', content: yourPrompt }\n  ]\n})\n``` This code initializes the Anthropic SDK with your API key and sends a message to the Claude model, specifying the maximum tokens and the user's prompt.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":0.9}
{"type":"Fact","question":"What is the maximum number of tokens allowed when using the Anthropic Claude model?","answer":"When using the Anthropic Claude model, the maximum number of tokens allowed is 4000.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":0.9}
{"type":"Method","question":"What are the characteristics of the Anthropic Claude model?","answer":"The Anthropic Claude model is recognized for its high cultural sensitivity, making it a strong immediate option for applications that require careful handling of sensitive content.","context":null,"document":"AI Model Alternatives - Free & Open Source Options","category":"Principle","section":"AI Model Alternatives - Free & Open Source Options > **BETTER ALTERNATIVES:** > **1. ANTHROPIC CLAUDE (BEST IMMEDIATE OPTION)**","confidence":0.8}
{"type":"Practice","question":"How can I view all storytellers in a project on the Empathy Ledger platform?","answer":"You can view all storytellers involved in a project through the Project Storyteller Management UI, which provides a comprehensive list of all storytellers linked to the specific project.","context":null,"document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > What Works âœ… > 1. **Project Storyteller Management UI**","confidence":0.9}
{"type":"Practice","question":"What are the steps to add storytellers to a project in the Empathy Ledger?","answer":"To add storytellers to a project, use the dropdown menu provided in the Project Storyteller Management UI, where you can select and add storytellers to the project.","context":null,"document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > What Works âœ… > 1. **Project Storyteller Management UI**","confidence":0.9}
{"type":"Practice","question":"How can I remove storytellers from a project on the Empathy Ledger platform?","answer":"You can remove storytellers from a project by selecting them from the list in the Project Storyteller Management UI and choosing the option to remove them.","context":null,"document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > What Works âœ… > 1. **Project Storyteller Management UI**","confidence":0.9}
{"type":"Fact","question":"What information is shown regarding storyteller roles in a project?","answer":"The Project Storyteller Management UI displays the roles of each storyteller involved in the project, such as participant and lead.","context":null,"document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > What Works âœ… > 1. **Project Storyteller Management UI**","confidence":0.9}
{"type":"Fact","question":"How are transcripts linked to a project displayed in the Empathy Ledger?","answer":"The Project Storyteller Management UI lists the transcripts that are associated with the project, allowing users to easily access and review them.","context":null,"document":"Storyteller & Project Management - Review & Recommendations","category":"Practice","section":"Storyteller & Project Management - Review & Recommendations > What Works âœ… > 1. **Project Storyteller Management UI**","confidence":0.9}
{"type":"Warning","question":"What should I be cautious about when using AI tools for research analysis?","answer":"AI tools may produce incoherent or irrelevant responses, which can undermine the quality of research outputs. It is essential to critically evaluate the coherence and relevance of the outputs provided by the AI.","context":"The evaluation of GPT-4o-mini revealed instances of incoherent rambling that contributed little to the analysis.","document":"AI Tools Evaluation & Recommendation for Research Analysis","category":"Principle","section":"AI Tools Evaluation & Recommendation for Research Analysis > Current Performance Analysis > GPT-4o-mini (Current Primary)","confidence":0.95}
{"type":"Practice","question":"How does content hash tracking work in the Analysis Caching Implementation?","answer":"Content hash tracking detects changes in transcript content by generating a unique hash for each version of the content. If the hash differs from the previously stored value, it indicates that the content has changed, allowing for effective caching.","context":null,"document":"Analysis Caching Implementation âœ…","category":"Principle","section":"Analysis Caching Implementation âœ… > Solution Implemented > 1. Database Schema","confidence":0.9}
{"type":"Procedure","question":"How do I ensure project analysis reflects our definition of success?","answer":"Define success metrics that are based on community values and engage stakeholders to confirm that these metrics are included in the project analysis.","context":"Aligning project analysis with community-defined success metrics is crucial for meaningful outcomes.","document":"Organization & Project Context Management System","category":"Procedure","section":"Organization & Project Context Management System > User Stories > As a Project Manager:","confidence":0.85}
{"type":"Fact","question":"How many storytellers are linked to 'The Homestead' project?","answer":"Four storytellers are linked to 'The Homestead' project via the `project_storytellers` table.","context":"The storytellers linked to the project are supposed to provide transcripts and stories reflecting this connection.","document":"Oonchiumpa Storyteller & Project Management Analysis","category":"Principle","section":"Oonchiumpa Storyteller & Project Management Analysis > Issues Found > 4. **Project-Storyteller Links Exist But Aren't Used**","confidence":0.9}
{"type":"Practice","question":"What issue exists with the linkage between storytellers and 'The Homestead' project?","answer":"Although there are four linked storytellers, their transcripts and stories do not reflect this linkage, indicating a need for better integration or usage of the link.","context":"This issue highlights a gap in the storytelling process on the platform.","document":"Oonchiumpa Storyteller & Project Management Analysis","category":"Principle","section":"Oonchiumpa Storyteller & Project Management Analysis > Issues Found > 4. **Project-Storyteller Links Exist But Aren't Used**","confidence":0.85}
{"type":"Practice","question":"What is model-specific caching in the Analysis Caching Implementation?","answer":"Model-specific caching involves creating separate caches for different models like gpt-4o-mini, claude, etc., to optimize performance based on the specific requirements and characteristics of each model.","context":null,"document":"Analysis Caching Implementation âœ…","category":"Principle","section":"Analysis Caching Implementation âœ… > Solution Implemented > 1. Database Schema","confidence":0.85}
{"type":"Practice","question":"What is the benefit of using JSONB storage in the Analysis Caching Implementation?","answer":"JSONB storage provides a flexible data structure for analysis, allowing for easy storage and retrieval of complex data types, which can efficiently handle varying schema requirements.","context":null,"document":"Analysis Caching Implementation âœ…","category":"Principle","section":"Analysis Caching Implementation âœ… > Solution Implemented > 1. Database Schema","confidence":0.8}
{"type":"Process","question":"How does automatic cleanup work in the Analysis Caching Implementation?","answer":"Automatic cleanup ensures that when a project is removed, a cascade delete action is triggered to remove associated cache entries, helping maintain data integrity and optimize storage usage.","context":null,"document":"Analysis Caching Implementation âœ…","category":"Principle","section":"Analysis Caching Implementation âœ… > Solution Implemented > 1. Database Schema","confidence":0.85}
{"type":"Practice","question":"What is the purpose of RLS policies in the Analysis Caching Implementation?","answer":"RLS (Row-Level Security) policies are used to enforce secure access control, ensuring that only authorized users can access specific rows of data within the database, thereby enhancing the security of sensitive information.","context":null,"document":"Analysis Caching Implementation âœ…","category":"Principle","section":"Analysis Caching Implementation âœ… > Solution Implemented > 1. Database Schema","confidence":0.9}
{"type":"Process","question":"What is the process for generating TypeScript types from a PostgreSQL database in Supabase?","answer":"The process for generating TypeScript types from a PostgreSQL database in Supabase involves several steps: First, Supabase introspects the tables, columns, and relationships in the database. Next, it generates TypeScript interfaces based on this introspection. These interfaces are then saved to the file 'src/types/database.types.ts'. Finally, you can import these types into your code, ensuring full type safety.","context":"This process allows developers to work with typed data structures in their applications, enhancing code reliability.","document":"Supabase TypeScript Type Generation Guide","category":"Principle","section":"Supabase TypeScript Type Generation Guide > How It Works","confidence":1}
{"type":"Practice","question":"How do I run custom queries using Supabase?","answer":"To run custom queries using Supabase, first create a client using the 'createClient' function from the '@supabase/supabase-js' package with your Supabase URL and service role key. Then, use the 'from' method to specify the table you want to query, followed by 'select' to define the columns you're interested in. Finally, you can execute the query and handle the response accordingly.","context":"Example of querying a table in Supabase.","document":"Database Access Guide","category":"Principle","section":"Database Access Guide > âœ… Correct Way to Query Database > Run Custom Queries","confidence":0.9}
{"type":"Procedure","question":"What are the steps to create a Supabase client and execute a query?","answer":"1. Import the createClient function from the '@supabase/supabase-js' library. 2. Call createClient with your Supabase URL and service role key from environment variables. 3. Define an asynchronous function to execute your query. 4. Use the 'from' method to specify the table, followed by 'select' to retrieve desired columns and 'limit' if needed. 5. Handle the response by checking for data or errors and log the necessary information.","context":"General step-by-step procedure for using Supabase.","document":"Database Access Guide","category":"Principle","section":"Database Access Guide > âœ… Correct Way to Query Database > Run Custom Queries","confidence":0.9}
{"type":"Fact","question":"What package do I need to use to interact with Supabase in JavaScript?","answer":"You need the '@supabase/supabase-js' package to interact with Supabase in JavaScript.","context":"Info about the package required for Supabase interaction.","document":"Database Access Guide","category":"Principle","section":"Database Access Guide > âœ… Correct Way to Query Database > Run Custom Queries","confidence":0.95}
{"type":"Practice","question":"How can I check the status of the database in Empathy Ledger?","answer":"You can check the status of the database by running the command: `npm run db:status`. This command will show you the status of the Local database (whether it's running or stopped), the Remote database connection (whether it's connected or not), and the Migrations status (whether they are applied or pending).","context":null,"document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > What We Need âœ…","confidence":1}
{"type":"Practice","question":"What command do I use to run migrations in Empathy Ledger?","answer":"To run migrations in Empathy Ledger, you can use the command: `npm run db:migrate`. This command auto-detects the environment and applies the necessary migrations.","context":null,"document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > What We Need âœ…","confidence":1}
{"type":"Practice","question":"How can I execute an SQL query in Empathy Ledger?","answer":"You can execute an SQL query by running the command: `npm run db:sql \"SELECT * FROM stories LIMIT 5\"`. This command works in any environment to retrieve data from the database.","context":null,"document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > What We Need âœ…","confidence":1}
{"type":"Practice","question":"What is the command to sync the local and remote databases in Empathy Ledger?","answer":"To sync the local and remote databases in Empathy Ledger, use the command: `npm run db:sync`. This command will synchronize the data between your local and remote databases.","context":null,"document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > What We Need âœ…","confidence":1}
{"type":"Fact","question":"What visibility does the Empathy Ledger provide regarding database migrations?","answer":"The Empathy Ledger provides clear visibility into what migrations have been applied and where, allowing users to easily track the status and ensure proper database management.","context":null,"document":"Empathy Ledger - Database Workflow System","category":"Principle","section":"Empathy Ledger - Database Workflow System > The Core Issue (What You Identified) > What We Need âœ…","confidence":1}
{"type":"Principle","question":"Why is it important to never assume consent when working within the Empathy Ledger?","answer":"It is important to never assume consent in the Empathy Ledger because explicit storyteller permission is required to respect their rights and ensure their stories are shared in a manner that aligns with their cultural values and protocols.","context":null,"document":"Empathy Ledger Documentation Hub","category":"Principle","section":"Empathy Ledger Documentation Hub > Sacred Boundaries (NEVER)","confidence":1}
{"type":"Principle","question":"How does the Empathy Ledger prioritize design over cleverness?","answer":"The Empathy Ledger prioritizes simplicity over cleverness by ensuring that the platform's design and features are straightforward and accessible, avoiding unnecessary complexity that could hinder understanding and usability.","context":null,"document":"Empathy Ledger Documentation Hub","category":"Principle","section":"Empathy Ledger Documentation Hub > Sacred Boundaries (NEVER)","confidence":1}
{"type":"Principle","question":"What is the 'specs-before-code' philosophy in the Empathy Ledger?","answer":"The 'specs-before-code' philosophy in the Empathy Ledger emphasizes the importance of developing specifications prior to coding to ensure clarity, alignment with cultural protocols, and effective implementation of features.","context":null,"document":"Empathy Ledger Documentation Hub","category":"Principle","section":"Empathy Ledger Documentation Hub > Sacred Boundaries (NEVER)","confidence":1}
{"type":"Practice","question":"What is the function of the project-outcomes-tracker.ts?","answer":"The project-outcomes-tracker.ts is responsible for extracting project-specific outcomes from the project data, helping to monitor and evaluate success.","context":"This is part of the functionalities completed during the integration related to OLLAMA.","document":"ðŸŽ‰ Session Complete - October 11, 2025","category":"Principle","section":"ðŸŽ‰ Session Complete - October 11, 2025 > ðŸ¦™ GOAL 1: OLLAMA INTEGRATION (COMPLETE!) > What Was Accomplished > 1. All AI Modules Refactored (100%)","confidence":0.9}
{"type":"Practice","question":"How does the intelligent-quote-extractor.ts assist users?","answer":"The intelligent-quote-extractor.ts finds and retrieves powerful quotes that can be used to enhance storytelling and presentations on the platform.","context":"This tool contributes to the richness of content provided by the Empathy Ledger.","document":"ðŸŽ‰ Session Complete - October 11, 2025","category":"Principle","section":"ðŸŽ‰ Session Complete - October 11, 2025 > ðŸ¦™ GOAL 1: OLLAMA INTEGRATION (COMPLETE!) > What Was Accomplished > 1. All AI Modules Refactored (100%)","confidence":0.9}
{"type":"Practice","question":"What is the role of the intelligent-indigenous-impact-analyzer.ts?","answer":"The intelligent-indigenous-impact-analyzer.ts assesses various impact dimensions of projects, allowing for a deeper understanding of their effects on Indigenous communities.","context":"This tool plays a critical role in evaluating the efficacy of initiatives on the platform.","document":"ðŸŽ‰ Session Complete - October 11, 2025","category":"Principle","section":"ðŸŽ‰ Session Complete - October 11, 2025 > ðŸ¦™ GOAL 1: OLLAMA INTEGRATION (COMPLETE!) > What Was Accomplished > 1. All AI Modules Refactored (100%)","confidence":0.9}
{"type":"Practice","question":"What does the project-profile-extractor.ts do?","answer":"The project-profile-extractor.ts extracts contextual information from documents related to projects, aiding in the gathering of necessary background data.","context":"This function is essential for providing a comprehensive understanding of each project within the Empathy Ledger.","document":"ðŸŽ‰ Session Complete - October 11, 2025","category":"Principle","section":"ðŸŽ‰ Session Complete - October 11, 2025 > ðŸ¦™ GOAL 1: OLLAMA INTEGRATION (COMPLETE!) > What Was Accomplished > 1. All AI Modules Refactored (100%)","confidence":0.9}
{"type":"Practice","question":"What is profile completeness scoring in the context of Enhanced Storyteller Cards?","answer":"Profile completeness scoring assesses the extent to which a user's profile is fully developed and enriched with relevant information. This scoring helps identify areas where additional data may enhance the storytelling experience.","context":null,"document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ¤– AI-Driven Profile Enhancement","confidence":0.9}
{"type":"Method","question":"How is story theme extraction achieved through content analysis?","answer":"Story theme extraction is performed by analyzing the textual content of submitted stories to identify recurring themes and concepts. This allows for more targeted audience engagement and storytelling enhancement.","context":null,"document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ¤– AI-Driven Profile Enhancement","confidence":0.85}
{"type":"Practice","question":"What are smart tag suggestions with confidence scores?","answer":"Smart tag suggestions are automated recommendations that provide relevant tags for a story based on its content. Each suggestion comes with a confidence score indicating the strength of the recommendation, helping storytellers choose the most appropriate tags.","context":null,"document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ¤– AI-Driven Profile Enhancement","confidence":0.88}
{"type":"Practice","question":"What are evidence-based recommendations in the context of Enhanced Storyteller Cards?","answer":"Evidence-based recommendations are suggestions provided to users based on the analysis of previous successful storytelling patterns and outcomes. These recommendations aim to improve the quality and impact of new stories submitted to the platform.","context":null,"document":"Enhanced Storyteller Cards - Implementation Guide","category":"Principle","section":"Enhanced Storyteller Cards - Implementation Guide > Key Features > ðŸ¤– AI-Driven Profile Enhancement","confidence":0.9}
{"type":"Practice","question":"What features are included in the OrganizationContextManager component?","answer":"The OrganizationContextManager component includes a full CRUD interface with a tabbed layout consisting of four tabs: Core Identity, Approach, Impact, and Metadata. It supports view/edit modes with inline field editing and array field management, allowing for the addition and removal of values, cultural frameworks, and key principles. Additionally, it features quality score badges and warnings, an empty state with action buttons, integration with wizard and import dialogs, and a responsive design with proper spacing.","context":null,"document":"Week 3 Progress Update - Frontend UI Implementation","category":"Principle","section":"Week 3 Progress Update - Frontend UI Implementation > What Was Built > 1. Organization Context UI (Complete) > **OrganizationContextManager Component** (600+ lines)","confidence":0.9}
{"type":"Procedure","question":"How do I create Google OAuth credentials for the Empathy Ledger?","answer":"To create Google OAuth credentials for the Empathy Ledger, follow these steps: 1. Go to the Google Cloud Console. 2. Select or create a project. 3. Navigate to APIs & Services â†’ Credentials. 4. Click '+ CREATE CREDENTIALS' and select 'OAuth 2.0 Client IDs'. 5. If prompted, configure the OAuth consent screen by choosing 'External' as the user type, filling in the app name as 'Empathy Ledger', adding your email as the support email, including 'localhost' and your domain as authorized domains, and then saving the changes.","context":null,"document":"Google OAuth Setup Guide for Empathy Ledger","category":"Principle","section":"Google OAuth Setup Guide for Empathy Ledger > ðŸš€ Step-by-Step Setup > Step 2: Create Google OAuth Credentials","confidence":0.9}
{"type":"Practice","question":"What is a better way to fetch data in a React component for the Empathy Ledger platform?","answer":"Instead of fetching data directly within a component, it's recommended to use a custom hook along with libraries like SWR or React Query. This allows for better data management, including loading states and error handling.","context":"Fetching data directly in a component can lead to issues with state management and render performance. Using a custom hook separates data logic from UI components.","document":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations","category":"Principle","section":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations > ðŸ—ï¸ Architecture Best Practices > 2. **Data Fetching Pattern**","confidence":0.9}
{"type":"Warning","question":"What should be avoided when fetching data in a React component?","answer":"Avoid directly fetching data within the component using useEffect. This can lead to bad practices such as mixing data fetching with component logic and making the component harder to test.","context":"Directly managing data fetching within the component can introduce complexity and risks related to state management and performance.","document":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations","category":"Principle","section":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations > ðŸ—ï¸ Architecture Best Practices > 2. **Data Fetching Pattern**","confidence":0.85}
{"type":"Practice","question":"How should loading states be handled in data fetching on the Empathy Ledger platform?","answer":"Loading states can be efficiently managed by using a custom hook that returns an 'isLoading' state. This enables the component to display a loading indicator while data is being fetched.","context":"Handling loading states effectively enhances user experience by providing visual feedback when data is being fetched.","document":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations","category":"Principle","section":"ðŸŽ¨ Frontend Best Practices & Redesign Recommendations > ðŸ—ï¸ Architecture Best Practices > 2. **Data Fetching Pattern**","confidence":0.9}
{"type":"Fact","question":"How many profiles have tenant IDs in the Empathy Ledger platform?","answer":"All 223 profiles have tenant IDs, achieving 100% coverage.","context":"This demonstrates the platform's commitment to enable multi-tenancy.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ‘¤ Profiles: FULLY TENANT-ENABLED**","confidence":1}
{"type":"Practice","question":"What privacy controls are available in the Empathy Ledger platform?","answer":"The platform includes rich privacy controls such as story visibility, AI consent, and adherence to cultural protocols.","context":"These controls help ensure that user data is managed with sensitivity and compliance to community standards.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ‘¤ Profiles: FULLY TENANT-ENABLED**","confidence":1}
{"type":"Fact","question":"What advanced features are included in the Empathy Ledger platform?","answer":"Advanced features of the platform include mentoring availability and collaboration preferences.","context":"These features enhance user interaction and support within communities.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ‘¤ Profiles: FULLY TENANT-ENABLED**","confidence":1}
{"type":"Fact","question":"What was completed in terms of legacy migration for the Empathy Ledger platform?","answer":"Legacy migration has been completed with quality scoring.","context":"This indicates that previous data has been successfully integrated and evaluated for quality.","document":"ðŸ¢ Organizational Access Strategy & Community Support Plan","category":"Principle","section":"ðŸ¢ Organizational Access Strategy & Community Support Plan > âœ… **CURRENT MULTI-TENANT CAPABILITIES CONFIRMED** > **ðŸ‘¤ Profiles: FULLY TENANT-ENABLED**","confidence":1}
{"type":"Fact","question":"What types of themes are included in the Transcript Analysis?","answer":"The Transcript Analysis includes two types of themes: standardized themes derived from a taxonomy, which can range from 0 to 15, and Indigenous-specific themes, which can range from 0 to 10.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > 1. Data Foundation (Already Built) > AI Analysis Output (Per Transcript)","confidence":1}
{"type":"Fact","question":"What is the purpose of the 'key_quotes' field in the Transcript Analysis interface?","answer":"The 'key_quotes' field in the Transcript Analysis interface is designed to consist of 1 to 10 verified quotes that are extracted from the transcripts.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > 1. Data Foundation (Already Built) > AI Analysis Output (Per Transcript)","confidence":1}
{"type":"Fact","question":"How is the emotional tone represented in the Transcript Analysis?","answer":"The emotional tone in the Transcript Analysis is represented as a string that indicates the overall narrative tone of the transcript.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > 1. Data Foundation (Already Built) > AI Analysis Output (Per Transcript)","confidence":1}
{"type":"Fact","question":"What does the 'cultural_sensitivity_level' field indicate in the Transcript Analysis?","answer":"The 'cultural_sensitivity_level' field indicates the degree of cultural sensitivity of the transcript analysis and can be categorized as 'low', 'medium', 'high', or 'sacred'.","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > 1. Data Foundation (Already Built) > AI Analysis Output (Per Transcript)","confidence":1}
{"type":"Fact","question":"What metrics are included in the verification_stats of the Transcript Analysis?","answer":"The verification_stats in the Transcript Analysis includes several metrics: the number of quotes extracted, quotes verified, quotes rejected, and the verification rate expressed as a percentage (0-100%).","context":null,"document":"Social Impact & Community Metrics System Design","category":"Principle","section":"Social Impact & Community Metrics System Design > 1. Data Foundation (Already Built) > AI Analysis Output (Per Transcript)","confidence":1}
{"type":"Procedure","question":"What are the steps to set up the database locally on the Empathy Ledger platform?","answer":"To set up the database locally, follow these steps: 1. Ensure Docker is installed on your system. 2. Start the database by running the command 'npm run db:start'. 3. Verify the connection using the script: './scripts/verify-supabase-connection.sh'. 4. Migrate the database by running 'npm run db:migrate'. For more detailed instructions, refer to the full guide at docs/database/local-setup.md.","context":"This process outlines the initial setup for database installation on the platform.","document":"Knowledge Base System Architecture","category":"Principle","section":"Knowledge Base System Architecture > RAG Query Pipeline (Week 2)","confidence":0.95}
{"type":"Method","question":"How does the Empathy Ledger ensure cultural safety in its query results?","answer":"Cultural safety is ensured through a thorough filtering process based on user roles. Super Admins and Platform Admins can access all information, while regular users have non-culturally-safe extractions hidden. The public only sees verified culturally-safe content. Additionally, content categorized as Sacred requires Elder approval to view.","context":"This methodology highlights the importance of role-based access to protect sensitive cultural information.","document":"Knowledge Base System Architecture","category":"Principle","section":"Knowledge Base System Architecture > RAG Query Pipeline (Week 2)","confidence":0.9}
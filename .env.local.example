# Database
NEXT_PUBLIC_SUPABASE_URL=https://yvnuayzslukamizrlhwb.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# LLM Provider - Choose your AI backend
# Options: 'ollama' (FREE, unlimited) or 'openai' (paid, rate limited)
LLM_PROVIDER=ollama

# OpenAI (only needed if LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-proj-xxx

# Ollama runs at http://localhost:11434 by default (no key needed!)
# If you're using Docker: docker run -d -p 11434:11434 ollama/ollama
# Then pull a model: docker exec -it <container> ollama pull llama3.1:8b
